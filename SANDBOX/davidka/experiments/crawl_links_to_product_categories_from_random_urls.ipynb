{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00175c6-7235-4abf-9c0d-a131b6d170b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "## \\file src/webdriver/llm_driver/simple_browser.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "Модуль для запуска задач с использованием LLM через LangChain и стандартных агентов.\n",
    "==================================================================================\n",
    "(Использует инструменты, взаимодействующие с BrowserController и/или API поиска)\n",
    "\n",
    "Предоставляет функциональность для:\n",
    "- Конфигурирования моделей (Gemini, OpenAI).\n",
    "- Установки API ключей.\n",
    "- Запуска задачи с использованием LLM и доступных инструментов (веб-поиск, браузер).\n",
    "- Выполнения задачи до конечного результата (`run_task`).\n",
    "- Стриминга выполнения задачи (`stream_task`).\n",
    "\n",
    "Зависимости:\n",
    "    - langchain-openai, langchain-google-genai, langchain-core, langchainhub, langchain\n",
    "    - langchain-community (для SerpAPIWrapper)\n",
    "    - google-search-results (для SerpAPIWrapper)\n",
    "    - python-dotenv\n",
    "    - browser_use (или ваш модуль с BrowserController)\n",
    "    - src.gs, src.logger, src.utils, header\n",
    "```rst\n",
    ".. module:: src.webdriver.llm_driver.simple_browser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ec09d-83d7-460b-9487-a15b5a3bf586",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipdb # <- трасировка и точки останова\n",
    "import os\n",
    "import asyncio\n",
    "from types import SimpleNamespace\n",
    "from typing import List, Dict, Any, Optional, Callable, Type, Tuple, AsyncIterator\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain компоненты\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.exceptions import LangChainException\n",
    "from langchain import hub\n",
    "# --- Инструмент для поиска через API ---\n",
    "# Убедитесь, что установлена: pip install google-search-results\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from browser_use import Agent\n",
    "\n",
    "# --- Внутренние модули ---\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "# from src.webdriver.ai_browser import tools\n",
    "# from src.webdriver.ai_browser.tools import get_tools, get_tools_by_type, get_tools_by_name\n",
    "from src.webdriver.llm_driver.use_llm import Config, Driver, stream_agent_execution\n",
    "\n",
    "from src.logger import logger\n",
    "from src.utils.jjson import j_loads, j_loads_ns\n",
    "from src.utils.printer import pprint as print\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6800e6-1d41-415f-9845-8925c5f48f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ENDPOINT:Path = Path(__root__/'SANDBOX'/'davidka')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79907a87-6334-4ccb-af83-7aa0447674b7",
   "metadata": {},
   "source": [
    "```python\n",
    "## \\file /sandbox/davidka/crawler_simple_driver.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "Модуль для сбора данных со страниц товаров через SimpleDriver\n",
    "=====================================================\n",
    "(адаптация исходного crawler.py)\n",
    "```rst\n",
    ".. module:: sandbox.davidka.crawler_simple_driver\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b79689-3c27-46e3-b723-2502a841e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import header\n",
    "from header import __root__\n",
    "from src import gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45ac14-f27d-491e-aec4-fbecb3534d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import random\n",
    "from types import SimpleNamespace\n",
    "from typing import List, Dict, Any, Optional, Callable, Type, Tuple, AsyncIterator\n",
    "from pathlib import Path\n",
    "from src.webdriver.llm_driver.simple_driver import SimpleDriver\n",
    "from src.logger import logger\n",
    "from src.utils.jjson import j_loads_ns, j_loads, j_dumps \n",
    "from src.utils.file import get_filenames_from_directory\n",
    "from src.utils.printer import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f67341-1c7b-4b68-9487-31656768d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ENDPOINT: Path = __root__ / 'SANDBOX' / 'davidka'\n",
    "    config:SimpleNamespace = j_loads_ns(ENDPOINT/'davidka.json')\n",
    "    mining_data_path: Path= Path(config.random_urls)\n",
    "\n",
    "    #train_data_supplier_categories_path: Path = ENDPOINT / 'train_data_supplier_categories'\n",
    "    #checked_domains: list = read_text_file(ENDPOINT / 'checked_domains.txt', as_list=True)\n",
    "    crawl_files_list: list = get_filenames_from_directory(mining_data_path, 'json')\n",
    "    instruction_grab_product_page_simple_driver: str = (ENDPOINT / 'instructions' / 'grab_product_page_simple_driver.md').read_text(encoding='utf-8')\n",
    "    instruction_get_supplier_categories: str = (ENDPOINT / 'instructions' / 'get_supplier_categories.md').read_text(encoding='utf-8')\n",
    "    instruction_find_product_in_supplier_domain: str = (ENDPOINT / 'instructions' / 'find_product_in_supplier_domain.md').read_text(encoding='utf-8')\n",
    "    instruction_for_products_urls_one_product: str = (ENDPOINT / 'instructions' / 'get_product_links_one_product.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_search: str = (ENDPOINT / 'instructions' / 'links_from_search.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_searh_page: str = (ENDPOINT / 'instructions' / 'links_from_searh_page.md').read_text(encoding='utf-8')\n",
    "    GEMINI_API_KEY = gs.credentials.gemini.onela.api_key\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2662c0d-e2fd-448a-ab8a-a603c6f0ef7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb6b00-8db1-49cc-b60c-f7f70ab7dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_urls_list_from_files(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"Читает файлы с товарами и возвращает product_url списком\"\"\"\n",
    "    products_urls_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                products_urls_list.append(product['product_url'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    random.shuffle(products_urls_list)\n",
    "    return products_urls_list\n",
    "\n",
    "\n",
    "def yield_product_urls_from_files(directory: Path = Config.mining_data_path, pattern: str = 'json'):\n",
    "    \"\"\"Генератор url товаров из файлов\"\"\"\n",
    "    filenames = get_filenames_from_directory(directory, pattern)\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            file_path = directory / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                yield product['product_url']\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "\n",
    "\n",
    "def get_categories_from_random_urls(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"Возвращает все категории из файлов товаров\"\"\"\n",
    "    categories_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                if 'parent_category' in product:\n",
    "                    categories_list.append(product['parent_category'])\n",
    "                if 'category_name' in product:\n",
    "                    categories_list.append(product['category_name'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    categories_list = list(filter(None, set(categories_list)))\n",
    "    random.shuffle(categories_list)\n",
    "    return categories_list\n",
    "\n",
    "\n",
    "async def build_random_products_urls_by_category(driver: SimpleDriver, category: str, task:str = '', num_of_links: str = '10') -> str:\n",
    "    \"\"\"Получить товары по категории\"\"\"\n",
    "    try:\n",
    "        logger.info(f'Обработка {category=}')\n",
    "        \n",
    "        task = task or Config.instruction_links_from_searh_page.replace('{PRODUCT_CATEGORY}', category).replace('{NUM_LINKS}', num_of_links)\n",
    "        #ipdb.set_trace()\n",
    "        answer = await driver.simple_process_task_async(task)\n",
    "        if not answer:\n",
    "            return ''\n",
    "        print('\\n -------------------------------- EXTRACTED DATA \\n------------------------------------------\\n')\n",
    "        print(answer)\n",
    "        print('\\n -------------------------------------------------------------------------------------------')\n",
    "        save_text_file(answer, Path(f'F:/llm/random_products_links/{gs.now}.json'))\n",
    "        return answer\n",
    "    except Exception as ex:\n",
    "        logger.error(f'Ошибка при обработке {category=}', ex, exc_info=True)\n",
    "        return ''\n",
    "\n",
    "\n",
    "async def fetch_categories_from_suppliers_random_urls() -> dict:\n",
    "    \"\"\"Сбор категорий с сайтов\"\"\"\n",
    "    categories_dict = {}\n",
    "    driver = Config.driver\n",
    "\n",
    "    for filename in Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                domain = get_domain(product['product_url'])\n",
    "                if domain in Config.checked_domains:\n",
    "                    continue\n",
    "                task = Config.instruction_get_supplier_categories.replace('{INPUT_URL}', domain)\n",
    "                res = await driver.simple_process_task_async(task)\n",
    "                if not res:\n",
    "                    continue\n",
    "                normalized_res = normalize_answer(res.get('output', ''))\n",
    "                data = j_loads(normalized_res)\n",
    "                print(data)\n",
    "                j_dumps(data, Config.train_data_supplier_categories_path / f'{gs.now}.json')\n",
    "                Config.checked_domains.append(domain)\n",
    "                save_text_file(Config.checked_domains, Config.ENDPOINT / 'checked_domains.txt')\n",
    "                j_dumps(Config.checked_domains, Config.ENDPOINT / 'checked_domains.json')\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    return categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9568bd-ee6c-4a51-9c1b-d6248b82428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver: SimpleDriver = SimpleDriver(gemini_model_name='gemini-1.5-flash-8b-exp-0924', GEMINI_API_KEY = gs.credentials.gemini.onela.api_key )\n",
    "\n",
    "\n",
    "# Пример: обработка товаров по категориям\n",
    "for category in get_categories_from_random_urls():\n",
    "    #ipdb.set_trace()\n",
    "    if not await build_random_products_urls_by_category(driver = driver, category = category, num_of_links = '10'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28ed5-5f08-4a92-8282-949542be9c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fe849-8485-4317-95ef-aedfe571ef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
