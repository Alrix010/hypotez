{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00175c6-7235-4abf-9c0d-a131b6d170b0",
   "metadata": {},
   "source": [
    "```python\n",
    "## \\file src/webdriver/llm_driver/simple_browser.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "Модуль для запуска задач с использованием LLM через LangChain и стандартных агентов. Ключ - `emil`\n",
    "==================================================================================\n",
    "(Использует инструменты, взаимодействующие с BrowserController и/или API поиска)\n",
    "\n",
    "Предоставляет функциональность для:\n",
    "- Конфигурирования моделей (Gemini, OpenAI).\n",
    "- Установки API ключей.\n",
    "- Запуска задачи с использованием LLM и доступных инструментов (веб-поиск, браузер).\n",
    "- Выполнения задачи до конечного результата (`run_task`).\n",
    "- Стриминга выполнения задачи (`stream_task`).\n",
    "\n",
    "Зависимости:\n",
    "    - langchain-openai, langchain-google-genai, langchain-core, langchainhub, langchain\n",
    "    - langchain-community (для SerpAPIWrapper)\n",
    "    - google-search-results (для SerpAPIWrapper)\n",
    "    - python-dotenv\n",
    "    - browser_use (или ваш модуль с BrowserController)\n",
    "    - src.gs, src.logger, src.utils, header\n",
    "```rst\n",
    ".. module:: src.webdriver.llm_driver.simple_browser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922ec09d-83d7-460b-9487-a15b5a3bf586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [browser_use] BrowserUse logging setup complete with level info\n",
      "INFO     [telemetry] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.\n",
      "INFO     [numexpr.utils] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO     [numexpr.utils] NumExpr defaulting to 8 threads.\n",
      "WARNING  [logger_console] ⚠️ \u001b[91m\u001b[49mError fetching data from git: https://api.github.com/repos/hypotez/hypo/releases/latest\n",
      " response.status_code=404 \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mАсинхронные контроллеры успешно импортированы из src.webdriver.llm_driver.controllers. \u001b[0m\n",
      "WARNING  [logger_console] ⚠️ \u001b[91m\u001b[49m.env файл не найден по пути: C:\\Users\\user\\Documents\\repos\\hypotez\\.env. \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mКонфигурация успешно загружена из C:\\Users\\user\\Documents\\repos\\hypotez\\src\\webdriver\\llm_driver\\use_llm.json \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mConfig Gemini: Status=active, Model=gemini-2.5-flash-preview-04-17, Key Present=True \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mConfig OpenAI: Status=disabled, Model=gpt-4o, Key Present=True \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mConfig SerpAPI: Status=inactive, Key Present=True \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mConfig DuckDuckGo: Status=active \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mConfig Tavily: Status=inactive, Key Present=False \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipdb # <- трасировка и точки останова\n",
    "import os\n",
    "import asyncio\n",
    "from types import SimpleNamespace\n",
    "from typing import List, Dict, Any, Optional, Callable, Type, Tuple, AsyncIterator\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain компоненты\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.exceptions import LangChainException\n",
    "from langchain import hub\n",
    "# --- Инструмент для поиска через API ---\n",
    "# Убедитесь, что установлена: pip install google-search-results\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from browser_use import Agent\n",
    "\n",
    "# --- Внутренние модули ---\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "# from src.webdriver.ai_browser import tools\n",
    "# from src.webdriver.ai_browser.tools import get_tools, get_tools_by_type, get_tools_by_name\n",
    "from src.webdriver.llm_driver.use_llm import Config, Driver, stream_agent_execution\n",
    "\n",
    "from src.logger import logger\n",
    "from src.utils.jjson import j_loads, j_loads_ns\n",
    "from src.utils.printer import pprint as print\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6800e6-1d41-415f-9845-8925c5f48f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ENDPOINT:Path = Path(__root__/'SANDBOX'/'davidka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304c99e5-9452-4fc7-8b4e-669dd093951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDriver(Driver):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, \n",
    "                 GEMINI_API_KEY:str = None, \n",
    "                 OPENAI_API_KEY:str = None, \n",
    "                 openai_model_name:str = None, \n",
    "                 gemini_model_name:str = None, \n",
    "                 start_browser:str = True,\n",
    "                **kwargs):\n",
    "        super().__init__(GEMINI_API_KEY, OPENAI_API_KEY, openai_model_name, gemini_model_name, start_browser, **kwargs) \n",
    "\n",
    "    async def simple_process_task_async(self, task:str = 'Hello, world!') -> Any:\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        result_dict:dict = {}\n",
    "\n",
    "        def clean_json(raw_text: str) -> str:\n",
    "            # 1. Убираем всё до первой фигурной скобки {\n",
    "\n",
    "            json_start = raw_text.find('{')\n",
    "            if json_start == -1:\n",
    "                return raw_text  # нет скобки, вернуть как есть\n",
    "            # Извлекаем текст начиная с первой фигурной скобки\n",
    "            json_cleaned = raw_text[json_start:]\n",
    "    \n",
    "            # 2. Убираем завершающие тройные кавычки или лишние пробелы\n",
    "            json_cleaned = json_cleaned.strip('`\\n ')\n",
    "            \n",
    "            return json_cleaned\n",
    "\n",
    "        try:\n",
    "            # Инициализация агента с списком моделей и задачей\n",
    "            # Убедитесь, что ваш класс Agent может принимать список LLM объектов в параметре 'llm'\n",
    "            agent = Agent(\n",
    "                task=task,\n",
    "                llm=self.gemini, # Передача инициализированнoй модели\n",
    "                # Другие параметры для Agent, если они есть\n",
    "            )\n",
    "            logger.info(f\"Агент начинает выполнение задачи: \\\"{task}\\\"\")\n",
    "            answer: Any = await agent.run() # Ожидание результата работы агента\n",
    "            if not answer:\n",
    "                logger.error('Не вернулся результат действий агента')\n",
    "                ...\n",
    "            timestamp:str = gs.now\n",
    "\n",
    "            for action_result in answer.history:\n",
    "                result_list:list = getattr(action_result, 'result', None)\n",
    "                result:'ActionResult' = result_list[0]\n",
    "                extracted_content:str =\tresult.extracted_content\n",
    "\n",
    "                cleaned_json_text = clean_json(extracted_content)\n",
    "                try:\n",
    "                    data = j_loads(cleaned_json_text)  # Загружаем JSON из текста\n",
    "                    if not data: continue\n",
    "                except Exception as ex:\n",
    "                    logger.error(\"Ошибка разбора JSON\", ex, exc_info=True)\n",
    "                    ...\n",
    "                    continue\n",
    "\n",
    "                # Сохраняем данные\n",
    "                timestamp = gs.now\n",
    "                j_dumps(data, Config.ENDPOINT/'train_data_products'/f'product_links_{timestamp}.json')\n",
    "                result_dict.update(data)\n",
    "\n",
    "            logger.info(\"Агент завершил выполнение задачи.\")\n",
    "            ...\n",
    "            return result_dict \n",
    "        except Exception as agent_err:\n",
    "            logger.error(f\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/nПроизошла ошибка во время инициализации или выполнения задачи агентом./n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n\", agent_err, exc_info=True)\n",
    "            ...\n",
    "            return '' # Возврат None при ошибке агента\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79907a87-6334-4ccb-af83-7aa0447674b7",
   "metadata": {},
   "source": [
    "```python\n",
    "## \\file /sandbox/davidka/crawler_simple_driver.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "Модуль для сбора данных со страниц товаров через SimpleDriver\n",
    "=====================================================\n",
    "(адаптация исходного crawler.py)\n",
    "```rst\n",
    ".. module:: sandbox.davidka.crawler_simple_driver\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c649b671-4a0d-47e3-ba42-b61c0a90023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "from src.webdriver.llm_driver.simple_driver import SimpleDriver\n",
    "from src.utils.jjson import j_loads, j_dumps\n",
    "from src.utils.file import read_text_file, save_text_file, get_filenames_from_directory\n",
    "from src.utils.url import get_domain\n",
    "from src.utils.string.ai_string_utils import normalize_answer\n",
    "from src.utils.printer import pprint as print\n",
    "from src.logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f67341-1c7b-4b68-9487-31656768d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49m--- Начало СИНХРОННОЙ инициализации Driver --- \u001b[0m\n",
      "WARNING  [logger_console] ⚠️ \u001b[91m\u001b[49mOpenAI LLM не инициализирован (Key=True, Status=disabled, Model=True) \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mИнициализация Gemini: Model=gemini-2.5-flash-preview-04-17 \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mGemini LLM инициализирован. \u001b[0m\n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49m--- Синхронная инициализация Driver завершена. Вызовите async_init() --- \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    ENDPOINT: Path = __root__ / 'SANDBOX' / 'davidka'\n",
    "    mining_data_path: Path = ENDPOINT / 'random_urls'\n",
    "    train_data_supplier_categories_path: Path = ENDPOINT / 'train_data_supplier_categories'\n",
    "    checked_domains: list = read_text_file(ENDPOINT / 'checked_domains.txt', as_list=True)\n",
    "    crawl_files_list: list = get_filenames_from_directory(mining_data_path, 'json')\n",
    "    instruction_grab_product_page_simple_driver: str = (ENDPOINT / 'instructions' / 'grab_product_page_simple_driver.md').read_text(encoding='utf-8')\n",
    "    instruction_get_supplier_categories: str = (ENDPOINT / 'instructions' / 'get_supplier_categories.md').read_text(encoding='utf-8')\n",
    "    instruction_find_product_in_supplier_domain: str = (ENDPOINT / 'instructions' / 'find_product_in_supplier_domain.md').read_text(encoding='utf-8')\n",
    "    instruction_for_products_urls_one_product: str = (ENDPOINT / 'instructions' / 'get_product_links_one_product.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_search: str = (ENDPOINT / 'instructions' / 'links_from_search.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_searh_page: str = (ENDPOINT / 'instructions' / 'links_from_searh_page.md').read_text(encoding='utf-8')\n",
    "    GEMINI_API_KEY = gs.credentials.gemini.emil.api_key\n",
    "    driver: SimpleDriver = SimpleDriver(gemini_model_name='gemini-1.5-flash-8b-exp-0924', GEMINI_API_KEY = GEMINI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fb6b00-8db1-49cc-b60c-f7f70ab7dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_urls_list_from_files(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"Читает файлы с продуктами и возвращает product_url списком\"\"\"\n",
    "    products_urls_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                products_urls_list.append(product['product_url'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    random.shuffle(products_urls_list)\n",
    "    return products_urls_list\n",
    "\n",
    "\n",
    "def yield_product_urls_from_files(directory: Path = Config.mining_data_path, pattern: str = 'json'):\n",
    "    \"\"\"Генератор url продуктов из файлов\"\"\"\n",
    "    filenames = get_filenames_from_directory(directory, pattern)\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            file_path = directory / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                yield product['product_url']\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "\n",
    "\n",
    "def get_categories_from_random_urls(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"Возвращает все категории из файлов продуктов\"\"\"\n",
    "    categories_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                if 'parent_category' in product:\n",
    "                    categories_list.append(product['parent_category'])\n",
    "                if 'category_name' in product:\n",
    "                    categories_list.append(product['category_name'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    categories_list = list(filter(None, set(categories_list)))\n",
    "    random.shuffle(categories_list)\n",
    "    return categories_list\n",
    "\n",
    "\n",
    "async def get_products_urls(category: str, task:str = '', num_of_links: str = '10') -> str:\n",
    "    \"\"\"Получить товары по категории\"\"\"\n",
    "    try:\n",
    "        driver = Config.driver\n",
    "        logger.info(f'Обработка {category=}')\n",
    "        \n",
    "        task = task or Config.instruction_links_from_searh_page.replace('{PRODUCT_CATEGORY}', category).replace('{NUM_LINKS}', num_of_links)\n",
    "        #ipdb.set_trace()\n",
    "        answer = await driver.simple_process_task_async(task)\n",
    "        if not answer:\n",
    "            return ''\n",
    "        print('\\n -------------------------------- EXTRACTED DATA \\n------------------------------------------\\n')\n",
    "        print(answer)\n",
    "        print('\\n -------------------------------------------------------------------------------------------')\n",
    "        return answer\n",
    "    except Exception as ex:\n",
    "        logger.error(f'Ошибка при обработке {category=}', ex, exc_info=True)\n",
    "        return ''\n",
    "\n",
    "\n",
    "async def fetch_categories_from_suppliers_random_urls() -> dict:\n",
    "    \"\"\"Сбор категорий с сайтов\"\"\"\n",
    "    categories_dict = {}\n",
    "    driver = Config.driver\n",
    "\n",
    "    for filename in Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                domain = get_domain(product['product_url'])\n",
    "                if domain in Config.checked_domains:\n",
    "                    continue\n",
    "                task = Config.instruction_get_supplier_categories.replace('{INPUT_URL}', domain)\n",
    "                res = await driver.simple_process_task_async(task)\n",
    "                if not res:\n",
    "                    continue\n",
    "                normalized_res = normalize_answer(res.get('output', ''))\n",
    "                data = j_loads(normalized_res)\n",
    "                print(data)\n",
    "                j_dumps(data, Config.train_data_supplier_categories_path / f'{gs.now}.json')\n",
    "                Config.checked_domains.append(domain)\n",
    "                save_text_file(Config.checked_domains, Config.ENDPOINT / 'checked_domains.txt')\n",
    "                j_dumps(Config.checked_domains, Config.ENDPOINT / 'checked_domains.json')\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    return categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9568bd-ee6c-4a51-9c1b-d6248b82428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mОбработка category='Temperature Controllers' \u001b[0m\n",
      "INFO     [agent] 🧠 Starting an agent with main_model=models/gemini-2.5-flash-preview-04-17 +vision, planner_model=None, extraction_model=None \n",
      "INFO     [logger_console] ℹ️ \u001b[32m\u001b[49mАгент начинает выполнение задачи: \"\n",
      "```md\n",
      "**Роль:** Ты — Автоматизированный Веб-Агент для Поиска Страниц.\n",
      "\n",
      "**Цель:**  \n",
      "Найти **все ссылки** из первой страницы поиска по запросу `Temperature Controllers`.\n",
      "\n",
      "**Инструкция:**\n",
      "\n",
      "1. **Открой поисковую систему** (например, Google, Bing или аналогичную).\n",
      "\n",
      "2. \n",
      "- **Введи запрос**: `Temperature Controllers`.\n",
      "\n",
      "3. **Из результатов поиска**:\n",
      "\n",
      "   - Собери **все ссылки** на первой странице поиска.\n",
      "   - Пропускай рекламные и спонсорские результаты.\n",
      "   - Пропускай ссылки на социальные сети и видеохостинги.\n",
      "\n",
      "4. **Фильтрация ссылок**:\n",
      "   - Игнорируй все ссылки, в домене которых содержатся следующие ключевые слова:\n",
      "     - `youtube`\n",
      "     - `tiktok`\n",
      "     - `facebook`\n",
      "     - `instagram`\n",
      "     - `twitter`\n",
      "     - `linkedin`\n",
      "     - `pinterest`\n",
      "     - `vk`\n",
      "     - `reddit`\n",
      "     - `snapchat`\n",
      "     - и аналогичные платформы социальных сетей или видеохостингов.\n",
      "   - Проверку выполняй по части URL (поддомен и основной домен).\n",
      "   - Если URL содержит хотя бы одно из этих слов — пропускай его.\n",
      "\n",
      "5. **Больше ничего не делай**:\n",
      "   - Не переходи по ссылкам.\n",
      "   - Не анализируй содержимое страниц.\n",
      "   - Только сохрани сами URL.\n",
      "\n",
      "---\n",
      "\n",
      "**📦 Формат итогового ответа:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"links\": [\n",
      "    \"<ссылка 1>\",\n",
      "    \"<ссылка 2>\",\n",
      "    \"<ссылка 3>\",\n",
      "    \"...\",\n",
      "    \"<последняя ссылка>\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**⚡ Важно:**\n",
      "- Сохраняй только реальные органические результаты поиска.\n",
      "- Пропускай рекламные и спонсорские блоки.\n",
      "- Пропускай ссылки на социальные сети и видеохостинги.\n",
      "- Никаких дополнительных комментариев или пояснений — только JSON-ответ.\n",
      "```\n",
      "\" \u001b[0m\n",
      "WARNING  [langchain_google_genai.chat_models] Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 500\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "].\n",
      "ERROR    [agent] \n",
      "\n",
      "❌  LLM ChatGoogleGenerativeAI connection test failed. Check that GEMINI_API_KEY is set correctly in .env and that the LLM API account has sufficient funding.\n",
      "\n",
      "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 500\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "\n",
      "ERROR    [logger_console] ❌ \u001b[31m\u001b[49m\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/nПроизошла ошибка во время инициализации или выполнения задачи агентом./n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n Failed to connect to LLM API or LLM API is not responding correctly\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Documents\\repos\\hypotez\\src\\webdriver\\llm_driver\\simple_driver.py\", line 112, in simple_process_task_async\n",
      "    answer = await agent.run()\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\browser_use\\utils.py\", line 300, in wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\browser_use\\agent\\service.py\", line 793, in run\n",
      "    assert self.llm._verified_api_keys or SKIP_LLM_API_KEY_VERIFICATION, (\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: Failed to connect to LLM API or LLM API is not responding correctly\n"
     ]
    }
   ],
   "source": [
    "driver = Config.driver\n",
    "\n",
    "# Пример: обработка товаров по категориям\n",
    "for category in get_categories_from_random_urls():\n",
    "    #ipdb.set_trace()\n",
    "    if not await get_products_urls(category = category, num_of_links = '10'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28ed5-5f08-4a92-8282-949542be9c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
