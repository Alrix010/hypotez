# Модуль `crawlee_python`

## Обзор

Модуль `crawlee_python` предоставляет пользовательскую реализацию `PlaywrightCrawler` с использованием библиотеки Crawlee. Он позволяет настраивать параметры браузера, обрабатывать запросы и извлекать данные с веб-страниц.

## Подробнее

Этот модуль предназначен для создания веб-пауков, использующих библиотеку Crawlee и Playwright для управления браузером. Он позволяет выполнять обход веб-сайтов, извлекать данные и сохранять их в формате JSON. Модуль предоставляет гибкие настройки для управления поведением браузера, такие как запуск в headless-режиме и выбор типа браузера.

## Классы

### `CrawleePython`

**Описание**: Класс `CrawleePython` представляет собой пользовательскую реализацию `PlaywrightCrawler` с использованием библиотеки Crawlee.

**Атрибуты**:
- `max_requests` (int): Максимальное количество запросов для выполнения во время обхода.
- `headless` (bool): Определяет, запускать ли браузер в headless-режиме.
- `browser_type` (str): Тип используемого браузера ('chromium', 'firefox', 'webkit').
- `crawler` (PlaywrightCrawler): Экземпляр `PlaywrightCrawler`.
- `options` (List[str]): Список дополнительных аргументов командной строки для запуска браузера.

**Принцип работы**:
Класс инициализируется с заданными параметрами, такими как максимальное количество запросов, режим headless и тип браузера. Он настраивает и запускает `PlaywrightCrawler` с указанными параметрами. Класс также предоставляет методы для экспорта и получения извлеченных данных.

**Методы**:
- `__init__`: Инициализирует экземпляр класса `CrawleePython`.
- `setup_crawler`: Настраивает экземпляр `PlaywrightCrawler` с указанной конфигурацией.
- `run_crawler`: Запускает обход веб-страниц с использованием `PlaywrightCrawler`.
- `export_data`: Экспортирует данные в JSON-файл.
- `get_data`: Получает извлеченные данные.
- `run`: Основной метод для настройки, запуска обхода и экспорта данных.

## Методы класса

### `__init__`

```python
def __init__(self, max_requests: int = 5, headless: bool = False, browser_type: str = 'firefox', options: Optional[List[str]] = None):
    """
    Инициализирует объект класса CrawleePython с заданными параметрами.

    Args:
        max_requests (int, optional): Максимальное количество запросов для выполнения во время обхода. По умолчанию 5.
        headless (bool, optional): Определяет, запускать ли браузер в headless-режиме. По умолчанию False.
        browser_type (str, optional): Тип используемого браузера ('chromium', 'firefox', 'webkit'). По умолчанию 'firefox'.
        options (Optional[List[str]], optional): Список дополнительных аргументов командной строки для запуска браузера. По умолчанию None.
    """
```

### `setup_crawler`

```python
async def setup_crawler(self):
    """
    Настраивает экземпляр PlaywrightCrawler с указанной конфигурацией.
    """
```

### `run_crawler`

```python
async def run_crawler(self, urls: List[str]):
    """
    Запускает обход веб-страниц с использованием PlaywrightCrawler.

    Args:
        urls (List[str]): Список URL-адресов для начала обхода.
    """
```

### `export_data`

```python
async def export_data(self, file_path: str):
    """
    Экспортирует весь набор данных в JSON-файл.

    Args:
        file_path (str): Путь для сохранения экспортированного JSON-файла.
    """
```

### `get_data`

```python
async def get_data(self) -> Dict[str, Any]:
    """
    Извлекает данные.

    Returns:
        Dict[str, Any]: Извлеченные данные в виде словаря.
    """
```

### `run`

```python
async def run(self, urls: List[str]):
    """
    Основной метод для настройки и запуска веб-паука, а также экспорта данных.

    Args:
        urls (List[str]): Список URL-адресов для начала обхода.
    """
```

## Параметры класса

- `max_requests` (int): Максимальное количество запросов, которые будут выполнены во время обхода веб-страниц. Этот параметр позволяет ограничить время работы веб-паука и избежать излишней нагрузки на целевые серверы.
- `headless` (bool): Флаг, указывающий, следует ли запускать браузер в режиме без графического интерфейса (headless). Headless-режим полезен для запуска веб-паука на серверах без монитора, так как он потребляет меньше ресурсов.
- `browser_type` (str): Тип браузера, который будет использоваться для обхода веб-страниц. Поддерживаются следующие типы: 'chromium', 'firefox' и 'webkit'. Выбор типа браузера может повлиять на совместимость с различными веб-сайтами и на производительность веб-паука.
- `options` (Optional[List[str]]): Список дополнительных аргументов командной строки, которые будут переданы при запуске браузера. Эти аргументы позволяют настроить различные аспекты поведения браузера, такие как прокси-сервер, пользовательский агент и другие параметры.

## Примеры

Пример использования класса `CrawleePython`:

```python
if __name__ == '__main__':
    async def main():
        crawler = CrawleePython(max_requests=5, headless=False, browser_type='firefox', options=["--headless"])
        await crawler.run(['https://www.example.com'])

    asyncio.run(main())