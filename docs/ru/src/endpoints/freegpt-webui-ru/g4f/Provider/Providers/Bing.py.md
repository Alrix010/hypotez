# Модуль Bing.py

## Обзор

Модуль `Bing.py` предназначен для взаимодействия с чат-ботом Bing AI. Он предоставляет функциональность для создания диалогов, генерации ответов в потоковом режиме и форматирования запросов. Модуль использует асинхронные запросы для обеспечения неблокирующего взаимодействия.

## Подробней

Модуль содержит классы и функции, необходимые для установления соединения с Bing AI, отправки запросов и получения ответов. Он включает в себя настройку SSL, формирование заголовков запросов, создание структуры сообщений и обработку ответов от сервера Bing.

## Классы

### `optionsSets`

**Описание**: Класс, предназначенный для хранения наборов опций, используемых при взаимодействии с Bing AI.

**Атрибуты**:

-   `optionSet` (dict): Словарь, содержащий типы для опций `tone` (str) и `optionsSets` (list).
-   `jailbreak` (dict): Словарь, содержащий набор опций для "обхода защиты" Bing AI.

### `Defaults`

**Описание**: Класс, содержащий значения по умолчанию для различных параметров, используемых при взаимодействии с Bing AI.

**Атрибуты**:

-   `delimiter` (str): Разделитель, используемый для разделения сообщений при потоковой передаче данных.
-   `ip_address` (str): IP-адрес, используемый в заголовках запросов. Генерируется случайным образом.
-   `allowedMessageTypes` (list): Список допустимых типов сообщений.
-   `sliceIds` (list): Список идентификаторов "слайсов".
-   `location` (dict): Информация о местоположении пользователя, используемая в запросах.

## Функции

### `_format(msg: dict) -> str`

**Назначение**: Форматирует сообщение в JSON-формат и добавляет разделитель в конце.

**Параметры**:

-   `msg` (dict): Словарь, представляющий сообщение.

**Возвращает**:

-   `str`: JSON-представление сообщения с разделителем.

**Как работает функция**:
Функция принимает словарь `msg`, преобразует его в JSON-строку с помощью `json.dumps`, убедившись, что не ASCII символы будут корректно отображены (ensure_ascii=False). Затем добавляет к полученной строке разделитель `Defaults.delimiter`.

**Примеры**:

```python
msg = {"text": "Hello, world!"}
formatted_msg = _format(msg)
print(formatted_msg)  # doctest: +SKIP
# Output: {"text": "Hello, world!"}

```

### `create_conversation() -> tuple[str, str, str]`

**Назначение**: Создает разговор с Bing AI и возвращает идентификаторы и подпись разговора.

**Возвращает**:

-   `tuple[str, str, str]`: Кортеж, содержащий `conversationId`, `clientId` и `conversationSignature`.

**Вызывает исключения**:

-   `Exception`: Если не удается создать разговор после нескольких попыток.

**Как работает функция**:
Функция пытается создать разговор с Bing AI, отправляя GET-запрос к `https://www.bing.com/turing/conversation/create`. Она повторяет попытку до 5 раз. В каждом цикле извлекаются `conversationId`, `clientId` и `conversationSignature` из JSON-ответа. Если после 5 попыток не удается получить все три параметра, вызывается исключение.

**Примеры**:

```python
# Пример вызова функции
conversation_id, client_id, conversation_signature = await create_conversation()
print(f"Conversation ID: {conversation_id}") # doctest: +SKIP
print(f"Client ID: {client_id}") # doctest: +SKIP
print(f"Conversation Signature: {conversation_signature}") # doctest: +SKIP
```

### `stream_generate(prompt: str, mode: optionsSets.optionSet = optionsSets.jailbreak, context: bool | str = False) -> Generator[str, None, None]`

**Назначение**: Генерирует ответы от Bing AI в потоковом режиме.

**Параметры**:

-   `prompt` (str): Текст запроса.
-   `mode` (dict): Набор опций, используемых при генерации ответа. По умолчанию `optionsSets.jailbreak`.
-   `context` (bool | str): Контекст разговора. По умолчанию `False`.

**Возвращает**:

-   `Generator[str, None, None]`: Генератор, возвращающий части ответа от Bing AI.

**Вызывает исключения**:

-   `Exception`: Если возникает ошибка при получении ответа от Bing AI.

**Как работает функция**:

1.  Устанавливает таймаут для aiohttp клиента.
2.  Создает сессию aiohttp клиента.
3.  Вызывает функцию `create_conversation()` для получения идентификаторов разговора.
4.  Подключается к WebSocket серверу Bing AI.
5.  Отправляет структуру сообщения, содержащую запрос и параметры.
6.  Получает ответы от сервера и обрабатывает их, извлекая текст ответа.
7.  Возвращает текст ответа через генератор.
8.  В случае ошибки закрывает WebSocket соединение и сессию aiohttp клиента.

**Примеры**:

```python
# Пример вызова функции
prompt = "Tell me a joke."
async for response_part in stream_generate(prompt):
    print(response_part, end="")  # doctest: +SKIP
```

### `run(generator) -> Generator[Any, None, None]`

**Назначение**: Запускает асинхронный генератор и возвращает значения.

**Параметры**:

-   `generator`: Асинхронный генератор.

**Возвращает**:

-   `Generator[Any, None, None]`: Генератор, возвращающий значения из асинхронного генератора.

**Как работает функция**:

1.  Получает event loop.
2.  Преобразует `generator` в асинхронный итератор.
3.  В цикле пытается получить следующее значение из асинхронного итератора, используя `loop.run_until_complete`.
4.  Возвращает полученное значение через генератор.
5.  Останавливается, когда `StopAsyncIteration` исключение поднято.

**Примеры**:

```python
async def my_generator():
    yield "Hello"
    yield "World"

# Пример использования функции
for value in run(my_generator()):
    print(value)
# Hello
# World
```

### `convert(messages: list) -> str`

**Назначение**: Преобразует список сообщений в строку контекста.

**Параметры**:

-   `messages` (list): Список сообщений, где каждое сообщение - словарь с ключами `role` и `content`.

**Возвращает**:

-   `str`: Строка контекста, содержащая сообщения в формате Markdown.

**Как работает функция**:
Функция принимает список сообщений, где каждое сообщение представляет собой словарь с ключами `role` и `content`. Функция формирует строку контекста, объединяя все сообщения в формате Markdown.

**Примеры**:

```python
messages = [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi there"}
]
context = convert(messages)
print(context)
# [user](#message)
# Hello
#
# [assistant](#message)
# Hi there
#
```

### `_create_completion(model: str, messages: list, stream: bool, **kwargs) -> Generator[str, None, None]`

**Назначение**: Создает запрос к Bing AI и возвращает ответ в потоковом режиме.

**Параметры**:

-   `model` (str): Имя модели.
-   `messages` (list): Список сообщений.
-   `stream` (bool): Флаг, указывающий, нужно ли возвращать ответ в потоковом режиме.
-   `**kwargs`: Дополнительные параметры.

**Возвращает**:

-   `Generator[str, None, None]`: Генератор, возвращающий части ответа от Bing AI.

**Как работает функция**:

1.  Определяет промпт и контекст в зависимости от количества сообщений.
2.  Вызывает функцию `run` с асинхронным генератором `stream_generate` для получения ответа от Bing AI в потоковом режиме.
3.  Возвращает полученные токены через генератор.

**Примеры**:

```python
messages = [{"role": "user", "content": "Tell me a joke."}]
for token in _create_completion("gpt-4", messages, True):
    print(token, end="")  # doctest: +SKIP
```

## Параметры

-   `url` (str): URL-адрес Bing AI.
-   `model` (list): Список поддерживаемых моделей.
-   `supports_stream` (bool): Флаг, указывающий, поддерживается ли потоковая передача данных.
-   `needs_auth` (bool): Флаг, указывающий, требуется ли аутентификация.
-   `ssl_context` (ssl.SSLContext): SSL-контекст для безопасного соединения.
-   `params` (str): Строка, содержащая информацию о поддерживаемых параметрах функции `_create_completion`.