# Модуль для работы с Vercel Provider
## Обзор

Модуль предоставляет класс `Client` для взаимодействия с моделями Vercel AI. Он включает в себя функциональность для получения токена, генерации текста на основе выбранной модели и обработки параметров модели.

## Подробней

Данный модуль предназначен для интеграции с Vercel AI и предоставляет инструменты для работы с различными моделями, размещенными на этой платформе. Он позволяет генерировать текст на основе заданных параметров и промптов, используя API Vercel.

## Классы

### `Client`

**Описание**: Класс `Client` предоставляет методы для взаимодействия с API Vercel AI.

**Принцип работы**:
1.  Инициализируется сессия `requests.Session()` для выполнения HTTP-запросов.
2.  Определяются заголовки (`headers`), которые будут использоваться в запросах.
3.  Метод `get_token()` получает токен аутентификации с использованием `execjs` для выполнения JavaScript-кода, возвращаемого сервером.
4.  Метод `get_default_params()` извлекает параметры по умолчанию для указанной модели из словаря `vercel_models`.
5.  Метод `generate()` отправляет запрос на генерацию текста, используя полученный токен и параметры, и возвращает результат в виде потока чанков.

**Аттрибуты**:

*   `session` (requests.Session): Сессия для выполнения HTTP-запросов.
*   `headers` (dict): Заголовки HTTP-запросов.

**Методы**:

*   `__init__()`: Инициализирует экземпляр класса `Client` с сессией и заголовками.
*   `get_token()`: Получает токен аутентификации для доступа к API Vercel.
*   `get_default_params(model_id: str) -> dict`: Возвращает параметры по умолчанию для указанной модели.
*   `generate(model_id: str, prompt: str, params: dict = {}) -> Generator[str, None, None]`: Генерирует текст на основе указанной модели и промпта.

### `__init__`

```python
 def __init__(self):
        """
        Инициализирует экземпляр класса `Client`.

        Создает сессию `requests.Session()` и устанавливает заголовки для HTTP-запросов.
        """
        ...
```

**Назначение**: Инициализирует экземпляр класса `Client`.

**Как работает функция**:

1.  Создает HTTP сессию с помощью `requests.Session()`.
2.  Определяет заголовки, которые будут использоваться при отправке запросов.

**Примеры**:

```python
client = Client()
print(type(client.session))  # Вывод: <class 'curl_cffi.requests.Session'>
print(client.headers)
```

### `get_token`

```python
def get_token(self) -> str:
    """
    Получает токен аутентификации для доступа к API Vercel.

    Возвращает base64-encoded токен.

    Returns:
        str: Токен аутентификации в формате base64.
    """
    ...
```

**Назначение**: Получает токен аутентификации для доступа к API Vercel.

**Как работает функция**:

1.  Выполняет GET-запрос к `https://sdk.vercel.ai/openai.jpeg` и извлекает текст ответа.
2.  Декодирует полученный base64-encoded JSON.
3.  Извлекает функции `c` и `a` из декодированного JSON.
4.  Формирует JavaScript-код, используя извлеченные функции.
5.  Выполняет JavaScript-код с использованием `execjs` и получает токен.
6.  Кодирует полученный токен в base64 и возвращает его.

**Примеры**:

```python
client = Client()
token = client.get_token()
print(type(token))  # Вывод: <class 'str'>
print(token)
```

### `get_default_params`

```python
def get_default_params(self, model_id: str) -> dict:
    """
    Возвращает параметры по умолчанию для указанной модели.

    Args:
        model_id (str): Идентификатор модели.

    Returns:
        dict: Словарь параметров по умолчанию.
    """
    ...
```

**Назначение**: Возвращает параметры по умолчанию для указанной модели.

**Как работает функция**:

1.  Извлекает словарь параметров для указанной модели из `vercel_models`.
2.  Создает новый словарь, содержащий только значения параметров.

**Примеры**:

```python
client = Client()
model_id = 'anthropic:claude-instant-v1'
params = client.get_default_params(model_id)
print(type(params))  # Вывод: <class 'dict'>
print(params)
```

### `generate`

```python
def generate(self, model_id: str, prompt: str, params: dict = {}) -> Generator[str, None, None]:
    """
    Генерирует текст на основе указанной модели и промпта.

    Args:
        model_id (str): Идентификатор модели.
        prompt (str): Промпт для генерации текста.
        params (dict, optional): Дополнительные параметры для модели. Defaults to {}.

    Yields:
        str: Части сгенерированного текста.
    Raises:
        Exception: Если возникает ошибка при отправке запроса.
    """
    ...
```

**Назначение**: Генерирует текст на основе указанной модели и промпта.

**Как работает функция**:

1.  Если `model_id` не содержит `:`, пытается найти его в словаре `models`.
2.  Извлекает параметры по умолчанию для указанной модели с помощью `self.get_default_params()`.
3.  Объединяет параметры по умолчанию, переданные параметры и промпт в один словарь `payload`.
4.  Добавляет токен аутентификации в заголовки запроса.
5.  Создает очередь `chunks_queue` для хранения чанков сгенерированного текста.
6.  Определяет функцию `callback`, которая добавляет декодированные чанки в очередь.
7.  Создает и запускает поток `request_thread`, который отправляет POST-запрос к API Vercel и обрабатывает ответ с помощью `callback`.
8.  Извлекает чанки из очереди и генерирует их до тех пор, пока не будет получен весь текст или не возникнет ошибка.

**Внутренние функции**:

*   `callback(data)`: Добавляет декодированные данные в очередь `chunks_queue`.
*   `request_thread()`: Отправляет запрос к API Vercel и обрабатывает ответ.

**Примеры**:

```python
client = Client()
model_id = 'anthropic:claude-instant-v1'
prompt = 'Напиши короткое стихотворение о весне.'
for chunk in client.generate(model_id, prompt):
    print(chunk)
```

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, stream: bool, **kwargs) -> Generator[str, None, None]:
    """
    Генерирует завершение текста на основе указанной модели и списка сообщений.

    Args:
        model (str): Идентификатор модели.
        messages (list): Список сообщений в формате [{"role": "user" | "assistant", "content": "message content"}].
        stream (bool): Указывает, следует ли возвращать результат в виде потока.
        **kwargs: Дополнительные параметры.

    Yields:
        str: Части сгенерированного текста.
    """
    ...
```

**Назначение**: Генерирует текст на основе указанной модели и списка сообщений.

**Как работает функция**:

1.  Создает строку `conversation`, содержащую историю сообщений между пользователем и ассистентом.
2.  Инициализирует `Client` и вызывает метод `generate` для генерации текста на основе `conversation`.
3.  Генерирует чанки сгенерированного текста.

**Примеры**:

```python
model = 'anthropic:claude-instant-v1'
messages = [
    {'role': 'user', 'content': 'Привет!'},
    {'role': 'assistant', 'content': 'Здравствуйте!'}
]
for token in _create_completion(model, messages, stream=True):
    print(token)
```

### `params`

```python
params: str
```

**Назначение**:  Строка, содержащая информацию о поддерживаемых типах параметров для функции `_create_completion`.

**Как работает**:

Формирует строку, используя `os.path.basename(__file__)` для получения имени текущего файла, и `get_type_hints(_create_completion)` для получения аннотаций типов параметров функции `_create_completion`.  Создаёт строку с именами аргументов и их типами, например: `'model': str, 'messages': list, 'stream': bool`.

**Примеры**:

Строка `params` будет содержать что-то вроде: `'g4f.Providers.Vercel supports: (model: str, messages: list, stream: bool)'`.