# Модуль Lockchat

## Обзор

Модуль предоставляет функциональность для взаимодействия с Lockchat API, включая отправку запросов на создание завершений чата. Он поддерживает потоковую передачу ответов и использует модель `gpt-4` или `gpt-3.5-turbo`.

## Подробней

Этот модуль предназначен для интеграции с Lockchat API, позволяя отправлять запросы на генерацию текста с использованием указанных моделей. Он обрабатывает ответы в потоковом режиме, возвращая токены по мере их поступления. Модуль также содержит параметры для указания поддерживаемых моделей и необходимости аутентификации.

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, stream: bool, temperature: float = 0.7, **kwargs):
    """ Функция создает запрос к Lockchat API для генерации текста на основе предоставленных параметров.

    Args:
        model (str): Идентификатор модели для использования (например, 'gpt-4', 'gpt-3.5-turbo').
        messages (list): Список сообщений для отправки в API.
        stream (bool): Флаг, указывающий, следует ли использовать потоковую передачу ответов.
        temperature (float, optional): Параметр temperature для контроля случайности генерации. По умолчанию 0.7.
        **kwargs: Дополнительные параметры.

    Returns:
        Generator[str, None, None]: Генератор токенов текста, возвращаемых из API.

    Raises:
        Exception: Если возникает ошибка при обращении к API.

    Пример:
        messages = [{'role': 'user', 'content': 'Hello, how are you?'}]
        model = 'gpt-3.5-turbo'
        for token in _create_completion(model=model, messages=messages, stream=True):
            print(token)

    """
```

**Назначение**: Создает запрос к Lockchat API для генерации текста на основе предоставленных параметров. Функция отправляет POST-запрос к API и обрабатывает ответ, возвращая токены по мере их поступления.

**Параметры**:
- `model` (str): Идентификатор модели для использования (например, 'gpt-4', 'gpt-3.5-turbo').
- `messages` (list): Список сообщений для отправки в API.
- `stream` (bool): Флаг, указывающий, следует ли использовать потоковую передачу ответов.
- `temperature` (float, optional): Параметр temperature для контроля случайности генерации. По умолчанию 0.7.
- `**kwargs`: Дополнительные параметры.

**Возвращает**:
- `Generator[str, None, None]`: Генератор токенов текста, возвращаемых из API.

**Вызывает исключения**:
- Отсутствуют явные исключения, но могут возникать исключения `requests.exceptions.RequestException` при проблемах с сетевым запросом.

**Как работает функция**:

1. **Подготовка полезной нагрузки**: Функция создает словарь `payload`, содержащий параметры запроса, такие как температура, сообщения, модель и флаг потоковой передачи.
2. **Определение заголовков**: Функция создает словарь `headers`, содержащий заголовок `user-agent`.
3. **Отправка POST-запроса**: Функция отправляет POST-запрос к Lockchat API с использованием библиотеки `requests`. Указывается URL-адрес API, полезная нагрузка в формате JSON и заголовки. В запросе также включается параметр `stream=True` для потоковой передачи ответов.
4. **Обработка потока ответов**: Функция перебирает строки ответа, используя `response.iter_lines()`.
5. **Проверка на наличие ошибки**: Для каждой строки проверяется, не содержит ли она сообщение об ошибке, указывающее на то, что модель не существует. Если такая ошибка обнаружена, функция выводит сообщение об ошибке и рекурсивно вызывает себя, чтобы повторить запрос.
6. **Извлечение содержимого токена**: Если строка содержит "content", функция извлекает содержимое токена из JSON-структуры ответа.
7. **Генерация токенов**: Если извлеченное содержимое токена не пустое, функция генерирует этот токен с помощью `yield`.

```
    Начало
    │
    ├── Подготовка полезной нагрузки (payload) и заголовков (headers)
    │
    ├── Отправка POST-запроса к Lockchat API (requests.post)
    │
    ├── Обработка потока ответов (response.iter_lines)
    │
    ├── Проверка на наличие ошибки (b'The model: `gpt-4` does not exist' in token)
    │   └── Если ошибка обнаружена:
    │       └── Рекурсивный вызов _create_completion для повторной попытки
    │
    ├── Извлечение содержимого токена (json.loads(token.decode('utf-8').split('data: ')[1])['choices'][0]['delta'].get('content'))
    │
    └── Генерация токена (yield (token))
    │
    Конец
```

**Примеры**:

```python
messages = [{"role": "user", "content": "Hello, how are you?"}]
for token in _create_completion(model="gpt-3.5-turbo", messages=messages, stream=True):
    print(token)
```

### `params`

```python
params = f'g4f.Providers.{os.path.basename(__file__)[:-3]} supports: ' + \
    '(%s)' % ', '.join([f"{name}: {get_type_hints(_create_completion)[name].__name__}" for name in _create_completion.__code__.co_varnames[:_create_completion.__code__.co_argcount]])
```

**Назначение**: Формирует строку с информацией о поддерживаемых параметрах функции `_create_completion`.

**Как работает**:
1. Извлекает имя файла текущего модуля без расширения `.py`.
2. Получает имена параметров и их типы из функции `_create_completion` с использованием `get_type_hints`.
3. Форматирует строку, содержащую информацию о поддерживаемых параметрах и их типах.

```
    Начало
    │
    ├── Извлечение имени файла (os.path.basename(__file__)[:-3])
    │
    ├── Получение аннотаций типов параметров (_create_completion) (get_type_hints)
    │
    └── Форматирование строки с информацией о параметрах
    │
    Конец
```

**Примеры**:

```python
print(params) #  Например: g4f.Providers.Lockchat supports: (model: str, messages: list, stream: bool, temperature: float)