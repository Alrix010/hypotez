# Модуль Mishalsgpt

## Обзор

Модуль предоставляет интерфейс для взаимодействия с моделью Mishalsgpt через API. Он определяет функцию `_create_completion` для создания запросов к API и получения ответов.
Поддерживает потоковую передачу данных и не требует авторизации.
Модуль предназначен для использования в проекте `hypotez` для обеспечения доступа к возможностям модели Mishalsgpt.

## Подробней

Модуль `Mishalsgpt` служит в качестве поставщика (Provider) для библиотеки `g4f` в проекте `hypotez`.
Он предоставляет способ взаимодействия с API `Mishalsgpt`, оборачивая запросы к API в функцию `_create_completion`.
Этот модуль использует библиотеку `requests` для выполнения HTTP-запросов и модуль `os` для получения имени файла.

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, stream: bool, **kwargs):
    """
    Создает запрос к API Mishalsgpt и возвращает ответ.

    Args:
        model (str): Идентификатор модели для использования.
        messages (list): Список сообщений для отправки в API.
        stream (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
        **kwargs: Дополнительные параметры.

    Returns:
        Generator[str, None, None]: Генератор, возвращающий содержимое ответа от API.

    Raises:
        requests.exceptions.RequestException: Если возникает ошибка при выполнении HTTP-запроса.

    Example:
        >>> model_name = "gpt-3.5-turbo"
        >>> messages_example = [{"role": "user", "content": "Hello, how are you?"}]
        >>> stream_option = True
        >>> for chunk in _create_completion(model_name, messages_example, stream_option):
        ...     print(chunk)
    """
    ...
```

**Назначение**:
Функция `_create_completion` отправляет запрос к API Mishalsgpt и возвращает ответ в виде генератора. Она принимает параметры, такие как модель, сообщения и флаг потоковой передачи, и использует библиотеку `requests` для отправки POST-запроса.

**Параметры**:
- `model` (str): Идентификатор модели, которую следует использовать.
- `messages` (list): Список сообщений, отправляемых в API.
- `stream` (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
- `**kwargs`: Дополнительные параметры.

**Возвращает**:
- `Generator[str, None, None]`: Генератор, возвращающий содержимое ответа от API.

**Вызывает исключения**:
- `requests.exceptions.RequestException`: Если возникает ошибка при выполнении HTTP-запроса.

**Как работает функция**:

1.  **Формирование заголовков**: Функция начинает с формирования заголовков HTTP-запроса, устанавливая тип контента в `application/json`.
2.  **Создание данных запроса**: Затем она создает словарь `data`, содержащий модель, температуру и сообщения для отправки в API.
3.  **Отправка POST-запроса**: После этого функция отправляет POST-запрос к API Mishalsgpt по адресу `url + '/api/openai/v1/chat/completions'`, передавая заголовки и данные запроса.
4.  **Обработка потокового ответа**: Если `stream` установлен в `True`, функция обрабатывает потоковый ответ, извлекая содержимое каждого сообщения и возвращая его в виде генератора.
5.  **Извлечение содержимого**: Извлекает содержимое ответа в формате JSON, получая доступ к элементам `['choices'][0]['message']['content']`.
6.  **Генерирование результата**: Возвращает результат в виде генератора, который выдает содержимое каждого полученного сообщения.

**ASCII flowchart**:

```
    Формирование заголовков
    ↓
    Создание данных запроса
    ↓
    Отправка POST-запроса к API
    ↓
    Обработка потокового ответа
    ↓
    Извлечение содержимого
    ↓
    Генерирование результата
```

**Примеры**:

```python
model_name = "gpt-3.5-turbo"
messages_example = [{"role": "user", "content": "Hello, how are you?"}]
stream_option = True
for chunk in _create_completion(model_name, messages_example, stream_option):
    print(chunk)
```

### `params`

```python
params = f'g4f.Providers.{os.path.basename(__file__)[:-3]} supports: ' + \
    '(%s)' % ', '.join([f"{name}: {get_type_hints(_create_completion)[name].__name__}" for name in _create_completion.__code__.co_varnames[:_create_completion.__code__.co_argcount]])
```

**Назначение**:

Переменная `params` формирует строку, содержащую информацию о поддержке параметров функцией `_create_completion`. Она используется для отображения поддерживаемых параметров и их типов.

**Как работает**:

1.  **Получение имени файла**: Использует `os.path.basename(__file__)[:-3]` для получения имени текущего файла без расширения `.py`.
2.  **Получение аннотаций типов**: Использует `get_type_hints(_create_completion)` для получения аннотаций типов параметров функции `_create_completion`.
3.  **Формирование списка параметров**: Создает список строк, каждая из которых содержит имя параметра и его тип.
4.  **Объединение параметров**: Объединяет список параметров в строку, разделенную запятыми.
5.  **Формирование строки параметров**: Формирует строку, содержащую информацию о поддержке параметров, включая имя файла и список параметров.

**Примеры**:

```python
print(params)