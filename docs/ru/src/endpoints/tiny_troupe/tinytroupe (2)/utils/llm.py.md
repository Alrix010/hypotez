# Модуль для работы с большими языковыми моделями (LLM)
## Обзор

Модуль предоставляет набор утилит для взаимодействия с большими языковыми моделями (LLM), такими как OpenAI и Google Gemini.
Он включает в себя функции для составления входных сообщений для модели, извлечения информации из ответов модели, управления повторными попытками при ошибках, а также подготовки шаблонов для запросов.

## Подробнее

Модуль содержит функции для:
-   Композиции сообщений для LLM на основе шаблонов.
-   Декоратора для превращения функций в LLM-функции.
-   Извлечения JSON и кодовых блоков из текста.
-   Повторных попыток выполнения функций при возникновении определенных исключений.
-   Добавления переменных для шаблонов, связанных с ответственностью ИИ (RAI).
-   Усечения длинных текстов для соответствия ограничениям моделей.

## Функции

### `compose_initial_LLM_messages_with_templates`

**Назначение**: Формирует начальные сообщения для вызова LLM модели, предполагая наличие системного (общее описание задачи) и опционального пользовательского сообщения (специфическое описание задачи). Сообщения формируются с использованием указанных шаблонов и конфигураций рендеринга.

**Параметры**:

-   `system_template_name` (str): Имя файла шаблона для системного сообщения.
-   `user_template_name` (str, optional): Имя файла шаблона для пользовательского сообщения. По умолчанию `None`.
-   `base_module_folder` (str, optional): Базовая папка модуля, используемая для поиска шаблонов. По умолчанию `None`.
-   `rendering_configs` (dict, optional): Словарь с конфигурациями для рендеринга шаблонов. По умолчанию `{}`.

**Возвращает**:

-   `list`: Список сообщений, где каждое сообщение представлено словарем с ключами `"role"` (роль отправителя, например, `"system"` или `"user"`) и `"content"` (текст сообщения).

**Как работает функция**:

1.  Определяет путь к папке с шаблонами, используя `base_module_folder` или значение по умолчанию `"../prompts/"`.
2.  Формирует полные пути к файлам шаблонов системного и пользовательского сообщений.
3.  Создает список `messages`, который будет содержать сообщения для LLM.
4.  Добавляет системное сообщение, рендеринг которого выполняется с помощью библиотеки `chevron` и переданных `rendering_configs`.
5.  Если указан `user_template_name`, добавляет пользовательское сообщение, рендеринг которого также выполняется с использованием `chevron` и `rendering_configs`.
6.  Возвращает список `messages`.

**Примеры**:

```python
messages = compose_initial_LLM_messages_with_templates(
    system_template_name="system_prompt.md",
    user_template_name="user_prompt.md",
    rendering_configs={"task": "translate to french"}
)
print(messages)
```

### `llm`

**Назначение**: Декоратор, преобразующий декорируемую функцию в функцию, основанную на LLM. Декорируемая функция должна возвращать строку (инструкцию для LLM), или параметры функции будут использованы в качестве инструкции для LLM. Ответ LLM приводится к аннотированному типу возвращаемого значения функции, если он присутствует.

**Параметры**:

-   `model_overrides` (keyword arguments): Переопределения параметров модели LLM, такие как `model`, `temperature`, `max_tokens`.

**Как работает функция**:

1.  Внутренняя функция `decorator` принимает функцию `func` в качестве аргумента.
2.  Внутри `decorator` определяется функция `wrapper`, которая оборачивает исходную функцию `func`.
3.  При вызове `wrapper` сначала вызывается исходная функция `func` с переданными аргументами и ключевыми словами.
4.  Если результат вызова `func` является строкой, она используется как `user_prompt` для LLM. В противном случае параметры функции используются для формирования `user_prompt`.
5.  Создается объект `LLMRequest` с системным сообщением, пользовательским сообщением, типом возвращаемого значения и переопределениями параметров модели.
6.  Вызывается метод `call` объекта `LLMRequest` для получения ответа от LLM.
7.  Возвращается результат вызова `llm_req.call()`.

**Примеры**:

```python
@llm(model="gpt-4-0613", temperature=0.5, max_tokens=100)
def joke():
    """Tell me a joke."""
    return "Tell me a joke."

print(joke())
```

### `extract_json`

**Назначение**: Извлекает JSON объект из строки, игнорируя любой текст до первой открывающей фигурной скобки `{` или квадратной скобки `[`, а также любые Markdown теги открытия (``\`json) или закрытия (``\`).

**Параметры**:

-   `text` (str): Строка, из которой нужно извлечь JSON.

**Возвращает**:

-   `dict`: Словарь, представляющий извлеченный JSON объект. Возвращает пустой словарь в случае ошибки.

**Как работает функция**:

1.  Удаляет любой текст до первой открывающей фигурной или квадратной скобки, используя регулярное выражение.
2.  Удаляет любой текст после последней закрывающей фигурной или квадратной скобки, используя регулярное выражение.
3.  Удаляет недопустимые escape-последовательности, заменяя `\\\'` на `'` и `\\,` на `,`.
4.  Парсит строку как JSON объект с помощью `json.loads(text, strict=False)`, где `strict=False` позволяет корректно обрабатывать новые строки, табы и другие специальные символы.
5.  Возвращает распарсенный JSON объект. В случае возникновения исключения логирует ошибку и возвращает пустой словарь.

**Примеры**:

```python
json_string = "```json { 'name': 'John', 'age': 30 } ```"
data = extract_json(json_string)
print(data)  # Output: {'name': 'John', 'age': 30}
```

### `extract_code_block`

**Назначение**: Извлекает блок кода из строки, игнорируя любой текст до первого открытия тройных обратных кавычек (`````) и любой текст после закрытия тройных обратных кавычек.

**Параметры**:

-   `text` (str): Строка, из которой нужно извлечь блок кода.

**Возвращает**:

-   `str`: Строка, представляющая извлеченный блок кода. Возвращает пустую строку в случае ошибки.

**Как работает функция**:

1.  Удаляет любой текст до первого открытия тройных обратных кавычек, используя регулярное выражение.
2.  Удаляет любой текст после последнего закрытия тройных обратных кавычек, используя регулярное выражение.
3.  Возвращает извлеченный блок кода.

**Примеры**:

```python
code_string = "```python def hello(): print('Hello, world!') ```"
code = extract_code_block(code_string)
print(code)  # Output: ```python def hello(): print('Hello, world!') ```
```

### `repeat_on_error`

**Назначение**: Декоратор, который повторяет вызов указанной функции, если происходит исключение из указанного списка, до указанного количества повторных попыток. Если количество повторных попыток превышено, исключение поднимается. Если исключение не возникает, функция возвращается нормально.

**Параметры**:

-   `retries` (int): Количество повторных попыток.
-   `exceptions` (list): Список классов исключений, которые нужно перехватывать.

**Как работает функция**:

1.  Внутренняя функция `decorator` принимает функцию `func` в качестве аргумента.
2.  Внутри `decorator` определяется функция `wrapper`, которая оборачивает исходную функцию `func`.
3.  При вызове `wrapper` выполняется цикл `for` от `0` до `retries - 1`.
4.  Внутри цикла `try` вызывается исходная функция `func` с переданными аргументами и ключевыми словами. Если вызов успешен, функция возвращает результат.
5.  Если возникает исключение, которое находится в списке `exceptions`, оно перехватывается.
6.  В случае перехвата исключения, логируется сообщение об ошибке с помощью `logger.debug`.
7.  Если это последняя попытка (i == retries - 1), исключение поднимается.
8.  В противном случае логируется сообщение о повторной попытке, и цикл продолжается.

**Примеры**:

```python
@repeat_on_error(retries=3, exceptions=[ValueError, TypeError])
def risky_function(x):
    if x < 0:
        raise ValueError("x cannot be negative")
    return 10 / x
```

### `add_rai_template_variables_if_enabled`

**Назначение**: Добавляет переменные шаблона RAI (Responsible AI) в указанный словарь, если включены соответствующие параметры в файле конфигурации.

**Параметры**:

-   `template_variables` (dict): Словарь переменных шаблона, в который нужно добавить переменные RAI.

**Возвращает**:

-   `dict`: Обновленный словарь переменных шаблона.

**Как работает функция**:

1.  Импортирует модуль `config` из `tinytroupe`, чтобы избежать циклического импорта.
2.  Считывает значения параметров `RAI_HARMFUL_CONTENT_PREVENTION` и `RAI_COPYRIGHT_INFRINGEMENT_PREVENTION` из файла конфигурации.
3.  Если `RAI_HARMFUL_CONTENT_PREVENTION` включен, считывает содержимое файла `prompts/rai_harmful_content_prevention.md` и добавляет его в словарь `template_variables` под ключом `'rai_harmful_content_prevention'`. В противном случае устанавливает значение `None`.
4.  Аналогично, если `RAI_COPYRIGHT_INFRINGEMENT_PREVENTION` включен, считывает содержимое файла `prompts/rai_copyright_infringement_prevention.md` и добавляет его в словарь `template_variables` под ключом `'rai_copyright_infringement_prevention'`. В противном случае устанавливает значение `None`.
5.  Возвращает обновленный словарь `template_variables`.

**Примеры**:

```python
template_vars = {}
updated_vars = add_rai_template_variables_if_enabled(template_vars)
print(updated_vars)
```

### `truncate_actions_or_stimuli`

**Назначение**: Усекает содержимое действий или стимулов до указанной максимальной длины. Не изменяет исходный список.

**Параметры**:

-   `list_of_actions_or_stimuli` (Collection\[dict]): Список действий или стимулов для усечения.
-   `max_content_length` (int): Максимальная длина содержимого.

**Возвращает**:

-   `Collection[str]`: Усеченный список действий или стимулов. Это новый список, а не ссылка на исходный список, чтобы избежать неожиданных побочных эффектов.

**Как работает функция**:

1.  Создает глубокую копию списка `list_of_actions_or_stimuli`, чтобы избежать изменения исходного списка.
2.  Итерируется по элементам в клонированном списке.
3.  Для каждого элемента проверяет наличие ключа `"content"`.
4.  Если ключ `"content"` присутствует, проверяет наличие ключей `"action"`, `"stimulus"` или `"stimuli"` в содержимом сообщения.
5.  Если найдены ключи `"action"` или `"stimulus"`, проверяет наличие ключа `"content"` внутри них и усекает его значение до `max_content_length` с использованием функции `break_text_at_length`.
6.  Если найден ключ `"stimuli"`, итерируется по элементам списка стимулов и усекает значение ключа `"content"` каждого стимула до `max_content_length`.
7.  Возвращает клонированный список с усеченным содержимым.

**Примеры**:

```python
actions = [{"role": "user", "content": {"action": {"content": "This is a very long action."}}}]
truncated_actions = truncate_actions_or_stimuli(actions, 10)
print(truncated_actions)