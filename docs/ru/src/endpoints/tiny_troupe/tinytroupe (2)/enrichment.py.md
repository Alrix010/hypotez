# Модуль для обогащения контента с использованием LLM
## Обзор

Модуль `enrichment.py` содержит класс `TinyEnricher`, который используется для обогащения текстового контента с использованием больших языковых моделей (LLM) на основе заданных требований и контекстной информации. Класс предоставляет функциональность для составления запросов к LLM, получения и обработки результатов.

## Подробнее

Этот модуль предназначен для интеграции с другими частями проекта, где требуется автоматическое обогащение контента, например, добавление дополнительной информации или преобразование текста в соответствии с определенными критериями. Он использует шаблоны mustache для формирования запросов к LLM и включает механизмы для кэширования и повторного использования контекстной информации.

## Классы

### `TinyEnricher`

**Описание**: Класс `TinyEnricher` предоставляет методы для обогащения контента с использованием больших языковых моделей (LLM).

**Принцип работы**:
1.  При инициализации класса определяется, будет ли использоваться предыдущий контекст. Также создается пустой кэш контекста `context_cache`.
2.  Метод `enrich_content` принимает требования, контент, тип контента и контекстную информацию.
3.  Составляет сообщения для LLM с использованием шаблонов mustache.
4.  Отправляет запрос в LLM и получает ответ.
5.  Извлекает блок кода из ответа LLM и возвращает его.

**Аттрибуты**:

-   `use_past_results_in_context` (bool): Определяет, использовать ли предыдущие результаты в контексте. По умолчанию `False`.
-   `context_cache` (list): Кэш для хранения контекстной информации.

**Методы**:

-   `enrich_content()`: Обогащает предоставленный контент с использованием LLM.

## Функции

### `enrich_content`

```python
def enrich_content(self, requirements: str, content: str, content_type: str = None, context_info: str = "", context_cache: list = None, verbose: bool = False) -> str | None:
    """ Функция обогащает предоставленный контент с использованием LLM.

    Args:
        requirements (str): Требования к обогащению контента.
        content (str): Контент, который необходимо обогатить.
        content_type (str, optional): Тип контента. По умолчанию `None`.
        context_info (str, optional): Контекстная информация. По умолчанию "".
        context_cache (list, optional): Кэш контекстной информации. По умолчанию `None`.
        verbose (bool, optional): Флаг для вывода отладочной информации. По умолчанию `False`.

    Returns:
        str | None: Обогащенный контент или `None`, если обогащение не удалось.
    """
```

**Назначение**: Обогащает предоставленный контент с использованием больших языковых моделей (LLM) на основе заданных требований и контекстной информации.

**Параметры**:

-   `requirements` (str): Требования к обогащению контента.
-   `content` (str): Контент, который необходимо обогатить.
-   `content_type` (str, optional): Тип контента. По умолчанию `None`.
-   `context_info` (str, optional): Контекстная информация. По умолчанию "".
-   `context_cache` (list, optional): Кэш контекстной информации. По умолчанию `None`.
-   `verbose` (bool, optional): Флаг для вывода отладочной информации. По умолчанию `False`.

**Возвращает**:

-   `str | None`: Обогащенный контент или `None`, если обогащение не удалось.

**Как работает функция**:

1.  **Подготовка данных**: Функция принимает на вход контент, требования к нему, тип контента, контекстную информацию и кэш контекста.
2.  **Компоновка сообщений**: Используется функция `utils.compose_initial_LLM_messages_with_templates` для создания сообщений, которые будут отправлены в LLM.  Эта функция использует шаблоны mustache для формирования системного и пользовательского сообщений на основе переданных параметров.
3.  **Отправка запроса в LLM**: Функция `openai_utils.client().send_message` отправляет скомпонованные сообщения в LLM для получения ответа. Параметр `temperature` определяет случайность ответов LLM.
4.  **Обработка ответа**: Извлекается блок кода из ответа LLM с использованием функции `utils.extract_code_block`. Если ответ отсутствует, возвращается `None`.
5.  **Логирование**: В процессе работы функции ведется отладочное логирование с использованием модуля `logger`.

```text
    Начало
    ↓
    → Формирование параметров для рендеринга (rendering_configs)
    ↓
    → Компоновка сообщений с использованием шаблонов mustache (compose_initial_LLM_messages_with_templates)
    ↓
    → Отправка сообщения в LLM (openai_utils.client().send_message)
    ↓
    → Извлечение блока кода из ответа LLM (extract_code_block)
    ↓
    Конец
```

**Примеры**:

Пример 1: Обогащение контента с минимальными параметрами.

```python
enricher = TinyEnricher()
requirements = "Добавить в текст больше деталей."
content = "Это простой текст."
enriched_content = enricher.enrich_content(requirements, content)
if enriched_content:
    print(f"Обогащенный контент: {enriched_content}")
```

Пример 2: Обогащение контента с указанием типа контента и контекстной информации.

```python
enricher = TinyEnricher()
requirements = "Сделать текст более формальным."
content = "Привет, это текст."
content_type = "email"
context_info = "Предыдущая переписка с клиентом."
enriched_content = enricher.enrich_content(requirements, content, content_type, context_info)
if enriched_content:
    print(f"Обогащенный контент: {enriched_content}")
```