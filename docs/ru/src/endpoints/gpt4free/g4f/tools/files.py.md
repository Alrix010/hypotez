# Модуль для работы с файлами
## \file hypotez/src/endpoints/gpt4free/g4f/tools/files.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
Модуль содержит функции для безопасной обработки имен файлов, определения поддерживаемых типов файлов,
чтения содержимого различных форматов файлов (текстовые, PDF, DOCX, ODT, EPUB, XLSX, HTML, ZIP),
кэширования содержимого файлов, разделения файлов на части, извлечения ссылок из HTML и загрузки файлов из интернета.
"""

## Обзор

Этот модуль предоставляет набор инструментов для работы с файлами различных форматов, включая извлечение текста,
кэширование и разделение файлов на части. Он также включает функции для загрузки файлов из интернета и
извлечения ссылок из HTML-контента.

## Подробнее

Модуль предназначен для обработки и извлечения информации из файлов различных типов, используемых в проекте `hypotez`.
Он обеспечивает безопасную обработку имен файлов, определяет поддерживаемые типы файлов и предоставляет функции для
чтения содержимого файлов различных форматов. Кроме того, модуль включает функции для кэширования содержимого файлов,
разделения файлов на части, извлечения ссылок из HTML и загрузки файлов из интернета.

## Функции

### `secure_filename`

**Назначение**: Обеспечивает безопасное создание имени файла, удаляя небезопасные символы.

**Параметры**:
- `filename` (str): Имя файла для обработки.

**Возвращает**:
- `str`: Безопасное имя файла.

**Как работает функция**:
Функция `secure_filename` принимает имя файла в качестве входных данных и выполняет следующие действия:
1. Проверяет, не является ли имя файла `None`, и возвращает `None`, если это так.
2. Заменяет все символы, кроме букв, цифр, основных знаков препинания и символов Unicode, символом подчеркивания `_`.
3. Удаляет пробелы в начале и конце имени файла.
4. Обрезает имя файла до 100 символов.
5. Удаляет символы ".", ",", "_", "-" и "+" в начале и конце имени файла.
6. Возвращает обработанное имя файла.

**Примеры**:

```python
filename = "Пример названия файла.txt"
secure_filename(filename)  # Результат: "Пример_названия_файла.txt"

filename = "test/../../example.txt"
secure_filename(filename)  # Результат: "test___example.txt"
```

### `supports_filename`

**Назначение**: Проверяет, поддерживается ли указанный тип файла для обработки.

**Параметры**:
- `filename` (str): Имя файла для проверки.

**Возвращает**:
- `bool`: `True`, если файл поддерживается, иначе `False`.

**Вызывает исключения**:
- `MissingRequirementsError`: Если отсутствуют необходимые библиотеки для обработки указанного типа файла.

**Как работает функция**:
Функция `supports_filename` принимает имя файла в качестве входных данных и выполняет следующие действия:
1. Проверяет расширение файла и наличие необходимых библиотек для его обработки.
2. Если файл является PDF, проверяет наличие библиотек `pypdf2`, `pdfplumber` или `pdfminer`.
3. Если файл является DOCX, проверяет наличие библиотек `docx` или `docx2txt`.
4. Если файл является ODT, проверяет наличие библиотеки `odfpy`.
5. Если файл является EPUB, проверяет наличие библиотеки `ebooklib`.
6. Если файл является XLSX, проверяет наличие библиотеки `openpyxl`.
7. Если файл является HTML, проверяет наличие библиотеки `beautifulsoup4`.
8. Если файл является ZIP, возвращает `True`.
9. Если файл имеет расширение, входящее в список `PLAIN_FILE_EXTENSIONS`, возвращает `True`.
10. Если ни одно из условий не выполнено, возвращает `False`.
11. Если отсутствуют необходимые библиотеки, вызывает исключение `MissingRequirementsError`.

**Примеры**:

```python
filename = "example.pdf"
supports_filename(filename)  # Результат: True, если установлена хотя бы одна из библиотек pypdf2, pdfplumber или pdfminer

filename = "example.docx"
supports_filename(filename)  # Результат: True, если установлена хотя бы одна из библиотек docx или docx2txt
```

### `get_bucket_dir`

**Назначение**: Формирует путь к директории bucket на основе заданных параметров.

**Параметры**:
- `*parts`: Переменное количество аргументов, представляющих части пути.

**Возвращает**:
- `str`: Полный путь к директории bucket.

**Как работает функция**:
Функция `get_bucket_dir` принимает переменное количество аргументов, представляющих части пути к директории bucket.
Она объединяет эти части с использованием функции `os.path.join` и применяет функцию `secure_filename` к каждой части,
чтобы обеспечить безопасность имени файла. Затем она возвращает полный путь к директории bucket.

**Примеры**:

```python
get_bucket_dir("bucket1", "file.txt")  # Результат: "<путь_к_cookies>/buckets/bucket1/file.txt"
```

### `get_buckets`

**Назначение**: Получает список директорий bucket.

**Параметры**:
- Нет

**Возвращает**:
- `list[str] | None`: Список имен директорий bucket или `None`, если директория не существует.

**Как работает функция**:
Функция `get_buckets` пытается получить список директорий в каталоге "buckets". Если каталог "buckets" существует,
она возвращает список имен подкаталогов. Если каталог не существует или возникает ошибка ОС, она возвращает `None`.

**Примеры**:

```python
get_buckets()  # Возвращает список директорий типа: ['bucket1', 'bucket2']
```

### `spacy_refine_chunks`

**Назначение**: Улучшает разделение текста на фрагменты с использованием библиотеки `spacy`.

**Параметры**:
- `source_iterator`: Итератор, предоставляющий исходные текстовые фрагменты.

**Возвращает**:
- `Generator[str, None, None]`: Генератор, возвращающий улучшенные текстовые фрагменты.

**Вызывает исключения**:
- `MissingRequirementsError`: Если библиотека `spacy` не установлена.

**Как работает функция**:
Функция `spacy_refine_chunks` принимает итератор исходных текстовых фрагментов и выполняет следующие действия:
1. Проверяет, установлена ли библиотека `spacy`. Если нет, вызывает исключение `MissingRequirementsError`.
2. Загружает модель `en_core_web_sm` из библиотеки `spacy`.
3. Для каждого фрагмента текста создает объект `Doc` с использованием модели `nlp`.
4. Извлекает предложения из объекта `Doc` и сортирует их по длине текста в обратном порядке.
5. Возвращает два самых длинных предложения.

**Внутренние функции**:
- Нет

**Примеры**:

```python
source_iterator = ["Это первый фрагмент текста.", "Это второй фрагмент текста."]
refined_chunks = spacy_refine_chunks(source_iterator)
for chunk in refined_chunks:
    print(chunk)  # Выводит улучшенные фрагменты текста
```

### `get_filenames`

**Назначение**: Получает список имен файлов из файла `FILE_LIST` в указанной директории.

**Параметры**:
- `bucket_dir` (Path): Путь к директории bucket.

**Возвращает**:
- `list[str]`: Список имен файлов.

**Как работает функция**:
Функция `get_filenames` принимает путь к директории bucket и выполняет следующие действия:
1. Формирует путь к файлу `FILE_LIST` в указанной директории.
2. Проверяет, существует ли файл `FILE_LIST`.
3. Если файл существует, открывает его для чтения и считывает список имен файлов.
4. Удаляет пробелы в начале и конце каждой строки.
5. Возвращает список имен файлов.
6. Если файл не существует, возвращает пустой список.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
filenames = get_filenames(bucket_dir)
print(filenames)  # Выводит список имен файлов
```

### `stream_read_files`

**Назначение**: Читает содержимое файлов из указанного списка и возвращает его в виде итератора.

**Параметры**:
- `bucket_dir` (Path): Путь к директории, содержащей файлы.
- `filenames` (list): Список имен файлов для чтения.
- `delete_files` (bool): Если `True`, файлы удаляются после прочтения. По умолчанию `False`.

**Возвращает**:
- `Iterator[str]`: Итератор, возвращающий содержимое файлов.

**Как работает функция**:
Функция `stream_read_files` принимает путь к директории bucket, список имен файлов и флаг удаления файлов.
Для каждого имени файла в списке она выполняет следующие действия:
1. Формирует путь к файлу.
2. Проверяет, существует ли файл и не является ли он пустым.
3. Если файл является ZIP-архивом, извлекает все файлы из архива и рекурсивно вызывает функцию `stream_read_files` для каждого извлеченного файла. После извлечения файлов и их обработки, удаляет извлеченные файлы и сам ZIP-архив, если установлен флаг `delete_files`.
4. Если файл является PDF, DOCX, ODT, EPUB, XLSX или HTML, извлекает текст из файла с использованием соответствующих библиотек и возвращает его.
5. Если файл имеет расширение, входящее в список `PLAIN_FILE_EXTENSIONS`, считывает содержимое файла и возвращает его.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
filenames = ["file1.txt", "file2.pdf"]
for content in stream_read_files(bucket_dir, filenames):
    print(content)  # Выводит содержимое каждого файла
```

### `cache_stream`

**Назначение**: Кэширует содержимое потока данных в файл и возвращает итератор для чтения этого кэша.

**Параметры**:
- `stream` (Iterator[str]): Итератор, предоставляющий поток данных для кэширования.
- `bucket_dir` (Path): Путь к директории, где будет храниться кэш.

**Возвращает**:
- `Iterator[str]`: Итератор, возвращающий содержимое кэшированного файла.

**Как работает функция**:
Функция `cache_stream` принимает итератор потока данных и путь к директории bucket.
Она выполняет следующие действия:
1. Формирует путь к файлу кэша `PLAIN_CACHE` в указанной директории.
2. Формирует путь к временному файлу.
3. Если файл кэша существует, считывает его содержимое и возвращает его в виде итератора.
4. Если файл кэша не существует, открывает временный файл для записи и записывает в него содержимое потока данных.
5. Переименовывает временный файл в файл кэша.
6. Возвращает итератор для чтения кэшированного файла.

**Примеры**:

```python
stream = ["chunk1", "chunk2", "chunk3"]
bucket_dir = Path("/path/to/bucket")
for chunk in cache_stream(stream, bucket_dir):
    print(chunk)  # Выводит содержимое кэшированного файла
```

### `is_complete`

**Назначение**: Проверяет, является ли переданная строка полным блоком данных.

**Параметры**:
- `data` (str): Строка для проверки.

**Возвращает**:
- `bool`: `True`, если строка является полным блоком данных, иначе `False`.

**Как работает функция**:
Функция `is_complete` проверяет, заканчивается ли строка `data` последовательностью символов `\n\`\`\`\n\n` и является ли количество символов ``` четным числом.
Если оба условия выполняются, функция возвращает `True`, иначе возвращает `False`.

**Примеры**:

```python
data = "Это полный блок данных.\n\`\`\`\n\n"
is_complete(data)  # Результат: True

data = "Это неполный блок данных.\n\`\`\`"
is_complete(data)  # Результат: False
```

### `read_path_chunked`

**Назначение**: Читает файл по частям (chunks) и возвращает содержимое каждой части в виде итератора.

**Параметры**:
- `path` (Path): Путь к файлу.

**Возвращает**:
- `Generator[str, None, None]`: Итератор, возвращающий содержимое файла по частям.

**Как работает функция**:
Функция `read_path_chunked` принимает путь к файлу и выполняет следующие действия:
1. Открывает файл для чтения в кодировке UTF-8.
2. Считывает файл построчно и накапливает содержимое в буфере.
3. Если размер буфера превышает 4096 байт, проверяет, является ли буфер полным блоком данных.
4. Если буфер является полным блоком данных или его размер превышает 8192 байта, возвращает содержимое буфера и очищает его.
5. Если после завершения чтения файла в буфере осталось содержимое, возвращает его.

**Примеры**:

```python
path = Path("/path/to/file.txt")
for chunk in read_path_chunked(path):
    print(chunk)  # Выводит содержимое файла по частям
```

### `read_bucket`

**Назначение**: Читает содержимое файлов кэша из указанной директории bucket.

**Параметры**:
- `bucket_dir` (Path): Путь к директории bucket.

**Возвращает**:
- `Generator[str, None, None]`: Итератор, возвращающий содержимое файлов кэша.

**Как работает функция**:
Функция `read_bucket` принимает путь к директории bucket и выполняет следующие действия:
1. Формирует пути к файлам кэша `PLAIN_CACHE` и `spacy_0001.cache` в указанной директории.
2. Если файл `spacy_0001.cache` не существует, а файл `PLAIN_CACHE` существует, считывает содержимое файла `PLAIN_CACHE` и возвращает его.
3. Для каждого индекса от 1 до 999 формирует пути к файлам кэша `spacy_{idx:04d}.cache` и `plain_{idx:04d}.cache`.
4. Если файл `spacy_{idx:04d}.cache` существует, считывает его содержимое и возвращает его.
5. Если файл `plain_{idx:04d}.cache` существует, считывает его содержимое и возвращает его.
6. Если ни один из файлов не существует, завершает работу.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
for content in read_bucket(bucket_dir):
    print(content)  # Выводит содержимое файлов кэша
```

### `stream_read_parts_and_refine`

**Назначение**: Читает части файлов и уточняет их содержимое с использованием библиотеки `spacy`.

**Параметры**:
- `bucket_dir` (Path): Путь к директории bucket.
- `delete_files` (bool): Если `True`, части файлов удаляются после обработки. По умолчанию `False`.

**Возвращает**:
- `Generator[str, None, None]`: Итератор, возвращающий уточненные части файлов.

**Как работает функция**:
Функция `stream_read_parts_and_refine` принимает путь к директории bucket и флаг удаления файлов.
Она выполняет следующие действия:
1. Формирует пути к файлам кэша `PLAIN_CACHE`, `spacy_0001.cache` и `plain_0001.cache` в указанной директории.
2. Если файл `spacy_0001.cache` не существует и файл `plain_0001.cache` не существует, а файл `PLAIN_CACHE` существует, вызывает функцию `split_file_by_size_and_newline` для разделения файла `PLAIN_CACHE` на части.
3. Для каждого индекса от 1 до 999 формирует пути к файлам кэша `plain_{idx:04d}.cache` и `spacy_{idx:04d}.cache`.
4. Если файл `spacy_{idx:04d}.cache` существует, считывает его содержимое и возвращает его.
5. Если файл `plain_{idx:04d}.cache` не существует, завершает работу.
6. Открывает временный файл для записи.
7. Для каждой части файла вызывает функцию `spacy_refine_chunks` для уточнения содержимого.
8. Записывает уточненное содержимое во временный файл и возвращает его.
9. Переименовывает временный файл в файл `spacy_{idx:04d}.cache`.
10. Если установлен флаг `delete_files`, удаляет часть файла.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
for chunk in stream_read_parts_and_refine(bucket_dir):
    print(chunk)  # Выводит уточненные части файлов
```

### `split_file_by_size_and_newline`

**Назначение**: Разделяет файл на части заданного размера, разделяя только по символам новой строки.

**Параметры**:
- `input_filename` (str): Путь к входному файлу.
- `output_dir` (str): Директория для сохранения выходных файлов.
- `chunk_size_bytes` (int): Желаемый размер каждой части в байтах. По умолчанию 1MB.

**Как работает функция**:
Функция `split_file_by_size_and_newline` принимает путь к входному файлу, директорию для сохранения выходных файлов и желаемый размер каждой части в байтах.
Она выполняет следующие действия:
1. Открывает входной файл для чтения в кодировке UTF-8.
2. Формирует префикс для имен выходных файлов.
3. Считывает файл построчно и накапливает содержимое в буфере.
4. Если размер буфера превышает `chunk_size_bytes`, проверяет, является ли буфер полным блоком данных.
5. Если буфер является полным блоком данных или его размер превышает `chunk_size_bytes * 2`, записывает содержимое буфера в выходной файл и очищает буфер.
6. После завершения чтения файла записывает оставшееся содержимое буфера в выходной файл.

**Примеры**:

```python
input_filename = "/path/to/input.txt"
output_dir = "/path/to/output"
split_file_by_size_and_newline(input_filename, output_dir)
```

### `get_filename`

**Назначение**: Извлекает имя файла из HTTP-ответа.

**Параметры**:
- `response` (ClientResponse): Объект HTTP-ответа.

**Возвращает**:
- `str | None`: Имя файла или `None`, если не удалось определить.

**Как работает функция**:
Функция `get_filename` принимает объект HTTP-ответа и пытается извлечь имя файла из заголовка `Content-Disposition`.
Если заголовок `Content-Disposition` присутствует, функция извлекает имя файла из его значения.
Если заголовок `Content-Disposition` отсутствует или не содержит имени файла, функция пытается извлечь имя файла из URL-адреса.
Если имя файла не удалось определить, функция возвращает `None`.

**Примеры**:

```python
response = await session.get("https://example.com/file.pdf")
filename = await get_filename(response)
print(filename)  # Выводит имя файла, если удалось определить
```

### `get_file_extension`

**Назначение**: Определяет расширение файла на основе HTTP-ответа.

**Параметры**:
- `response` (ClientResponse): Объект HTTP-ответа.

**Возвращает**:
- `str | None`: Расширение файла или `None`, если не удалось определить.

**Как работает функция**:
Функция `get_file_extension` принимает объект HTTP-ответа и пытается определить расширение файла на основе заголовка `Content-Type`.
Если заголовок `Content-Type` присутствует, функция определяет расширение файла на основе его значения.
Если заголовок `Content-Type` отсутствует, функция пытается определить расширение файла на основе URL-адреса.
Если расширение файла не удалось определить, функция возвращает `None`.

**Примеры**:

```python
response = await session.get("https://example.com/file.pdf")
extension = await get_file_extension(response)
print(extension)  # Выводит расширение файла, если удалось определить
```

### `read_links`

**Назначение**: Извлекает ссылки из HTML-контента.

**Параметры**:
- `html` (str): HTML-контент.
- `base` (str): Базовый URL для объединения относительных ссылок.

**Возвращает**:
- `set[str]`: Набор URL-адресов, извлеченных из HTML-контента.

**Как работает функция**:
Функция `read_links` принимает HTML-контент и базовый URL-адрес и выполняет следующие действия:
1. Создает объект `BeautifulSoup` для парсинга HTML-контента.
2. Выбирает основной контент HTML-страницы на основе CSS-селекторов.
3. Извлекает все ссылки из HTML-контента.
4. Объединяет относительные ссылки с базовым URL-адресом.
5. Возвращает набор URL-адресов.

**Примеры**:

```python
html = "<a href='/link1'>Link1</a><a href='https://example.com/link2'>Link2</a>"
base = "https://example.com"
links = read_links(html, base)
print(links)  # Выводит набор URL-адресов
```

### `download_urls`

**Назначение**: Загружает файлы по списку URL-адресов асинхронно.

**Параметры**:
- `bucket_dir` (Path): Директория для сохранения загруженных файлов.
- `urls` (list[str]): Список URL-адресов для загрузки.
- `max_depth` (int): Максимальная глубина рекурсии для загрузки HTML-страниц и извлечения ссылок. По умолчанию 0.
- `loading_urls` (set[str]): Набор URL-адресов, которые уже загружаются. По умолчанию пустой набор.
- `lock` (asyncio.Lock): Блокировка для синхронизации доступа к общим ресурсам. По умолчанию `None`.
- `delay` (int): Задержка между запросами в секундах. По умолчанию 3.
- `new_urls` (list[str]): Список новых URL-адресов, найденных во время загрузки HTML-страниц. По умолчанию пустой список.
- `group_size` (int): Количество URL-адресов для одновременной загрузки. По умолчанию 5.
- `timeout` (int): Время ожидания ответа от сервера в секундах. По умолчанию 10.
- `proxy` (Optional[str]): Прокси-сервер для использования при загрузке файлов. По умолчанию `None`.

**Возвращает**:
- `AsyncIterator[str]`: Асинхронный итератор, возвращающий имена загруженных файлов.

**Как работает функция**:
Функция `download_urls` принимает список URL-адресов и выполняет следующие действия:
1. Создает асинхронную сессию для выполнения HTTP-запросов.
2. Для каждого URL-адреса в списке выполняет следующие действия:
    - Загружает файл по URL-адресу.
    - Определяет имя файла на основе HTTP-ответа.
    - Проверяет, разрешено ли расширение файла.
    - Если файл является HTML-страницей и `max_depth` больше 0, извлекает ссылки из HTML-контента и добавляет их в список новых URL-адресов.
    - Сохраняет файл в указанной директории.
3. Рекурсивно вызывает функцию `download_urls` для загрузки новых URL-адресов.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
urls = ["https://example.com/file1.txt", "https://example.com/file2.pdf"]
async for filename in download_urls(bucket_dir, urls):
    print(filename)  # Выводит имена загруженных файлов
```

### `get_downloads_urls`

**Назначение**: Получает список URL-адресов для загрузки из файла `DOWNLOADS_FILE`.

**Параметры**:
- `bucket_dir` (Path): Директория, содержащая файл `DOWNLOADS_FILE`.
- `delete_files` (bool): Если `True`, файл `DOWNLOADS_FILE` удаляется после прочтения. По умолчанию `False`.

**Возвращает**:
- `Iterator[str]`: Итератор, возвращающий URL-адреса для загрузки.

**Как работает функция**:
Функция `get_downloads_urls` принимает путь к директории bucket и флаг удаления файлов.
Она выполняет следующие действия:
1. Формирует путь к файлу `DOWNLOADS_FILE` в указанной директории.
2. Проверяет, существует ли файл `DOWNLOADS_FILE`.
3. Если файл существует, открывает его для чтения и считывает JSON-данные.
4. Если установлен флаг `delete_files`, удаляет файл `DOWNLOADS_FILE`.
5. Для каждого элемента в JSON-данных извлекает URL-адреса для загрузки.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
for url in get_downloads_urls(bucket_dir):
    print(url)  # Выводит URL-адреса для загрузки
```

### `read_and_download_urls`

**Назначение**: Читает URL-адреса из файла загрузок и загружает файлы по этим URL-адресам.

**Параметры**:
- `bucket_dir` (Path): Директория, в которой хранятся загруженные файлы.
- `delete_files` (bool): Удалять ли файл загрузок после обработки. По умолчанию `False`.
- `event_stream` (bool): Генерировать ли поток событий для отслеживания прогресса. По умолчанию `False`.

**Как работает функция**:
Функция `read_and_download_urls` выполняет следующие действия:
1. Получает список URL-адресов из файла загрузок с помощью функции `get_downloads_urls`.
2. Открывает файл `FILE_LIST` в режиме добавления для записи имен загруженных файлов.
3. Для каждого URL-адреса в списке загружает файл с помощью функции `download_urls`.
4. Записывает имя загруженного файла в файл `FILE_LIST`.
5. Если `event_stream` имеет значение `True`, генерирует поток событий для отслеживания прогресса загрузки.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
for event in read_and_download_urls(bucket_dir, event_stream=True):
    print(event)  # Выводит события загрузки
```

### `async_read_and_download_urls`

**Назначение**: Асинхронно считывает URL-адреса из файла загрузок и загружает файлы по этим URL-адресам.

**Параметры**:
- `bucket_dir` (Path): Директория, в которой хранятся загруженные файлы.
- `delete_files` (bool): Удалять ли файл загрузок после обработки. По умолчанию `False`.
- `event_stream` (bool): Генерировать ли поток событий для отслеживания прогресса. По умолчанию `False`.

**Как работает функция**:
Функция `async_read_and_download_urls` выполняет следующие действия:
1. Получает список URL-адресов из файла загрузок с помощью функции `get_downloads_urls`.
2. Открывает файл `FILE_LIST` в режиме добавления для записи имен загруженных файлов.
3. Для каждого URL-адреса в списке асинхронно загружает файл с помощью функции `download_urls`.
4. Записывает имя загруженного файла в файл `FILE_LIST`.
5. Если `event_stream` имеет значение `True`, генерирует поток событий для отслеживания прогресса загрузки.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
async for event in async_read_and_download_urls(bucket_dir, event_stream=True):
    print(event)  # Выводит события загрузки
```

### `stream_chunks`

**Назначение**: Создает поток фрагментов текста из файлов в указанной директории.

**Параметры**:
- `bucket_dir` (Path): Путь к директории bucket.
- `delete_files` (bool): Если `True`, файлы удаляются после обработки. По умолчанию `False`.
- `refine_chunks_with_spacy` (bool): Если `True`, фрагменты текста уточняются с помощью библиотеки `spacy`. По умолчанию `False`.
- `event_stream` (bool): Если `True`, генерируется поток событий для отслеживания прогресса. По умолчанию `False`.

**Возвращает**:
- `Iterator[str]`: Итератор, возвращающий фрагменты текста.

**Как работает функция**:
Функция `stream_chunks` принимает путь к директории bucket, флаги удаления файлов, уточнения фрагментов и генерации потока событий.
Она выполняет следующие действия:
1. Если `refine_chunks_with_spacy` имеет значение `True`, вызывает функцию `stream_read_parts_and_refine` для чтения и уточнения фрагментов текста.
2. Если `refine_chunks_with_spacy` имеет значение `False`, вызывает функцию `stream_read_files` для чтения файлов и функцию `cache_stream` для кэширования содержимого.
3. Если `event_stream` имеет значение `True`, генерирует поток событий для отслеживания прогресса обработки.
4. Если установлен флаг `delete_files`, удаляет обработанные файлы.

**Примеры**:

```python
bucket_dir = Path("/path/to/bucket")
for chunk in stream_chunks(bucket_dir, refine_chunks_with_spacy=True, event_stream=True):
    print(chunk)  # Выводит фрагменты текста и события прогресса
```

### `get_streaming`

**Назначение**: Генерирует поток данных из файлов в указанной директории.

**Параметры**:
- `bucket_dir` (str): Путь к директории, содержащей файлы.
- `delete_files` (bool): Удалять ли файлы после обработки. По умолчанию `False`.
- `refine_chunks_with_spacy` (bool): Использовать ли `spacy` для уточнения фрагментов текста. По умолчанию `False`.
- `event_stream` (bool): Генерировать ли поток событий для отслеживания прогресса. По умолчанию `False`.

**Возвращает**:
- `Iterator[str]`: Итератор, генерирующий поток данных.

**Вызывает исключения**:
- `Exception`: Если во время обработки возникает ошибка, информация об ошибке включается в поток событий (если `event_stream` имеет значение `True`).

**Как работает функция**:
Функция `get_streaming` выполняет следующие действия:
1. Создает директорию bucket, если она не существует.
2. Генерирует поток данных из файла загрузок с помощью функции `read_and_download_urls`.
3. Генерирует поток фрагментов текста из файлов в директории bucket с помощью функции `stream_chunks`.
4. Если во время обработки возникает ошибка, информация об ошибке включается в поток событий (если `event_stream` имеет значение `True`).

**Примеры**:

```python
bucket_dir = "/path/to/bucket"
for chunk in get_streaming(bucket_dir, event_stream=True):
    print(chunk)  # Выводит фрагменты текста и события прогресса
```

### `get_async_streaming`

**Назначение**: Асинхронно генерирует поток данных из файлов в указанной директории.

**Параметры**:
- `bucket_dir` (str): Путь к директории, содержащей файлы.
- `delete_files` (bool): Удалять ли файлы после обработки. По умолчанию `False`.
- `refine_chunks_with_spacy` (bool): Использовать ли `spacy` для уточнения фрагментов текста. По умолчанию `False`.
- `event_stream` (bool): Генерировать ли поток событий для отслеживания прогресса. По умолчанию `False`.

**Возвращает**:
- `Iterator[str]`: Итератор, генерирующий поток данных.

**Вызывает исключения**:
- `Exception`: Если во время обработки возникает ошибка, информация об ошибке включается в поток событий (если `event_stream` имеет значение `True`).

**Как работает функция**:
Функция `get_async_streaming` выполняет следующие действия:
1. Создает директорию bucket, если она не существует.
2. Асинхронно генерирует поток данных из файла загрузок с помощью функции `async_read_and_download_urls`.
3. Генерирует поток фрагментов текста из файлов в директории bucket с помощью функции `stream_chunks`.
4. Если во время обработки возникает ошибка, информация об ошибке включается в поток событий (если `event_stream` имеет значение `True`).

**Примеры**:

```python
bucket_dir = "/path/to/bucket"
for chunk in get_async_streaming(bucket_dir, event_stream=True):
    print(chunk)  # Выводит фрагменты текста и события прогресса
```