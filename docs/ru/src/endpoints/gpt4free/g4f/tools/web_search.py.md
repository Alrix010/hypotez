# Модуль для выполнения веб-поиска с использованием DuckDuckGo Search API
## Обзор

Модуль `web_search.py` предоставляет функциональность для выполнения веб-поиска с использованием DuckDuckGo Search API. Он включает в себя функции для запроса поисковых результатов, извлечения текста из веб-страниц и форматирования результатов для использования в качестве контекста для больших языковых моделей.
Модуль предназначен для интеграции с другими компонентами проекта `hypotez`, предоставляя актуальную информацию из интернета для улучшения ответов и выполнения задач.

## Подробнее
Модуль выполняет следующие основные задачи:

1. **Поиск информации**: Использует DuckDuckGo Search API для получения релевантных результатов на основе запроса пользователя.
2. **Извлечение текста**: Извлекает текст из веб-страниц, чтобы предоставить подробную информацию в дополнение к поисковым сниппетам.
3. **Кэширование**: Кэширует результаты поиска и извлеченный текст, чтобы уменьшить задержки и нагрузку на сеть.
4. **Форматирование результатов**: Форматирует результаты поиска в удобный для чтения формат, включая заголовки, текст и ссылки на источники.

Этот модуль является важной частью системы, поскольку позволяет языковым моделям получать доступ к актуальной информации из интернета, что делает ответы более полными и точными. Он также включает механизмы обработки ошибок и исключений, что обеспечивает стабильность и надежность работы.

## Классы

### `SearchResults`
Описание: Класс предназначен для хранения и обработки результатов веб-поиска.

**Атрибуты**:
- `results` (list): Список объектов `SearchResultEntry`, представляющих отдельные результаты поиска.
- `used_words` (int): Количество использованных слов в результатах поиска.

**Методы**:
- `from_dict(data: dict)`: Создает экземпляр класса из словаря.
- `__iter__()`: Возвращает итератор по результатам поиска.
- `__str__()`: Форматирует результаты поиска в виде строки.
- `__len__()` -> int: Возвращает количество результатов поиска.
- `get_sources()` -> Sources: Возвращает объект `Sources`, содержащий URL и заголовки результатов поиска.
- `get_dict()`: Преобразует объект в словарь.

### `SearchResultEntry`

**Описание**: Класс представляет собой отдельную запись результата веб-поиска.

**Атрибуты**:
- `title` (str): Заголовок результата поиска.
- `url` (str): URL результата поиска.
- `snippet` (str): Краткое описание результата поиска (сниппет).
- `text` (str, optional): Полный текст, извлеченный из веб-страницы (по умолчанию `None`).

**Методы**:
- `set_text(text: str)`: Устанавливает текст для результата поиска.
- `get_dict()`:  Преобразует объект в словарь.

## Функции

### `scrape_text`

```python
def scrape_text(html: str, max_words: int = None, add_source=True, count_images: int = 2) -> Iterator[str]:
    """
    Извлекает текст из HTML-кода веб-страницы, удаляя лишние элементы и форматируя результат.

    Args:
        html (str): HTML-код страницы для извлечения текста.
        max_words (int, optional): Максимальное количество слов для извлечения. По умолчанию `None` (без ограничений).
        add_source (bool): Флаг, указывающий, нужно ли добавлять источник в конце извлеченного текста.
        count_images (int): Количество изображений для извлечения.

    Returns:
        Iterator[str]: Итератор строк, содержащих извлеченный текст.

    Как работает функция:
    1. Преобразует HTML в объект BeautifulSoup для удобного парсинга.
    2. Выбирает основной контент страницы, используя CSS-селекторы для различных возможных контейнеров (main, .main-content-wrapper и т.д.).
    3. Удаляет нежелательные элементы, такие как глобальные элементы раскрытия информации (например, для Zdnet).
    4. Извлекает текст из различных элементов (заголовки, параграфы, списки и т.д.), разделяет его на строки и удаляет пустые строки.
    5. Ограничивает количество извлекаемых слов, если указано `max_words`.
    6. Добавляет ссылку на источник в конце извлеченного текста, если `add_source` установлен в `True`.

    A - Преобразование HTML в BeautifulSoup
    ↓
    B - Выбор основного контента страницы
    ↓
    C - Удаление нежелательных элементов
    ↓
    D - Извлечение текста из элементов
    ↓
    E - Ограничение количества слов
    ↓
    F - Добавление ссылки на источник

    Примеры:
    >>> html_content = "<html><body><h1>Заголовок</h1><p>Текст параграфа.</p></body></html>"
    >>> list(scrape_text(html_content, max_words=5))
    ['Заголовок ', 'Текст параграфа.']
    """
    ...
```

### `fetch_and_scrape`
```python
async def fetch_and_scrape(session: ClientSession, url: str, max_words: int = None, add_source: bool = False) -> str:
    """
    Асинхронно загружает HTML-код веб-страницы по URL и извлекает из него текст. Использует кэширование для повторного использования загруженных данных.

    Args:
        session (ClientSession): Асинхронная HTTP-сессия для выполнения запросов.
        url (str): URL веб-страницы для загрузки.
        max_words (int, optional): Максимальное количество слов для извлечения. По умолчанию `None` (без ограничений).
        add_source (bool): Флаг, указывающий, нужно ли добавлять источник в конце извлеченного текста.

    Returns:
        str: Извлеченный текст из веб-страницы или None в случае ошибки.

    Как работает функция:
    1. Формирует путь к файлу кэша на основе URL и текущей даты.
    2. Проверяет, существует ли кэшированный файл. Если да, возвращает его содержимое.
    3. Если кэшированного файла нет, выполняет GET-запрос к указанному URL.
    4. Извлекает текст из HTML-кода с помощью функции scrape_text.
    5. Сохраняет извлеченный текст в кэш.

    A - Формирование пути к файлу кэша
    ↓
    B - Проверка существования кэша
    ├── Да: Возврат содержимого кэша
    └── Нет: GET-запрос к URL
    ↓
    C - Извлечение текста из HTML
    ↓
    D - Сохранение текста в кэш

    Примеры:
    >>> import asyncio
    >>> from aiohttp import ClientSession
    >>> async def main():
    ...     async with ClientSession() as session:
    ...         text = await fetch_and_scrape(session, "https://example.com", max_words=10)
    ...         print(text)
    >>> asyncio.run(main())
    None
    """
    ...
```

### `search`

```python
async def search(query: str, max_results: int = 5, max_words: int = 2500, backend: str = "auto", add_text: bool = True, timeout: int = 5, region: str = "wt-wt") -> SearchResults:
    """
    Выполняет поиск в DuckDuckGo и возвращает результаты.

    Args:
        query (str): Поисковый запрос.
        max_results (int, optional): Максимальное количество результатов для возврата. По умолчанию 5.
        max_words (int, optional): Максимальное количество слов для извлечения из каждой страницы. По умолчанию 2500.
        backend (str, optional): Бэкенд для использования (auto, api, html). По умолчанию "auto".
        add_text (bool, optional): Флаг, указывающий, нужно ли извлекать текст из веб-страниц. По умолчанию True.
        timeout (int, optional): Время ожидания для HTTP-запросов в секундах. По умолчанию 5.
        region (str, optional): Регион для поиска. По умолчанию "wt-wt" (всемирный).

    Returns:
        SearchResults: Объект SearchResults, содержащий результаты поиска.

    Raises:
        MissingRequirementsError: Если отсутствуют необходимые библиотеки (duckduckgo-search, beautifulsoup4).

    Как работает функция:
    1. Проверяет наличие необходимых библиотек. Если их нет, вызывает исключение MissingRequirementsError.
    2. Выполняет поиск с использованием DuckDuckGo Search API.
    3. Если `add_text` установлен в `True`, извлекает текст из каждой веб-страницы.
    4. Форматирует результаты и возвращает объект SearchResults.

    A - Проверка наличия библиотек
    ├── Нет: Вызов исключения MissingRequirementsError
    └── Да: Выполнение поиска через DuckDuckGo
    ↓
    B - Извлечение текста (если add_text == True)
    ↓
    C - Форматирование результатов

    Примеры:
    >>> import asyncio
    >>> async def main():
    ...     results = await search("example query", max_results=3)
    ...     print(results)
    >>> asyncio.run(main())
    <__main__.SearchResults object at ...>
    """
    ...
```

### `do_search`

```python
async def do_search(prompt: str, query: str = None, instructions: str = DEFAULT_INSTRUCTIONS, **kwargs) -> tuple[str, Sources]:
    """
    Выполняет поиск и форматирует результаты для использования в подсказках для языковых моделей.

    Args:
        prompt (str): Исходный запрос пользователя.
        query (str, optional): Поисковый запрос. Если не указан, используется первая строка запроса пользователя.
        instructions (str, optional): Инструкции для языковой модели. По умолчанию DEFAULT_INSTRUCTIONS.
        **kwargs: Дополнительные аргументы для функции search.

    Returns:
        tuple[str, Sources]: Кортеж, содержащий отформатированный запрос и объект Sources.

    Как работает функция:
    1. Проверяет, нужно ли выполнять поиск на основе предоставленных аргументов.
    2. Если поисковый запрос не указан, использует первую строку запроса пользователя.
    3. Выполняет поиск с использованием функции search.
    4. Форматирует результаты поиска и объединяет их с инструкциями и запросом пользователя.
    5. Возвращает отформатированный запрос и объект Sources.

    A - Проверка необходимости поиска
    ├── Не нужно: Возврат исходного запроса
    └── Нужно: Определение поискового запроса
    ↓
    B - Выполнение поиска
    ↓
    C - Форматирование результатов
    ↓
    D - Объединение результатов с запросом и инструкциями

    Примеры:
    >>> import asyncio
    >>> async def main():
    ...     prompt, sources = await do_search("Tell me about example.com")
    ...     print(prompt)
    ...     print(sources)
    >>> asyncio.run(main())
    <Текст с результатами поиска>
    <src.endpoints.gpt4free.g4f.providers.response.Sources object at ...>
    """
    ...
```

### `get_search_message`

```python
def get_search_message(prompt: str, raise_search_exceptions=False, **kwargs) -> str:
    """
    Получает отформатированное сообщение поиска для использования в языковых моделях.

    Args:
        prompt (str): Исходный запрос пользователя.
        raise_search_exceptions (bool, optional): Флаг, указывающий, нужно ли вызывать исключения, связанные с поиском. По умолчанию False.
        **kwargs: Дополнительные аргументы для функции do_search.

    Returns:
        str: Отформатированное сообщение поиска.

    Как работает функция:
    1. Выполняет поиск с использованием функции do_search.
    2. Перехватывает исключения, связанные с поиском, и обрабатывает их.
    3. Возвращает отформатированное сообщение поиска.

    A - Выполнение поиска через do_search
    ↓
    B - Перехват исключений
    ├── Исключение: Логирование ошибки и возврат исходного запроса
    └── Нет исключения: Возврат отформатированного сообщения

    Примеры:
    >>> get_search_message("Tell me about example.com")
    <Текст с результатами поиска>
    """
    ...
```

### `spacy_get_keywords`

```python
def spacy_get_keywords(text: str):
    """
    Извлекает ключевые слова из текста с использованием библиотеки spaCy.

    Args:
        text (str): Текст для извлечения ключевых слов.

    Returns:
        list: Список ключевых слов.

    Как работает функция:
    1. Проверяет, установлена ли библиотека spaCy.
    2. Загружает языковую модель spaCy.
    3. Обрабатывает текст с использованием spaCy.
    4. Извлекает ключевые слова на основе частей речи (существительные, прилагательные) и именованных сущностей.

    A - Проверка наличия spaCy
    ├── Нет: Возврат исходного текста
    └── Да: Загрузка языковой модели
    ↓
    B - Обработка текста spaCy
    ↓
    C - Извлечение ключевых слов

    Примеры:
    >>> spacy_get_keywords("This is an example sentence about Apple Inc.")
    ['example', 'sentence', 'Apple Inc.']
    """
    ...