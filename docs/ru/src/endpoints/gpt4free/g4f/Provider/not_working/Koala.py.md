# Модуль Koala для работы с gpt4free
=========================================

Модуль предназначен для работы с провайдером Koala в рамках gpt4free. Он обеспечивает асинхронное взаимодействие с API Koala для генерации текста на основе предоставленных сообщений.

## Обзор

Модуль содержит класс `Koala`, который наследуется от `AsyncGeneratorProvider` и `ProviderModelMixin`. Этот класс позволяет создавать асинхронный генератор для получения ответов от Koala.

## Подробнее

Модуль используется для взаимодействия с сервисом Koala, предоставляющим доступ к различным моделям GPT. Он поддерживает сохранение истории сообщений и позволяет настраивать прокси для подключения.

## Классы

### `Koala`

**Описание**: Класс для взаимодействия с Koala API.

**Наследует**:
- `AsyncGeneratorProvider`: Обеспечивает асинхронную генерацию ответов.
- `ProviderModelMixin`: Предоставляет методы для работы с моделями.

**Атрибуты**:
- `url` (str): URL сервиса Koala.
- `api_endpoint` (str): URL API для взаимодействия.
- `working` (bool): Указывает, работает ли провайдер.
- `supports_message_history` (bool): Поддерживает ли провайдер историю сообщений.
- `default_model` (str): Модель, используемая по умолчанию.

**Методы**:
- `create_async_generator`: Создает асинхронный генератор для получения ответов от Koala.
- `_parse_event_stream`: Разбирает поток событий, возвращаемый сервером.

## Функции

### `create_async_generator`

```python
    @classmethod
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: Optional[str] = None,
        connector: Optional[BaseConnector] = None,
        **kwargs: Any
    ) -> AsyncGenerator[Dict[str, Union[str, int, float, List[Dict[str, Any]], None]], None]:
        """Создает асинхронный генератор для получения ответов от Koala.

        Args:
            cls (Koala): Класс Koala.
            model (str): Название используемой модели.
            messages (Messages): Список сообщений для отправки.
            proxy (Optional[str], optional): Прокси-сервер для подключения. По умолчанию `None`.
            connector (Optional[BaseConnector], optional): Коннектор для сессии aiohttp. По умолчанию `None`.
            **kwargs (Any): Дополнительные аргументы.

        Returns:
            AsyncGenerator[Dict[str, Union[str, int, float, List[Dict[str, Any]], None]], None]: Асинхронный генератор, выдающий словарь с ответами.

        Raises:
            Exception: В случае ошибки при запросе к API.

        Example:
            >>> async for chunk in Koala.create_async_generator(model='gpt-4o-mini', messages=[{'role': 'user', 'content': 'Hello'}]):
            ...     print(chunk)
        """
        ...
```

**Назначение**: Создает асинхронный генератор для получения ответов от Koala API.

**Параметры**:
- `cls` (Koala): Класс Koala.
- `model` (str): Название используемой модели. Если не указано, используется `gpt-4o-mini`.
- `messages` (Messages): Список сообщений для отправки, где каждое сообщение представляет собой словарь с ролями (`role`) и содержанием (`content`).
- `proxy` (Optional[str], optional): Прокси-сервер для подключения. По умолчанию `None`.
- `connector` (Optional[BaseConnector], optional): Коннектор для сессии `aiohttp`. По умолчанию `None`.
- `**kwargs` (Any): Дополнительные аргументы.

**Возвращает**:
- `AsyncGenerator[Dict[str, Union[str, int, float, List[Dict[str, Any]], None]], None]`: Асинхронный генератор, выдающий словари с ответами от API.

**Вызывает исключения**:
- `Exception`: В случае ошибки при запросе к API.

**Как работает функция**:

1. **Подготовка заголовков**:
   - Определяет заголовки HTTP-запроса, включая `User-Agent`, `Accept`, `Referer` и другие необходимые параметры.
   - Генерирует случайный `Visitor-ID`.

2. **Создание сессии**:
   - Создает асинхронную сессию `aiohttp.ClientSession` с заданными заголовками и прокси (если указан).

3. **Формирование данных**:
   - Извлекает текст из последнего сообщения пользователя (`input_text`).
   - Объединяет все сообщения с ролью "system" в одну строку (`system_messages`) и добавляет их к `input_text`.
   - Формирует словарь `data` с входными данными, историей сообщений пользователя и ассистента, а также выбранной моделью.

4. **Отправка запроса**:
   - Отправляет POST-запрос к API Koala (`cls.api_endpoint`) с данными в формате JSON и прокси (если указан).

5. **Обработка ответа**:
   - Проверяет статус ответа с помощью `raise_for_status`.
   - Передает ответ в функцию `_parse_event_stream` для разбора потока событий.

6. **Генерация ответов**:
   - Асинхронно генерирует ответы, полученные из потока событий, с использованием `yield`.

```
    Начало
    │
    ├── Заголовки_HTTP (Подготовка заголовков)
    │   │
    │   └── Случайный_Visitor_ID (Генерация случайного Visitor-ID)
    │
    │
    └── Создание_сессии (Создание асинхронной сессии aiohttp.ClientSession)
        │
        ├── Извлечение_текста (Извлечение текста из последнего сообщения пользователя)
        │   │
        │   └── Объединение_system_сообщений (Объединение сообщений с ролью "system")
        │
        │
        └── Формирование_данных (Формирование словаря data с входными данными)
            │
            └── Отправка_POST_запроса (Отправка POST-запроса к API Koala)
                │
                ├── Проверка_статуса_ответа (Проверка статуса ответа)
                │   │
                │   └── Разбор_потока_событий (Передача ответа в _parse_event_stream)
                │
                │
                └── Генерация_ответов (Асинхронная генерация ответов из потока событий)
                    │
                    └── Конец
```

**Примеры**:

```python
async for chunk in Koala.create_async_generator(model='gpt-4o-mini', messages=[{'role': 'user', 'content': 'Привет'}]):
    print(chunk)
```

```python
async for chunk in Koala.create_async_generator(model='gpt-4o-mini', messages=[{'role': 'system', 'content': 'Ты - полезный ассистент'}, {'role': 'user', 'content': 'Что такое Python?'}]):
    print(chunk)
```

### `_parse_event_stream`

```python
    @staticmethod
    async def _parse_event_stream(response: ClientResponse) -> AsyncGenerator[Dict[str, Any], None]:
        """Разбирает поток событий, возвращаемый сервером.

        Args:
            response (ClientResponse): Ответ от сервера.

        Returns:
            AsyncGenerator[Dict[str, Any], None]: Асинхронный генератор, выдающий словарь с данными из потока событий.

        Raises:
            Нет.

        Example:
            # Пример использования внутри create_async_generator, явно не вызывается
            async for chunk in cls._parse_event_stream(response):
                yield chunk
        """
        ...
```

**Назначение**: Разбирает поток событий, возвращаемый сервером, и извлекает данные.

**Параметры**:
- `response` (ClientResponse): Ответ от сервера в виде `ClientResponse` объекта.

**Возвращает**:
- `AsyncGenerator[Dict[str, Any], None]`: Асинхронный генератор, выдающий словари с данными из потока событий.

**Как работает функция**:

1. **Чтение чанков**:
   - Асинхронно читает чанки из содержимого ответа (`response.content`).

2. **Проверка префикса**:
   - Проверяет, начинается ли чанк с префикса `b"data: "`.

3. **Извлечение данных**:
   - Если чанк начинается с указанного префикса, извлекает данные, удаляя первые 6 байт (`chunk[6:]`).

4. **Декодирование JSON**:
   - Декодирует JSON-строку в словарь с помощью `json.loads`.

5. **Генерация данных**:
   - Асинхронно генерирует полученный словарь с данными с использованием `yield`.

```
    Начало
    │
    └── Чтение_чанков (Асинхронное чтение чанков из содержимого ответа)
        │
        └── Проверка_префикса (Проверка, начинается ли чанк с b"data: ")
            │
            └── Извлечение_данных (Извлечение данных, если чанк начинается с префикса)
                │
                └── Декодирование_JSON (Декодирование JSON-строки в словарь)
                    │
                    └── Генерация_данных (Асинхронная генерация словаря с данными)
                        │
                        └── Конец
```

**Примеры**:

```python
# Пример использования внутри create_async_generator, явно не вызывается
async for chunk in Koala._parse_event_stream(response):
    yield chunk