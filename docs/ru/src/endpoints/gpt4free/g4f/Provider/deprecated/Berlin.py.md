# Модуль `Berlin`

## Обзор

Модуль `Berlin` предоставляет асинхронный генератор для взаимодействия с сервисом `ai.berlin4h.top` для получения ответов от модели GPT-3.5 Turbo. Модуль использует `aiohttp` для выполнения асинхронных HTTP-запросов и поддерживает работу через прокси-сервер.

## Подробней

Модуль предназначен для асинхронного получения ответов от модели GPT-3.5 Turbo через API сервиса `ai.berlin4h.top`. Он включает в себя функциональность для авторизации, формирования запросов и обработки потоковых ответов. Модуль также поддерживает использование прокси-сервера для обхода ограничений сети.
Расположение файла в проекте: `hypotez/src/endpoints/gpt4free/g4f/Provider/deprecated/Berlin.py` указывает, что этот модуль является частью более крупной системы, вероятно, предоставляющей интерфейс к различным бесплатным или условно-бесплатным API для работы с моделями обработки естественного языка, и находится в стадии "deprecated" (устаревший).

## Классы

### `Berlin`

**Описание**: Класс `Berlin` является асинхронным генератором провайдером, который взаимодействует с API `ai.berlin4h.top` для получения ответов от модели GPT-3.5 Turbo.

**Наследует**:
- `AsyncGeneratorProvider`: Наследует от базового класса для асинхронных генераторов провайдеров.

**Атрибуты**:
- `url` (str): URL сервиса `ai.berlin4h.top`.
- `working` (bool): Флаг, указывающий на работоспособность провайдера.
- `supports_gpt_35_turbo` (bool): Флаг, указывающий на поддержку модели GPT-3.5 Turbo.
- `_token` (str | None): Токен авторизации, используемый для доступа к API.

### `create_async_generator`

```python
@classmethod
async def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    proxy: str = None,
    **kwargs
) -> AsyncResult:
    """Создает асинхронный генератор для взаимодействия с API Berlin.

    Args:
        model (str): Идентификатор модели, используемой для генерации ответа.
        messages (Messages): Список сообщений для передачи в модель.
        proxy (str, optional): URL прокси-сервера для использования при подключении. По умолчанию `None`.
        **kwargs: Дополнительные параметры, передаваемые в API.

    Returns:
        AsyncResult: Асинхронный генератор, возвращающий ответы от модели.

    Raises:
        RuntimeError: Если при обработке ответа возникает ошибка.

    Example:
        >>> async for chunk in Berlin.create_async_generator(model='gpt-3.5-turbo', messages=[{'role': 'user', 'content': 'Hello'}]):
        ...     print(chunk)
    """
```

**Назначение**: Метод `create_async_generator` создает асинхронный генератор, который отправляет запросы к API `ai.berlin4h.top` и возвращает ответы от модели GPT-3.5 Turbo.

**Параметры**:
- `cls` (type[Berlin]): Ссылка на класс `Berlin`.
- `model` (str): Идентификатор модели, используемой для генерации ответа.
- `messages` (Messages): Список сообщений для передачи в модель.
- `proxy` (str, optional): URL прокси-сервера для использования при подключении. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры, передаваемые в API.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, возвращающий ответы от модели.

**Вызывает исключения**:
- `RuntimeError`: Если при обработке ответа возникает ошибка.

**Как работает функция**:

1. **Инициализация**:
   - Проверяется и устанавливается модель по умолчанию, если она не указана.
   - Формируются заголовки HTTP-запроса, включая `User-Agent`, `Accept`, `Content-Type` и другие.
   - Инициализируется асинхронная сессия `aiohttp.ClientSession` с заданными заголовками.
2. **Авторизация**:
   - Если токен авторизации `cls._token` не установлен, выполняется запрос на авторизацию к API `/api/login` с использованием учетных данных (`'account': '免费使用GPT3.5模型@163.com'`, `'password': '659e945c2d004686bad1a75b708c962f'`).
   - Полученный токен сохраняется в `cls._token` для последующих запросов.
3. **Формирование запроса**:
   - Формируется промпт на основе переданных сообщений `messages` с использованием функции `format_prompt`.
   - Формируются данные запроса, включающие промпт, идентификатор родительского сообщения (случайный UUID), параметры модели (температура, штрафы, максимальное количество токенов) и дополнительные параметры из `kwargs`.
4. **Отправка запроса и обработка ответа**:
   - Отправляется POST-запрос к API `/api/chat/completions` с использованием сформированных данных, заголовков и прокси-сервера (если указан).
   - Полученный ответ обрабатывается по частям (chunks) с использованием асинхронного генератора.
   - Каждая часть ответа преобразуется из JSON в строку и возвращается через `yield`.
5. **Обработка ошибок**:
   - В случае ошибки при обработке ответа (например, неверный формат JSON) выбрасывается исключение `RuntimeError` с информацией о полученном чанке.

```
A: Инициализация заголовков и сессии aiohttp
|
B: Проверка и получение токена авторизации
|
C: Формирование данных запроса (prompt, UUID, параметры)
|
D: Отправка POST-запроса к API
|
E: Обработка потоковых чанков ответа
|
F: Преобразование JSON в строку и выдача результата через yield
```

**Примеры**:

```python
async for chunk in Berlin.create_async_generator(model='gpt-3.5-turbo', messages=[{'role': 'user', 'content': 'Hello'}]):
    print(chunk)
```
```python
async for chunk in Berlin.create_async_generator(model='gpt-3.5-turbo', messages=[{'role': 'user', 'content': 'Translate to Russian: Hello'}] , proxy = 'http://proxy.example.com:8080'):
    print(chunk)
```
```python
async for chunk in Berlin.create_async_generator(model='gpt-3.5-turbo', messages=[{'role': 'user', 'content': 'Tell me a joke'}], max_tokens = 100):
    print(chunk)