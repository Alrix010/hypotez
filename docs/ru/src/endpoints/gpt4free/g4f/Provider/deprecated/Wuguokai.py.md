# Документация модуля `Wuguokai`

## Обзор

Модуль предоставляет класс `Wuguokai`, который является провайдером для взаимодействия с сервисом `chat.wuguokai.xyz`.
Он поддерживает модель `gpt-3.5-turbo` и используется для создания завершений (completions) на основе предоставленных сообщений.

## Подробней

Этот модуль предназначен для интеграции с API `chat.wuguokai.xyz`, позволяя отправлять запросы на генерацию текста и получать ответы.
Он использует библиотеку `requests` для выполнения HTTP-запросов и форматирует запросы в соответствии с требованиями API.

## Классы

### `Wuguokai`

**Описание**: Класс `Wuguokai` является провайдером для взаимодействия с API `chat.wuguokai.xyz`.

**Наследует**:
- `AbstractProvider`: Этот класс наследуется от `AbstractProvider`, который, вероятно, предоставляет общую функциональность для всех провайдеров в проекте.

**Атрибуты**:
- `url` (str): URL-адрес сервиса `chat.wuguokai.xyz`.
- `supports_gpt_35_turbo` (bool): Указывает, поддерживает ли провайдер модель `gpt-3.5-turbo`.
- `working` (bool): Указывает, находится ли провайдер в рабочем состоянии.

**Методы**:
- `create_completion()`: Создает завершение на основе предоставленных параметров.

### Методы класса

### `create_completion`

```python
    def create_completion(
        model: str,
        messages: list[dict[str, str]],
        stream: bool,
        **kwargs: Any,
    ) -> CreateResult:
        """ Функция выполняет запрос к API wuguokai.xyz для генерации текста на основе предоставленных сообщений.
        Args:
            model (str): Идентификатор используемой модели.
            messages (list[dict[str, str]]): Список сообщений, используемых для генерации текста.
            stream (bool): Указывает, должен ли ответ быть возвращен в режиме потока.
            **kwargs (Any): Дополнительные аргументы, такие как прокси.

        Returns:
            CreateResult: Результат создания завершения, представляющий собой генератор текста.

        Raises:
            Exception: Если возникает ошибка при выполнении HTTP-запроса или при обработке ответа от API.

        
        - Функция принимает параметры, необходимые для запроса к API, включая модель, сообщения и настройки потоковой передачи.
        - Формирует заголовки HTTP-запроса, включая User-Agent, Referer и Content-Type.
        - Создает структуру данных запроса, содержащую сообщения и случайный идентификатор пользователя.
        - Отправляет POST-запрос к API `ai-api20.wuguokai.xyz/api/chat-process` с использованием библиотеки `requests`.
        - Обрабатывает ответ от API, проверяя статус код и разделяя текст ответа на части.
        - Возвращает текст ответа в виде генератора, который выдает части текста по мере их поступления.
        """
```

**Параметры**:
- `model` (str): Идентификатор используемой модели.
- `messages` (list[dict[str, str]]): Список сообщений, используемых для генерации текста.
- `stream` (bool): Указывает, должен ли ответ быть возвращен в режиме потока.
- `**kwargs` (Any): Дополнительные аргументы, такие как прокси.

**Возвращает**:
- `CreateResult`: Результат создания завершения, представляющий собой генератор текста.

**Вызывает исключения**:
- `Exception`: Если возникает ошибка при выполнении HTTP-запроса или при обработке ответа от API.

**Как работает функция**:
- Функция принимает параметры, необходимые для запроса к API, включая модель, сообщения и настройки потоковой передачи.
- Формирует заголовки HTTP-запроса, включая User-Agent, Referer и Content-Type.
- Создает структуру данных запроса, содержащую сообщения и случайный идентификатор пользователя.
- Отправляет POST-запрос к API `ai-api20.wuguokai.xyz/api/chat-process` с использованием библиотеки `requests`.
- Обрабатывает ответ от API, проверяя статус код и разделяя текст ответа на части.
- Возвращает текст ответа в виде генератора, который выдает части текста по мере их поступления.

**Примеры**:

```python
# Пример вызова функции create_completion с минимальным набором параметров
messages = [{"role": "user", "content": "Hello, world!"}]
result = Wuguokai.create_completion(model="gpt-3.5-turbo", messages=messages, stream=False)
for chunk in result:
    print(chunk)

# Пример вызова функции create_completion с использованием прокси
messages = [{"role": "user", "content": "Как дела?"}]
proxies = {"http": "http://1.2.3.4:8080", "https": "http://1.2.3.4:8080"}
result = Wuguokai.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True, proxy=proxies)
for chunk in result:
    print(chunk)