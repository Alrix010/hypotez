# Модуль GizAI

## Обзор

Модуль `GizAI` предоставляет асинхронный интерфейс для взаимодействия с AI-моделями через API `GizAI`. Он поддерживает стриминг, системные сообщения и историю сообщений. Позволяет использовать различные модели, такие как `chat-gemini-flash`.
Расположение файла в проекте: `hypotez/src/endpoints/gpt4free/g4f/Provider/GizAI.py`.
Этот модуль является частью поставщиков `gpt4free` в проекте `hypotez`, предоставляя доступ к еще одной платформе для работы с большими языковыми моделями.

## Подробней

Модуль предназначен для асинхронного взаимодействия с API `GizAI`. Он предоставляет возможность отправлять запросы к различным моделям AI, поддерживаемым платформой, и получать ответы. Модуль включает в себя функции для форматирования запросов и обработки ответов от API.

## Классы

### `GizAI`

**Описание**: Класс `GizAI` является асинхронным поставщиком, реализующим взаимодействие с API `GizAI`. Он поддерживает стриминг, системные сообщения и историю сообщений.

**Наследует**:
- `AsyncGeneratorProvider`: Обеспечивает асинхронную генерацию данных.
- `ProviderModelMixin`: Предоставляет функциональность для работы с моделями.

**Аттрибуты**:
- `url` (str): URL для доступа к `GizAI`.
- `api_endpoint` (str): URL API endpoint для отправки запросов.
- `working` (bool): Указывает, работает ли провайдер.
- `supports_stream` (bool): Указывает, поддерживает ли провайдер стриминг.
- `supports_system_message` (bool): Указывает, поддерживает ли провайдер системные сообщения.
- `supports_message_history` (bool): Указывает, поддерживает ли провайдер историю сообщений.
- `default_model` (str): Модель, используемая по умолчанию.
- `models` (List[str]): Список поддерживаемых моделей.
- `model_aliases` (Dict[str, str]): Словарь псевдонимов моделей.

**Методы**:
- `get_model(model: str) -> str`: Возвращает имя модели на основе псевдонима или использует модель по умолчанию.
- `create_async_generator(model: str, messages: Messages, proxy: str = None, **kwargs) -> AsyncResult`: Создает асинхронный генератор для отправки запросов к API `GizAI`.

### `get_model`

```python
    @classmethod
    def get_model(cls, model: str) -> str:
        """
        Возвращает имя модели на основе псевдонима или использует модель по умолчанию.

        Args:
            model (str): Имя модели или псевдоним.

        Returns:
            str: Имя модели.
        """
        ...
```

**Назначение**: Определяет, какую модель использовать, исходя из входных параметров. Если указана одна из поддерживаемых моделей, возвращает ее. Если указан псевдоним модели, возвращает соответствующую модель. В противном случае возвращает модель по умолчанию.

**Параметры**:
- `model` (str): Имя модели или псевдоним.

**Возвращает**:
- `str`: Имя модели.

**Как работает функция**:
1. Проверяет, входит ли `model` в список `cls.models`. Если да, возвращает `model`.
2. Если `model` не найдена в списке `cls.models`, проверяет, есть ли она в словаре `cls.model_aliases`. Если да, возвращает соответствующее значение из словаря.
3. Если `model` нет ни в `cls.models`, ни в `cls.model_aliases`, возвращает `cls.default_model`.

```
Проверка наличия модели в списке поддерживаемых моделей -> Проверка наличия псевдонима модели в словаре псевдонимов -> Возврат модели по умолчанию
```

**Примеры**:

```python
GizAI.get_model('chat-gemini-flash')  # Возвращает 'chat-gemini-flash'
GizAI.get_model('gemini-1.5-flash')   # Возвращает 'chat-gemini-flash'
GizAI.get_model('unknown-model')      # Возвращает 'chat-gemini-flash'
```

### `create_async_generator`

```python
    @classmethod
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: str = None,
        **kwargs
    ) -> AsyncResult:
        """
        Создает асинхронный генератор для отправки запросов к API `GizAI`.

        Args:
            model (str): Имя модели.
            messages (Messages): Список сообщений для отправки.
            proxy (str, optional): Адрес прокси-сервера. По умолчанию `None`.

        Returns:
            AsyncResult: Асинхронный генератор, возвращающий результаты от API.

        Raises:
            Exception: Если получен неожиданный статус ответа от API.
        """
        ...
```

**Назначение**: Создает и возвращает асинхронный генератор, который отправляет запросы к API `GizAI` и возвращает результаты.

**Параметры**:
- `model` (str): Имя модели, которую следует использовать.
- `messages` (Messages): Список сообщений для отправки в запросе.
- `proxy` (str, optional): Адрес прокси-сервера, если необходимо использовать прокси. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, который выдает результаты от API `GizAI`.

**Как работает функция**:
1. Определяет модель, используя метод `cls.get_model(model)`.
2. Формирует HTTP-заголовки для запроса.
3. Создает асинхронную сессию `aiohttp.ClientSession` с заданными заголовками.
4. Формирует данные запроса, включая модель и сообщения.
5. Отправляет POST-запрос к `cls.api_endpoint` с использованием асинхронной сессии, передавая данные запроса в формате JSON и прокси, если он указан.
6. Если статус ответа равен 201, извлекает результат из JSON-ответа и передает его через `yield`.
7. В случае получения неожиданного статуса ответа вызывает исключение `Exception` с информацией о статусе и тексте ответа.

```
Определение модели -> Формирование заголовков -> Создание асинхронной сессии -> Формирование данных запроса -> Отправка POST-запроса -> Извлечение результата или вызов исключения
```

**Примеры**:

```python
messages = [{"role": "user", "content": "Hello, how are you?"}]
async for response in GizAI.create_async_generator(model='chat-gemini-flash', messages=messages):
    print(response)
```
```python
messages = [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of France?"}]
async for response in GizAI.create_async_generator(model='gemini-1.5-flash', messages=messages, proxy='http://proxy.example.com'):
    print(response)
```

## Функции
В данном модуле функции отсутствуют.