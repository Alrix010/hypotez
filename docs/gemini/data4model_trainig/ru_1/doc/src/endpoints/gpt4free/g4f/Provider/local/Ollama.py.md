# Модуль для работы с Ollama

## Обзор

Модуль `Ollama` предназначен для взаимодействия с локально запущенными моделями Ollama. Он предоставляет функциональность для получения списка доступных моделей и создания асинхронного генератора для взаимодействия с выбранной моделью.

## Подробней

Модуль `Ollama` интегрируется с локально запущенными моделями Ollama, позволяя использовать их для генерации текста. Он наследуется от класса `OpenaiAPI` и использует его функциональность для создания асинхронных генераторов.

## Классы

### `Ollama`

**Описание**: Класс для взаимодействия с локально запущенными моделями Ollama.
**Наследует**: `OpenaiAPI`

**Атрибуты**:
- `label` (str): Метка провайдера, "Ollama".
- `url` (str): URL Ollama, "https://ollama.com".
- `login_url` (str): URL для логина, `None`.
- `needs_auth` (bool): Требуется ли аутентификация, `False`.
- `working` (bool): Статус работоспособности, `True`.
- `models` (List[str]): Список доступных моделей Ollama.
- `default_model` (str): Модель по умолчанию из списка доступных моделей Ollama.

**Методы**:
- `get_models()`: Получает список доступных моделей Ollama.
- `create_async_generator()`: Создает асинхронный генератор для взаимодействия с выбранной моделью.

## Методы класса

### `get_models`

```python
@classmethod
def get_models(cls, api_base: str = None, **kwargs) -> list[str]:
    """Получает список доступных моделей Ollama.

    Args:
        cls (Ollama): Ссылка на класс Ollama.
        api_base (str, optional): Базовый URL API. По умолчанию `None`.
        **kwargs: Дополнительные параметры.

    Returns:
        list[str]: Список имен доступных моделей.
    """
    ...
```

**Назначение**:
Метод `get_models` получает список доступных моделей Ollama. Если список моделей еще не был получен, он делает запрос к API Ollama для получения списка моделей и сохраняет его в атрибуте `models` класса.

**Параметры**:
- `cls`: Ссылка на класс.
- `api_base` (str, optional): Базовый URL API. Используется для переопределения URL по умолчанию. Если `None`, используется URL, сформированный на основе переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры.

**Возвращает**:
- `list[str]`: Список имен доступных моделей.

**Как работает функция**:
1. Проверяется, был ли уже получен список моделей (атрибут `cls.models`).
2. Если список моделей не был получен, определяется URL для запроса к API Ollama. Если `api_base` не указан, URL формируется на основе переменных окружения `OLLAMA_HOST` (по умолчанию "127.0.0.1") и `OLLAMA_PORT` (по умолчанию "11434").
3. Делается GET-запрос к API Ollama по адресу `/api/tags` для получения списка моделей.
4. Из JSON-ответа извлекаются имена моделей и сохраняются в атрибуте `cls.models`. Также сохраняется первая модель из списка в атрибуте `cls.default_model`.
5. Возвращается список имен моделей.

**Примеры**:

```python
# Получение списка моделей с использованием URL по умолчанию
models = Ollama.get_models()
print(models)

# Получение списка моделей с использованием переопределенного URL
models = Ollama.get_models(api_base="http://localhost:12345/v1")
print(models)
```

### `create_async_generator`

```python
@classmethod
def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    api_base: str = None,
    **kwargs
) -> AsyncResult:
    """Создает асинхронный генератор для взаимодействия с выбранной моделью.

    Args:
        cls (Ollama): Ссылка на класс Ollama.
        model (str): Имя модели для использования.
        messages (Messages): Список сообщений для отправки в модель.
        api_base (str, optional): Базовый URL API. По умолчанию `None`.
        **kwargs: Дополнительные параметры.

    Returns:
        AsyncResult: Асинхронный генератор для взаимодействия с моделью.
    """
    ...
```

**Назначение**:
Метод `create_async_generator` создает асинхронный генератор для взаимодействия с выбранной моделью Ollama. Он использует метод `create_async_generator` родительского класса `OpenaiAPI` для создания генератора.

**Параметры**:
- `cls`: Ссылка на класс.
- `model` (str): Имя модели для использования.
- `messages` (Messages): Список сообщений для отправки в модель.
- `api_base` (str, optional): Базовый URL API. Если `None`, используется URL, сформированный на основе переменных окружения `OLLAMA_HOST` (по умолчанию "localhost") и `OLLAMA_PORT` (по умолчанию "11434"). По умолчанию `None`.
- `**kwargs`: Дополнительные параметры.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор для взаимодействия с моделью.

**Как работает функция**:
1. Определяется базовый URL API. Если `api_base` не указан, URL формируется на основе переменных окружения `OLLAMA_HOST` (по умолчанию "localhost") и `OLLAMA_PORT` (по умолчанию "11434").
2. Вызывается метод `create_async_generator` родительского класса `OpenaiAPI` с передачей имени модели, списка сообщений и базового URL API.
3. Возвращается асинхронный генератор, созданный методом `create_async_generator` родительского класса.

**Примеры**:

```python
messages = [{"role": "user", "content": "Hello, Ollama!"}]

# Создание асинхронного генератора с использованием URL по умолчанию
generator = Ollama.create_async_generator(model="llama2", messages=messages)

# Создание асинхронного генератора с использованием переопределенного URL
generator = Ollama.create_async_generator(model="llama2", messages=messages, api_base="http://localhost:12345/v1")
```