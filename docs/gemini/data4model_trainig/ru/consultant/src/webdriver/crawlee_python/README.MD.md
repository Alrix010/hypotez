## Анализ кода модуля `README.MD`

**Качество кода:**

- **Соответствие стандартам**: 7/10
- **Плюсы**:
    - Хорошее описание функциональности модуля и его ключевых особенностей.
    - Наличие примеров конфигурации и использования.
    - Подробное описание полей конфигурационного файла.
    - Указаны требования к окружению и установке зависимостей.
- **Минусы**:
    - Не хватает документации в формате Python docstring для функций и классов, что затрудняет понимание структуры модуля при работе с кодом.
    - Отсутствует информация о структуре проекта и взаимодействии с другими модулями.
    - Форматирование не полностью соответствует PEP8 (например, в примерах кода использованы двойные кавычки вместо одинарных).

**Рекомендации по улучшению:**

1.  **Добавить docstring**: Добавить docstring в формате, указанном в инструкции, для всех классов и функций. Это необходимо для автоматической генерации документации и облегчения понимания кода.
2.  **Актуализировать примеры кода**: Привести примеры кода в соответствие со стандартом оформления кода проекта (использовать одинарные кавычки).
3.  **Улучшить описание интеграции**: Добавить информацию о взаимодействии данного модуля с другими частями проекта `hypotez`.
4.  **Добавить информацию о веб-драйвере**: Добавить информацию об использовании веб-драйвера в данном модуле, упомянув о необходимости наследования `Driver`, `Chrome`, `Firefox`, `Playwright` и использования `driver.execute_locator(l: dict)`.
5.  **Добавить информацию о логировании**: Подчеркнуть необходимость использования `logger` из модуля `src.logger` для логирования ошибок и информации.

**Оптимизированный код:**

```markdown
```rst
.. module:: src.webdriver.crawlee_python
```

# Crawlee Python Module for Automation and Data Scraping

Этот модуль предоставляет пользовательскую реализацию `PlaywrightCrawler` с использованием библиотеки Crawlee. Он позволяет вам настраивать параметры запуска браузера, обрабатывать веб-страницы и извлекать из них данные. Конфигурация управляется через файл `crawlee_python.json`.

## Key Features

-   **Централизованная конфигурация**: Конфигурация управляется через файл `crawlee_python.json`.
-   **Поддержка пользовательских опций**: Возможность передачи пользовательских опций во время инициализации.
-   **Улучшенное логирование и обработка ошибок**: Предоставляет подробные логи для инициализации, проблем с конфигурацией и ошибок WebDriver.
-   **Поддержка прокси**: Настройка прокси-серверов для обхода ограничений.
-   **Гибкие настройки браузера**: Настройка размера области просмотра, user-agent и других параметров браузера.

## Требования

Перед использованием этого модуля убедитесь, что установлены следующие зависимости:

-   Python 3.x
-   Playwright
-   Crawlee

Установите необходимые зависимости Python:

```bash
pip install playwright crawlee
```

Кроме того, убедитесь, что Playwright установлен и настроен для работы с браузером. Установите браузеры, используя команду:

```bash
playwright install
```

## Конфигурация

Конфигурация для Crawlee Python хранится в файле `crawlee_python.json`. Ниже приведена примерная структура файла конфигурации и его описание:

### Пример конфигурации (`crawlee_python.json`)

```json
{
  "max_requests": 10,
  "headless": true,
  "browser_type": "chromium",
  "options": [
    "--disable-dev-shm-usage",
    "--no-sandbox",
    "--disable-gpu"
  ],
  "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36",
  "proxy": {
    "enabled": false,
    "server": "http://proxy.example.com:8080",
    "username": "user",
    "password": "password"
  },
  "viewport": {
    "width": 1280,
    "height": 720
  },
  "timeout": 30000,
  "ignore_https_errors": false
}
```

### Описание полей конфигурации

#### 1. `max_requests`

Максимальное количество запросов для выполнения во время обхода. По умолчанию `10`.

#### 2. `headless`

Логическое значение, указывающее, должен ли браузер работать в режиме без графического интерфейса. По умолчанию `true`.

#### 3. `browser_type`

Тип используемого браузера. Возможные значения:

-   `chromium` (по умолчанию)
-   `firefox`
-   `webkit`

#### 4. `options`

Список аргументов командной строки, передаваемых в браузер. Примеры:

-   `--disable-dev-shm-usage`: Отключает использование `/dev/shm` в контейнерах Docker.
-   `--no-sandbox`: Отключает режим песочницы.
-   `--disable-gpu`: Отключает аппаратное ускорение GPU.

#### 5. `user_agent`

Строка user-agent, используемая для запросов браузера.

#### 6. `proxy`

Настройки прокси-сервера:

-   **enabled**: Логическое значение, указывающее, следует ли использовать прокси.
-   **server**: Адрес прокси-сервера.
-   **username**: Имя пользователя для аутентификации прокси.
-   **password**: Пароль для аутентификации прокси.

#### 7. `viewport`

Размеры окна браузера:

-   **width**: Ширина окна.
-   **height**: Высота окна.

#### 8. `timeout`

Максимальное время ожидания для операций (в миллисекундах). По умолчанию `30000` (30 секунд).

#### 9. `ignore_https_errors`

Логическое значение, указывающее, следует ли игнорировать ошибки HTTPS. По умолчанию `false`.

## Использование

Чтобы использовать `CrawleePython` в своем проекте, просто импортируйте и инициализируйте его:

```python
from src.webdriver.crawlee_python import CrawleePython
import asyncio

# Инициализация CrawleePython с пользовательскими опциями
async def main():
    crawler = CrawleePython(max_requests=10, headless=True, browser_type='chromium', options=["--headless"])
    await crawler.run(['https://www.example.com'])

asyncio.run(main())
```

Класс `CrawleePython` автоматически загружает настройки из файла `crawlee_python.json` и использует их для настройки WebDriver. Вы также можете указать пользовательский user-agent и передать дополнительные параметры во время инициализации WebDriver.

## Логирование и отладка

Класс WebDriver использует `logger` из `src.logger` для регистрации ошибок, предупреждений и общей информации. Все проблемы, возникающие во время инициализации, настройки или выполнения, будут зарегистрированы для упрощения отладки.

### Пример логов

-   **Ошибка во время инициализации WebDriver**: `Error initializing Crawlee Python: <error details>`
-   **Проблемы с конфигурацией**: `Error in crawlee_python.json file: <issue details>`

## Использование WebDriver

В этом модуле используется WebDriver для управления браузером. Для этого необходимо:

1.  Импортировать необходимые классы из `src.webdriver`:

```python
from src.webdirver import Driver, Chrome, Firefox, Playwright
```

2.  Создать экземпляр драйвера, указав тип браузера:

```python
driver = Driver(Chrome) # или Firefox, Playwright и т.д.
```

3.  Использовать метод `driver.execute_locator(l: dict)` для выполнения действий с элементами на странице, где `l` - словарь с параметрами локатора.

## Пример использования `driver.execute_locator`

```python
close_banner = {
  'attribute': None,
  'by': 'XPATH',
  'selector': "//button[@id = 'closeXButton']",
  'if_list': 'first',
  'use_mouse': False,
  'mandatory': False,
  'timeout': 0,
  'timeout_for_event': "presence_of_element_located",
  'event': 'click()',
  'locator_description': "Закрываю pop-up окно, если оно не появилось - не страшно (`mandatory`:`false`)"
}

result = driver.execute_locator(close_banner)
```

## Логирование

Для логирования используйте модуль `logger` из `src.logger.logger`.

Пример логирования ошибки:

```python
from src.logger import logger

try:
    # Код, который может вызвать ошибку
    ...
except Exception as ex:
    logger.error('Error while processing data', ex, exc_info=True)
```

## Лицензия

Этот проект лицензирован в соответствии с лицензией MIT. См. файл [LICENSE](../../LICENSE) для получения подробной информации.