# Модуль для токенизации текста

## Обзор

Модуль предназначен для токенизации текста с использованием библиотеки `tiktoken`. В настоящее время закомментирован и не используется в проекте. Изначально предназначался для оценки количества токенов в тексте, что может быть полезно при работе с большими языковыми моделями, такими как GPT.

## Подробней

Данный модуль мог бы использоваться для предварительной обработки текста перед отправкой в языковую модель, чтобы оценить стоимость запроса или убедиться, что текст не превышает лимит токенов.

## Функции

### `tokenize`

```python
# def tokenize(text: str, model: str = 'gpt-3.5-turbo') -> Union[int, str]:
#     encoding   = tiktoken.encoding_for_model(model)
#     encoded    = encoding.encode(text)
#     num_tokens = len(encoded)
    
#     return num_tokens, encoded
```

**Назначение**: Функция для токенизации текста с использованием указанной модели.

**Параметры**:

*   `text` (str): Текст для токенизации.
*   `model` (str, optional): Название модели для токенизации. По умолчанию `'gpt-3.5-turbo'`.

**Возвращает**:

*   `Union[int, str]`: Количество токенов и закодированный текст.

**Как работает функция**:

1.  Определяет кодировку для указанной модели с помощью `tiktoken.encoding_for_model(model)`.
2.  Кодирует текст в токены с использованием `encoding.encode(text)`.
3.  Определяет количество токенов `len(encoded)`.
4.  Возвращает количество токенов и закодированный текст.

**Примеры**:

```python
# from tiktoken import encoding_for_model
# text = "Пример текста для токенизации."
# model = "gpt-3.5-turbo"
# num_tokens, encoded = tokenize(text, model)
# print(f"Количество токенов: {num_tokens}")
# print(f"Закодированный текст: {encoded}")