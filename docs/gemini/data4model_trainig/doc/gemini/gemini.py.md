## Модуль `gemini`

### Обзор

Модуль `gemini` предназначен для интеграции с моделями Google Generative AI.

### Подробней

Модуль предоставляет класс `GoogleGenerativeAi`, который позволяет взаимодействовать с моделями Gemini для выполнения задач, связанных с обработкой естественного языка и анализа данных. Он поддерживает генерацию текста, анализ тональности, перевод и другие задачи, а также включает асинхронные методы для эффективного взаимодействия с API.

## Классы

### `Config`

Не описан в предоставленном фрагменте кода. Предположительно, содержит конфигурационные параметры для модуля.

### `GoogleGenerativeAi`

**Описание**: Класс для взаимодействия с моделями Google GenerativeAi.

**Атрибуты**:

*   `api_key` (str): API-ключ для доступа к сервисам Google Generative AI.

*   `dialogue_txt_path` (Path): Путь к файлу, используемому для логирования (инициализируется в `__post_init__`).
*   `generation_config` (Dict): Конфигурация генерации. Определяет параметры, такие как `response_mime_type` (по умолчанию `{"response_mime_type": "text/plain"}`).
*   `system_instruction` (Optional[str]): Системная инструкция для модели.
*   `history_dir` (Path): Директория для хранения истории чата (инициализируется в `__post_init__`).
*   `history_txt_file` (Path): Путь к текстовому файлу истории чата (инициализируется в `__post_init__`).
*   `history_json_file` (Path): Путь к JSON-файлу истории чата (инициализируется в `__post_init__`).
*   `config` (SimpleNamespace): Объект с конфигурацией модели Gemini, загруженной из JSON-файла (инициализируется в `__post_init__`).
*   `chat_history` (List[Dict]): Список диалогов (инициализируется как пустой список).
*   `model` (Any): Объект модели Gemini (инициализируется в `__post_init__`).
*   `chat_name` (str): Имя чата (инициализируется в `chat()`).
*   `timestamp` (str): Временная метка (инициализируется в `__post_init__`).

**Методы**:

*   `__init__`: Инициализирует объект `GoogleGenerativeAi`.
*   `normalize_answer`: Очищает вывод от лишних символов.
*   `_start_chat`: Запускает чат с начальной настройкой.
*   `clear_history`: Очищает историю чата в памяти и удаляет файл истории.
*   `_save_chat_history`: Сохраняет всю историю чата в JSON файл.
*   `_load_chat_history`: Загружает историю чата из JSON файла.
*   `chat`: Обрабатывает чат-запрос с различными режимами управления историей чата.
*   `ask`: Отправляет текстовый запрос модели и возвращает ответ.
*   `ask_async`: Асинхронно отправляет текстовый запрос модели и возвращает ответ.
*   `describe_image`: Отправляет изображение в Gemini Pro Vision и возвращает его текстовое описание.
*   `upload_file`: Загружает файл в Gemini API.

### `__init__`

```python
def __init__(self, api_key: str, 
                 generation_config: Dict = field(default_factory=lambda: {"response_mime_type": "text/plain"}),
                 system_instruction: Optional[str] = None):
    """Инициализация модели GoogleGenerativeAi с дополнительными настройками."""
    ...
```

**Назначение**: Инициализирует объект `GoogleGenerativeAi`.

**Параметры**:

*   `api_key` (str): Ключ API PrestaShop.
*   `generation_config` (Dict, optional): Default data format ('JSON' or 'XML'). Defaults to 'JSON'.
*   `system_instruction` (str, optional): System instructions for the model.

**Как работает функция**:

1.  Инициализирует атрибуты `api_key`, `generation_config`, `system_instruction`.
2.  Загружает конфигурацию из файла `gemini.json`.
3.  Инициализирует модель Gemini с использованием `genai.configure` и `genai.GenerativeModel`.
4.  Запускает чат с использованием метода `_start_chat`.

### `normalize_answer`

```python
def normalize_answer(self, text:str) -> str:
    """Очистка вывода от 
    ```md, ```python, ```json, ```html, ит.п.
    """
    ...
```

**Назначение**: Очищает вывод от лишних символов, таких как префиксы и кавычки.

**Параметры**:
- `text` (str): Текст, который нужно очистить.

**Возвращает**:
- `str`: Очищенный текст.

**Как работает функция**:

1.  Вызывает метод `normalize_answer` из модуля `src.utils.string.ai_string_normalizer` для очистки текста.

### `_start_chat`

```python
def _start_chat(self):
    """Запуск чата с начальной настройкой."""
    ...
```

**Назначение**: Запускает чат с начальной настройкой.

**Как работает функция**:

1.  Инициализирует историю чата, добавляя системную инструкцию, если она присутствует.
2.  Возвращает объект чата, созданный с помощью `self.model.start_chat()`.

### `clear_history`

```python
def clear_history(self):
    """
    Очищает историю чата в памяти и удаляет файл истории, если он существует.
    """
    ...
```

**Назначение**: Очищает историю чата в памяти и удаляет файл истории, если он существует.

**Как работает функция**:

1.  Очищает список `self.chat_history`.
2.  Удаляет файл истории чата, если он существует.

### `_save_chat_history`

```python
async def _save_chat_history(self):
    """Сохраняет всю историю чата в JSON файл"""
    ...
```

**Назначение**: Сохраняет всю историю чата в JSON файл.

**Как работает функция**:

1.  Формирует имя файла для сохранения истории чата.
2.  Сохраняет историю чата в JSON файл с использованием функции `j_dumps`.

### `_load_chat_history`

```python
async def _load_chat_history(self, chat_data_folder: Optional[str | Path]):
    """Загружает историю чата из JSON файла"""
    ...
```

**Назначение**: Загружает историю чата из JSON файла.

**Параметры**:

*   `chat_data_folder` (Optional[str | Path]): Путь к папке с данными чата.

**Как работает функция**:

1.  Формирует путь к файлу истории чата.
2.  Загружает историю чата из JSON файла с использованием функции `j_loads`.
3.  Восстанавливает историю чата в объекте `self._chat`.

### `chat`

```python
async def chat(self, q: str,  chat_name:str, flag: Optional[str] = 'save_chat') -> Optional[str]:
    """
    Обрабатывает чат-запрос с различными режимами управления историей чата.

    Args:
        q (str): Вопрос пользователя.
        chat_name (str):
        flag (Optional[str]): Режим управления историей. Возможные значения: 
                        "save_chat", "read_and_clear", "clear", "start_new".

    Returns:
        Optional[str]: Ответ модели.
    """
    ...
```

**Назначение**: Обрабатывает чат-запрос с различными режимами управления историей чата.

**Параметры**:

*   `q` (str): Вопрос пользователя.
*   `chat_name` (str): The name of the chat.
*   `flag` (Optional[str]): Режим управления историей. Возможные значения: `"save_chat"`, `"read_and_clear"`, `"clear"`, `"start_new"`.

**Возвращает**:

*   `Optional[str]`: Ответ модели.

**Как работает функция**:

1.  Устанавливает имя чата `chat_name`.
2.  В зависимости от значения параметра `flag` выполняет различные действия с историей чата (загрузка, очистка, сохранение).
3.  Отправляет запрос в модель Gemini и получает ответ.
4.  Сохраняет вопрос пользователя и ответ модели в историю чата.

### `ask`

```python
def ask(self, q: str, attempts: int = 15, save_history: bool = False, clean_response:bool = True) -> Optional[str]:
    """
    Метод отправляет текстовый запрос модели и возвращает ответ.
    """
    ...
```

**Назначение**: Отправляет текстовый запрос модели и возвращает ответ.

**Параметры**:

*   `q` (str): Текст запроса.
*   `attempts` (int, optional): Количество попыток повторной отправки запроса в случае неудачи. По умолчанию 15.
*   `save_history` (bool, optional): Флаг, указывающий, нужно ли сохранять диалог в историю. По умолчанию False.
*  `clean_response` (bool, optional): Флаг, указывающий, нужно ли очищать ответ от лишних символов. По умолчанию `True`.

**Возвращает**:

*   `Optional[str]`: Ответ модели или `None` в случае неудачи.

**Как работает функция**:

1.  Выполняет цикл повторных попыток отправки запроса к модели Gemini.
2.  В каждой попытке:
    *   Отправляет запрос с помощью метода `self.model.generate_content`.
    *   Проверяет, получен ли ответ от модели.
    *   В случае неудачи логирует ошибку и делает паузу перед повторной попыткой.
    *   В случае успеха сохраняет диалог в историю (если указано).
    *   Возвращает ответ модели, очищенный от лишних символов (если указано).

### `ask_async`

```python
async def ask_async(self, q: str, attempts: int = 15, save_history: bool = False, clean_response:bool = True) -> Optional[str]:
    """
    Метод асинхронно отправляет текстовый запрос модели и возвращает ответ.
    """
    ...
```

**Назначение**: Асинхронно отправляет текстовый запрос модели и возвращает ответ.

**Параметры**:

*   `q` (str): Текст запроса.
*   `attempts` (int, optional): Количество попыток повторной отправки запроса в случае неудачи. По умолчанию 15.
*   `save_history` (bool, optional): Флаг, указывающий, нужно ли сохранять диалог в историю. По умолчанию False.
*  `clean_response` (bool, optional): Флаг, указывающий, нужно ли очищать ответ от лишних символов. По умолчанию `True`.

**Возвращает**:

*   `Optional[str]`: Ответ модели или `None` в случае неудачи.

**Как работает функция**:

1.  Выполняет цикл повторных попыток отправки запроса к модели Gemini асинхронно.
2.  В каждой попытке:
    *   Отправляет запрос с помощью метода `asyncio.to_thread(self.model.generate_content, q)`.
    *   Проверяет, получен ли ответ от модели.
    *   В случае неудачи логирует ошибку и делает асинхронную паузу перед повторной попыткой.
    *   В случае успеха сохраняет диалог в историю (если указано).
    *   Возвращает ответ модели, очищенный от лишних символов (если указано).

### `describe_image`

```python
def describe_image(
    self, image: Path | bytes, mime_type: Optional[str] = 'image/jpeg', prompt: Optional[str] = ''
) -> Optional[str]:
    """
    Отправляет изображение в Gemini Pro Vision и возвращает его текстовое описание.

    Args:
        image: Путь к файлу изображения или байты изображения

    Returns:
        str: Текстовое описание изображения.
        None: Если произошла ошибка.
    """
    ...
```

**Назначение**: Отправляет изображение в Gemini Pro Vision и возвращает его текстовое описание.

**Параметры**:

*   `image` (Path | bytes): Путь к файлу изображения или байты изображения.
*   `mime_type` (Optional[str]): MIME-тип изображения (по умолчанию `'image/jpeg'`).
*   `prompt` (Optional[str]): Текстовый промпт для описания изображения (по умолчанию `''`).

**Возвращает**:

*   `str`: Текстовое описание изображения.
*   `None`: Если произошла ошибка.

**Как работает функция**:

1.  Подготавливает контент для запроса, преобразуя изображение в байты, если передан путь к файлу.
2.  Формирует запрос к модели Gemini Pro Vision с использованием метода `self.model.generate_content`.
3.  Возвращает текстовое описание изображения, полученное от модели.

### `upload_file`

```python
async def upload_file(
    self, file: str | Path | IOBase, file_name: Optional[str] = None
) -> bool:
    """
    https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai/upload_file.md
    response (file_types.File)
    """
    ...
```

**Назначение**: Загружает файл в Gemini API.

**Параметры**:

*   `file` (str | Path | IOBase): Путь к файлу, имя файла или файловый объект.
*   `file_name` (Optional[str]): Имя файла для Gemini API.

**Возвращает**:

*   `bool`: Объект ответа, если загрузка прошла успешно.

**Как работает функция**:

1.  Вызывает метод `genai.upload_file_async` для загрузки файла в Gemini API.
2.  В случае ошибки пытается удалить загруженный файл и повторить загрузку.

## Функция `main`

В коде отсутствует основная логика запуска (main), что делает невозможным полноценное использование модуля как самостоятельного приложения.

## Зависимости

*   `google.generativeai`
*   `requests`
*   `grpc`
*   `google.api_core.exceptions`
*   `google.auth.exceptions`
*   `src.logger`
*   `src.utils.printer`
*   `src.utils.file`
*   `src.utils.date_time`
*   `src.utils.jjson`
*   `src.utils.image`
*   `src.utils.string.ai_string_normalizer`
"""#:platform: Windows, Unix
:synopsis: Google generative llm integration
https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai.md"""
# Удалите этот мусор

Обратите внимание на отсутствие  значения  переменной `Config` - что является плохой практикой
```
class Config:
    ...
```
- Для использования модуля нужно установить
```
pip install -r requrements.txt
```
- Добавьте API Key

Советую обновить docstring
В коде не предусмотрена обработка исключений
Для чего предназначена функция main???
А так же указать что модуль требует настройки, а так же то, что для работы с ним, требуются google аккаунты
В целом нет примеров кода, но нужно больше и разнообразнее
В коде нужно исправить синтаксис
Оберните в try-except вызов API чтобы корректно обработать ошибки

Измените имя internal_function на более осмысленное (если есть internal function)