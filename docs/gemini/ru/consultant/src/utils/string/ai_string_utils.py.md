### **Анализ кода модуля `ai_string_utils.py`**

## \file hypotez/src/utils/string/ai_string_utils.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
Утилиты для приведения строк к требованиям обучения и нормализации ответов от языковых моделей.
================================================================================================

**Назначение**

Этот модуль предоставляет функции для обработки и очистки строк, включая:
1.  Подготовку текстовых данных для обучающих наборов (экранирование кавычек, удаление лишних пробелов).
2.  Нормализацию ответов от языковых моделей (удаление обрамляющих блоков кода).

 .. module:: src.utils.string.combined_string_utils  # Пример нового пути модуля
"""

import re
from typing import Union, List

# =========================================================================================
# Функции для подготовки данных для обучения (из string_for_train.py)
# =========================================================================================


def string_for_train(data: Union[str, List[str]]) -> str:
    """
    Очищает и форматирует данные для обучения. Функция удаляет повторяющиеся пробелы.

    Экранирует двойные кавычки (`"`) символом обратной косой черты (`\\\\`)
    и заменяет множественные пробельные символы одним пробелом.
    Удаляет начальные и конечные пробелы.

    Args:
        data (Union[str, List[str]]): Входные данные. Могут быть строкой или
                                      списком строк.

    Returns:
        str: Очищенная и объединенная строка (если на входе был список),
             готовая для использования в обучении. Возвращает пустую строку,
             если тип входных данных не строка и не список строк.

    Examples:
        >>> string_for_train('   Это  строка   с "кавычками"   и    пробелами. ')
        'Это строка с \\\\"кавычками\\\\" и пробелами.'
        >>> string_for_train(['Первая строка.', '   Вторая "строка"   с пробелами.'])
        'Первая строка. Вторая \\\\"строка\\\\" с пробелами.'
        >>> string_for_train(None)
        ''
        >>> string_for_train(123)
        ''
    """
    cleaned_text: str = ""

    if isinstance(data, str):
        # Экранирование кавычек и очистка от `\\n`
        cleaned_text = data.replace('"', '\\\\"').replace('\\n','')
        # Удаление повторяющихся пробелов и обрезка краев
        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()
        return cleaned_text
    elif isinstance(data, list):
        # Обработка каждого элемента списка
        processed_items = []
        for item in data:
            if isinstance(item, str):
                # Экранирование кавычек
                cleaned_item = item.replace('"', '\\\\"').replace('\\n','')
                # Нормализация пробелов (но не объединение через re.sub пока)
                processed_items.append(cleaned_item)
            else:
                # Пропустить нестроковые элементы или обработать иначе?
                # В текущей реализации они будут проигнорированы при объединении,
                # но можно добавить логирование или обработку ошибок.
                ...
        # Объединение элементов списка в одну строку через пробел
        cleaned_text = ' '.join(processed_items)
        # Финальное удаление повторяющихся пробелов и обрезка краев всей строки
        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()
        return cleaned_text
    else:
        # Возврат пустой строки для некорректного типа данных
        return ""

# =========================================================================================
# Функции для нормализации ответов ИИ (из ai_response_normalizer.py)
# =========================================================================================

# Список префиксов и суффиксов, обозначающих блоки кода в ответах моделей
_NORMALIZER_PREFIXES: list[str] = [
    '```md\\n',
    '```md ', # Добавим вариант с пробелом
    '```md',
    '```markdown\\n',
    '```markdown ', # Добавим вариант с пробелом
    '```markdown',
    '```html\\n',
    '```html ', # Добавим вариант с пробелом
    '```html',
    '```json\\n', # Добавим другие возможные типы
    '```json ',
    '```json',
    '```python\\n',
    '```python ',
    '```python',
    '```text\\n',
    '```text ',
    '```text',
    '```\\n',
    '``` ',
    '```',
]
_NORMALIZER_SUFFIX: str = '```'


def normalize_answer(text: str) -> str:
    """
    Нормализует текстовый ответ, удаляя обрамляющие блоки кода markdown.

    Проверяет, начинается ли строка `text` одним из префиксов из списка
    `_NORMALIZER_PREFIXES` (например, '```html\\\\n', '```markdown', '```')
    и заканчивается ли она суффиксом `_NORMALIZER_SUFFIX` ('```').
    Если оба условия выполняются, удаляет соответствующий префикс и суффикс.
    В противном случае возвращает исходную строку без изменений.

    Args:
        text (str): Исходная строка текста, потенциально содержащая
                    обрамляющие блоки кода.

    Returns:
        str: Нормализованная строка без начального и конечного блоков кода,
             либо исходная строка, если блоки не найдены.

    Examples:
        >>> normalize_answer("```html\\\\n<p>Пример</p>\\\\n```")
        '<p>Пример</p>\\\\n'
        >>> normalize_answer("```markdown\\n# Заголовок\\nТекст.\\n```")
        '# Заголовок\\\\nТекст.\\\\n'
        >>> normalize_answer("```\\nПросто текст\\n```")
        'Просто текст\\\\n'
        >>> normalize_answer("Обычный текст без блоков.")
        'Обычный текст без блоков.'
        >>> normalize_answer("```Неполный блок")
        '```Неполный блок'
        >>> normalize_answer("Блок в конце```")
        'Блок в конце```'
        >>> normalize_answer("```json\\n{\\"key\\": \\"value\\"}\\n```")
        '{\\"key\\": \\"value\\"}\\n'
        >>> normalize_answer("```md Текст```") # Пример с пробелом после md
        'Текст'
    """
    if not isinstance(text, str):
        # Можно добавить обработку ошибок или вернуть пустую строку/None
        return "" # Или return text, если нужно пропустить не-строки

    normalized_text = text # Начинаем с исходного текста

    for prefix in _NORMALIZER_PREFIXES:
        # Проверяем наличие префикса И суффикса
        if normalized_text.startswith(prefix) and normalized_text.endswith(_NORMALIZER_SUFFIX):
            # Удаляем префикс
            normalized_text = normalized_text.removeprefix(prefix)
            # Удаляем суффикс
            normalized_text = normalized_text.removesuffix(_NORMALIZER_SUFFIX)
            # Так как нашли и удалили, можно выходить из цикла
            break # Важно: прекращаем поиск после первого совпадения

    # Можно добавить .strip() для удаления случайных пробелов по краям после удаления блоков
    # return normalized_text.strip()
    return normalized_text

# =========================================================================================
# Пример использования (можно закомментировать или удалить)
# =========================================================================================
if __name__ == '__main__':
    # Примеры для string_for_train
    print("--- string_for_train ---")
    test_str = '   Это  строка   с "кавычками"   и    пробелами. '
    print(f"Original: '{test_str}'")
    print(f"Cleaned:  '{string_for_train(test_str)}'")

    test_list = ['Первая строка.', '   Вторая "строка"   с пробелами.', ' Третья    ', '   ']
    print(f"Original list: {test_list}")
    print(f"Cleaned list: '{string_for_train(test_list)}'")

    print(f"Invalid input (int): '{string_for_train(123)}'")
    print(f"Invalid input (None): '{string_for_train(None)}'")


    # Примеры для normalize_answer
    print("\\n--- normalize_answer ---")
    tests_norm = [
        "```html\\n<p>Пример</p>\\n```",
        "```markdown\\n# Заголовок\\nТекст.\\n```",
        "```\\nПросто текст\\n```",
        "Обычный текст без блоков.",
        "```Неполный блок",
        "Блок в конце```",
        "```json\\n{\\"key\\": \\"value\\"}\\n```",
        "```md Текст```"
    ]
    for test_case in tests_norm:
        print(f"Original: '{test_case}'")
        print(f"Normalized: '{normalize_answer(test_case)}'")

    print(f"Invalid input (int): '{normalize_answer(123)}'") # type: ignore
```

### **Анализ кода модуля `ai_string_utils.py`**

**Качество кода:**

- **Соответствие стандартам**: 7/10
- **Плюсы**:
    - Код хорошо структурирован и логически разделен на две основные функциональности.
    - Присутствуют docstring для функций с примерами использования.
    - Код достаточно читаемый и понятный.
- **Минусы**:
    - Используется `Union[str, List[str]]`, что не соответствует новым стандартам (следует использовать `str | List[str]`).
    - В некоторых местах отсутствует аннотация типов.
    - Не все комментарии переведены на русский язык.
    - В блоке `else` в функции `string_for_train` с обработкой списка отсутствует логирование или обработка ошибок для нестроковых элементов.
    - Нет обработки исключений.
    - В основном блоке `if __name__ == '__main__'` используется `print` вместо `pprint` из `src.utils.printer`.
    - В примере в конце файла используется конструкция `# type: ignore`, что может указывать на проблему с типизацией, которую следует исправить.

**Рекомендации по улучшению:**

- Заменить `Union[str, List[str]]` на `str | List[str]`.
- Добавить аннотации типов для переменных, где они отсутствуют.
- Перевести все комментарии и docstring на русский язык.
- Добавить логирование или обработку ошибок для нестроковых элементов в функции `string_for_train` при обработке списка.
- Добавить обработку исключений в функции `string_for_train` и `normalize_answer`.
- Использовать `pprint` из `src.utils.printer` вместо `print` в `if __name__ == '__main__'` для единообразного стиля.
- Избавиться от `# type: ignore` в конце файла, исправив проблему с типизацией.
- Добавить заголовок файла, если он отсутствует.

**Оптимизированный код:**

```python
## \file hypotez/src/utils/string/ai_string_utils.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
Модуль для работы со строками при обучении и нормализации ответов от языковых моделей.
=========================================================================================

Модуль содержит функции для подготовки текстовых данных к обучению и нормализации ответов,
полученных от AI-моделей. Он включает в себя:

1.  Функции для очистки и подготовки строк для обучения, такие как экранирование кавычек и удаление лишних пробелов.
2.  Функции для нормализации ответов моделей, включая удаление обрамляющих блоков кода.

Пример использования
----------------------

>>> from src.utils.string.ai_string_utils import string_for_train, normalize_answer
>>> text = '   Это  строка   с "кавычками"   и    пробелами. '
>>> cleaned_text = string_for_train(text)
>>> print(cleaned_text)
'Это строка с \\"кавычками\\" и пробелами.'

>>> ai_response = "```html\\n<p>Пример</p>\\n```"
>>> normalized_response = normalize_answer(ai_response)
>>> print(normalized_response)
'<p>Пример</p>\\n'

.. module:: src.utils.string.ai_string_utils
"""

import re
from typing import List, Optional, Union
from pathlib import Path
from src.logger import logger
from src.utils.printer import pprint

# =========================================================================================
# Функции для подготовки данных для обучения
# =========================================================================================

def string_for_train(data: str | List[str]) -> str:
    """
    Очищает и форматирует данные для обучения. Функция удаляет повторяющиеся пробелы.

    Экранирует двойные кавычки (`"`) символом обратной косой черты (`\\\\`)
    и заменяет множественные пробельные символы одним пробелом.
    Удаляет начальные и конечные пробелы.

    Args:
        data (str | List[str]): Входные данные. Могут быть строкой или списком строк.

    Returns:
        str: Очищенная и объединенная строка (если на входе был список),
             готовая для использования в обучении. Возвращает пустую строку,
             если тип входных данных не строка и не список строк.

    Raises:
        TypeError: Если элемент списка не является строкой.

    Example:
        >>> string_for_train('   Это  строка   с "кавычками"   и    пробелами. ')
        'Это строка с \\\\"кавычками\\\\" и пробелами.'
        >>> string_for_train(['Первая строка.', '   Вторая "строка"   с пробелами.'])
        'Первая строка. Вторая \\\\"строка\\\\" с пробелами.'
        >>> string_for_train(None)
        ''
        >>> string_for_train(123)
        ''
    """
    cleaned_text: str = ""

    if isinstance(data, str):
        # Экранирование кавычек и очистка от символов новой строки
        cleaned_text = data.replace('"', '\\\\"').replace('\\n','')
        # Удаление повторяющихся пробелов и обрезка краев
        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()
        return cleaned_text
    elif isinstance(data, list):
        # Обработка каждого элемента списка
        processed_items: List[str] = []
        for item in data:
            if isinstance(item, str):
                # Экранирование кавычек
                cleaned_item: str = item.replace('"', '\\\\"').replace('\\n','')
                # Нормализация пробелов (но не объединение через re.sub пока)
                processed_items.append(cleaned_item)
            else:
                # Логирование ошибки, если элемент списка не является строкой
                msg = f"Элемент списка не является строкой: {item}"
                logger.error(msg, exc_info=True)
                raise TypeError(msg)

        # Объединение элементов списка в одну строку через пробел
        cleaned_text = ' '.join(processed_items)
        # Финальное удаление повторяющихся пробелов и обрезка краев всей строки
        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()
        return cleaned_text
    else:
        # Возврат пустой строки для некорректного типа данных
        return ""

# =========================================================================================
# Функции для нормализации ответов ИИ
# =========================================================================================

# Список префиксов и суффиксов, обозначающих блоки кода в ответах моделей
_NORMALIZER_PREFIXES: List[str] = [
    '```md\\n',
    '```md ', # Добавим вариант с пробелом
    '```md',
    '```markdown\\n',
    '```markdown ', # Добавим вариант с пробелом
    '```markdown',
    '```html\\n',
    '```html ', # Добавим вариант с пробелом
    '```html',
    '```json\\n', # Добавим другие возможные типы
    '```json ',
    '```json',
    '```python\\n',
    '```python ',
    '```python',
    '```text\\n',
    '```text ',
    '```text',
    '```\\n',
    '``` ',
    '```',
]
_NORMALIZER_SUFFIX: str = '```'


def normalize_answer(text: str) -> str:
    """
    Нормализует текстовый ответ, удаляя обрамляющие блоки кода markdown.

    Функция проверяет, начинается ли строка `text` одним из префиксов из списка
    `_NORMALIZER_PREFIXES` (например, '```html\\\\n', '```markdown', '```')
    и заканчивается ли она суффиксом `_NORMALIZER_SUFFIX` ('```').
    Если оба условия выполняются, удаляет соответствующий префикс и суффикс.
    В противном случае возвращает исходную строку без изменений.

    Args:
        text (str): Исходная строка текста, потенциально содержащая
                    обрамляющие блоки кода.

    Returns:
        str: Нормализованная строка без начального и конечного блоков кода,
             либо исходная строка, если блоки не найдены.

    Example:
        >>> normalize_answer("```html\\\\n<p>Пример</p>\\\\n```")
        '<p>Пример</p>\\\\n'
        >>> normalize_answer("```markdown\\n# Заголовок\\nТекст.\\n```")
        '# Заголовок\\\\nТекст.\\\\n'
        >>> normalize_answer("```\\nПросто текст\\n```")
        'Просто текст\\\\n'
        >>> normalize_answer("Обычный текст без блоков.")
        'Обычный текст без блоков.'
        >>> normalize_answer("```Неполный блок")
        '```Неполный блок'
        >>> normalize_answer("Блок в конце```")
        'Блок в конце```'
        >>> normalize_answer("```json\\n{\\"key\\": \\"value\\"}\\n```")
        '{\\"key\\": \\"value\\"}\\n'
        >>> normalize_answer("```md Текст```") # Пример с пробелом после md
        'Текст'
    """
    if not isinstance(text, str):
        # Логирование предупреждения о некорректном типе данных
        msg = f"Некорректный тип данных: {type(text)}. Ожидается строка."
        logger.warning(msg, exc_info=True)
        return ""

    normalized_text: str = text  # Функция начинает с исходного текста

    for prefix in _NORMALIZER_PREFIXES:
        # Проверка наличия префикса и суффикса
        if normalized_text.startswith(prefix) and normalized_text.endswith(_NORMALIZER_SUFFIX):
            # Удаление префикса
            normalized_text = normalized_text.removeprefix(prefix)
            # Удаление суффикса
            normalized_text = normalized_text.removesuffix(_NORMALIZER_SUFFIX)
            # Прекращение поиска после первого совпадения
            break

    return normalized_text

# =========================================================================================
# Пример использования
# =========================================================================================
if __name__ == '__main__':
    # Примеры для string_for_train
    pprint("--- string_for_train ---")
    test_str: str = '   Это  строка   с "кавычками"   и    пробелами. '
    pprint(f"Original: '{test_str}'")
    pprint(f"Cleaned:  '{string_for_train(test_str)}'")

    test_list: List[str] = ['Первая строка.', '   Вторая "строка"   с пробелами.', ' Третья    ', '   ']
    pprint(f"Original list: {test_list}")
    pprint(f"Cleaned list: '{string_for_train(test_list)}'")

    pprint(f"Invalid input (int): '{string_for_train(123)}'")
    pprint(f"Invalid input (None): '{string_for_train(None)}'")

    # Примеры для normalize_answer
    pprint("\\n--- normalize_answer ---")
    tests_norm: List[str] = [
        "```html\\n<p>Пример</p>\\n```",
        "```markdown\\n# Заголовок\\nТекст.\\n```",
        "```\\nПросто текст\\n```",
        "Обычный текст без блоков.",
        "```Неполный блок",
        "Блок в конце```",
        "```json\\n{\\"key\\": \\"value\\"}\\n```",
        "```md Текст```"
    ]
    for test_case in tests_norm:
        pprint(f"Original: '{test_case}'")
        pprint(f"Normalized: '{normalize_answer(test_case)}'")

    pprint(f"Invalid input (int): '{normalize_answer(123)}'")