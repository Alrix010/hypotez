# Модуль `Ails.py`

## Обзор

Модуль предоставляет функциональность для взаимодействия с моделью `gpt-3.5-turbo` через API `ai.ls`. Он включает в себя функции для создания запросов к API и обработки ответов, а также вспомогательные классы для форматирования данных и расчета хешей.

## Подробнее

Модуль предназначен для использования в качестве провайдера для библиотеки `g4f`. Он определяет параметры подключения к API, такие как URL и модель, а также поддерживает потоковую передачу данных. Для аутентификации используется `Bearer free`. Модуль содержит вспомогательный класс `Utils` для выполнения хеширования и форматирования временных меток, а также функцию `_create_completion` для создания запросов и обработки ответов от API.

## Классы

### `Utils`

Класс содержит статические методы для выполнения вспомогательных операций, таких как хеширование данных и форматирование временных меток.

**Методы:**

- `hash(json_data: Dict[str, str]) -> sha256`
- `format_timestamp(timestamp: int) -> str`

#### `hash`

```python
def hash(json_data: Dict[str, str]) -> sha256:
    """
    Вычисляет SHA256 хеш на основе предоставленных JSON данных.

    Args:
        json_data (Dict[str, str]): Словарь с данными для хеширования.

    Returns:
        sha256: SHA256 хеш, представленный в виде шестнадцатеричной строки.

    Как работает функция:
    - Определяется секретный ключ в виде массива байтов.
    - Формируется базовая строка на основе значений 't' (timestamp), 'm' (message) из `json_data`,
    фиксированной строки 'WI,2rU#_r:r~aF4aJ36[.Z(/8Rv93Rf' и длины сообщения 'm'.
    - Вычисляется SHA256 хеш базовой строки.

    Примеры:
        >>> json_data = {'t': '1678886400000', 'm': 'Hello'}
        >>> Utils.hash(json_data)
        'e5b7e4b8a7e2b9c8a7e3b2c8a7e4b9c8a7e3b2c8a7e4b9c8a7e3b2c8a7e4b9c8'
    """
    ...
```

#### `format_timestamp`

```python
def format_timestamp(timestamp: int) -> str:
    """
    Форматирует временную метку, приводя её к виду, где последняя цифра является четной.

    Args:
        timestamp (int): Временная метка в виде целого числа.

    Returns:
        str: Отформатированная временная метка в виде строки.

    Как работает функция:
    - Извлекает последнюю цифру из временной метки.
    - Если последняя цифра четная, то добавляет 1.
    - Если последняя цифра нечетная, то оставляет её без изменений.
    - Формирует новую временную метку, заменяя последнюю цифру на полученную.

    Примеры:
        >>> Utils.format_timestamp(1678886405000)
        '1678886406000'
        >>> Utils.format_timestamp(1678886404000)
        '1678886404000'
    """
    ...
```

## Функции

### `_create_completion`

```python
def _create_completion(model: str, messages: list, temperature: float = 0.6, stream: bool = False, **kwargs):
    """
    Создает запрос к API для получения завершения текста.

    Args:
        model (str): Идентификатор модели для генерации текста.
        messages (list): Список сообщений для передачи в модель.
        temperature (float, optional): Температура генерации текста. По умолчанию 0.6.
        stream (bool, optional): Флаг, указывающий на необходимость потоковой передачи данных. По умолчанию False.
        **kwargs: Дополнительные параметры для передачи в API.

    Yields:
        str: Часть сгенерированного текста, полученная в процессе потоковой передачи.

    Как работает функция:
    - Формирует заголовки запроса, включая авторизацию, идентификатор клиента и тип контента.
    - Формирует параметры запроса, включая флаг полной генерации.
    - Форматирует временную метку с использованием `Utils.format_timestamp`.
    - Вычисляет подпись запроса с использованием `Utils.hash`.
    - Формирует JSON данные для отправки в API, включая модель, температуру, сообщения и подпись.
    - Отправляет POST запрос к API `https://api.caipacity.com/v1/chat/completions` с потоковой передачей данных.
    - Итерируется по ответу от API, извлекая части сгенерированного текста из каждого токена.

    Примеры:
        >>> messages = [{'role': 'user', 'content': 'Hello'}]
        >>> for token in _create_completion(model='gpt-3.5-turbo', messages=messages, stream=True):
        ...     print(token, end='')
        Hello!
    """
    ...