# Модуль `You`

## Обзор

Модуль предоставляет реализацию провайдера `You` для использования в проекте `hypotez`. Провайдер `You` позволяет взаимодействовать с моделью You.com с использованием модели `gpt-3.5-turbo`. 

## Подробней

Модуль использует `subprocess` для вызова скрипта `you.py` из `helpers`, расположенного в той же директории. Скрипт `you.py`  в свою очередь взаимодействует с API You.com для получения ответа от модели `gpt-3.5-turbo`. 

## Классы

### `_create_completion`

**Описание**: Функция создает завершение (ответ) от модели You.com.

**Параметры**:

- `model` (str): Имя модели, используемой для генерации ответа.
- `messages` (list): Список сообщений, которые передаются в модель.
- `stream` (bool): Флаг, указывающий, нужно ли использовать потоковый режим ответа.
- `**kwargs`: Дополнительные параметры, передаваемые в модель.

**Возвращает**:

- `Generator[str, None, None]`: Генератор строк, представляющих части ответа модели.

**Как работает функция**:

1. Функция определяет путь к директории, где находится файл `you.py`.
2. Создается JSON-строка с сообщениями (`messages`) для передачи в модель.
3. Формируется команда для вызова `you.py` с JSON-конфигурацией в качестве аргумента.
4. Используя `subprocess.Popen`, запускается процесс `you.py` с перенаправлением стандартного вывода (`stdout`) и стандартного потока ошибок (`stderr`) в `subprocess.PIPE`.
5. Функция `iter(p.stdout.readline, b'')`  итерирует по строкам стандартного вывода  `you.py`. 
6.  Каждая строка преобразуется в текст (`decode('utf-8')`)  и  возвращается как часть ответа от модели.
7.  Функция возвращает  генератор строк.


**Примеры**:

```python
# Пример вызова функции
from hypotez.src.endpoints.freegpt-webui-ru.g4f.Provider.Providers.You import _create_completion

model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Привет, как дела?"}]
stream = True
response = _create_completion(model, messages, stream)

# Итерирование по частям ответа
for part in response:
    print(part)