# Модуль Ails

## Обзор

Модуль содержит класс `Ails`, который предоставляет асинхронный генератор для получения ответов от модели GPT-3.5-turbo от сервиса ai.ls.

## Подробей

Модуль `Ails` использует API сервиса ai.ls для работы с моделью GPT-3.5-turbo. Класс `Ails` наследует от базового класса `AsyncGeneratorProvider`, который определяет общий интерфейс для всех асинхронных генераторов. 

## Классы

### `class Ails`

**Описание**: Класс, который предоставляет асинхронный генератор для получения ответов от модели GPT-3.5-turbo от сервиса ai.ls.

**Наследует**: `AsyncGeneratorProvider`

**Атрибуты**:

- `url`: URL-адрес API сервиса ai.ls
- `working`: Флаг, указывающий на то, что генератор работает
- `supports_message_history`: Флаг, указывающий на то, что модель поддерживает историю сообщений
- `supports_gpt_35_turbo`: Флаг, указывающий на то, что модель поддерживает GPT-3.5-turbo

**Методы**:

- `create_async_generator()`: Асинхронная функция, которая создает генератор для получения ответов от модели GPT-3.5-turbo.

**Параметры**:

- `model`: Имя модели (например, `gpt-3.5-turbo`).
- `messages`: Список сообщений для модели.
- `stream`: Флаг, указывающий на то, что нужно использовать потоковый режим.
- `proxy`: URL-адрес прокси-сервера.
- `kwargs`: Дополнительные параметры для модели (например, `temperature`).

**Возвращает**: 

- `AsyncResult`: Асинхронный генератор, который выдает токены ответа модели.

**Вызывает исключения**:

- `Exception`: Если происходит ошибка при отправке запроса или при получении ответа.

#### **Внутренние функции**:

##### `_hash(json_data: dict[str, str]) -> SHA256`

**Назначение**:  Функция генерирует хэш-сумму для данных, передаваемых в API ai.ls.

**Параметры**: 

- `json_data (dict[str, str])`: Словарь с данными для хэширования.

**Возвращает**: 

- `SHA256`: Строка с хэш-суммой.

**Как работает функция**: 

Функция формирует строку, объединяя время, текст последнего сообщения и несколько констант. Затем эта строка хэшируется с помощью алгоритма SHA256 и возвращается как строка. 

**Примеры**:

```python
>>> _hash({"t": "1690201600000", "m": "Hello, world!"})
'd7316f11c0269328f7c340154241506b80f5d6b7964c4c413c43327b66471772'
```

##### `_format_timestamp(timestamp: int) -> str`

**Назначение**: Функция форматирует временную метку в нужном формате для API ai.ls.

**Параметры**:

- `timestamp (int)`: Временная метка в миллисекундах.

**Возвращает**: 

- `str`:  Форматированная строка с временной меткой.

**Как работает функция**: 

Функция вычисляет остаток от деления временной метки на 10 и добавляет 1, если остаток четный. Затем она вычитает остаток из исходной временной метки и добавляет результат к остатку. 

**Примеры**:

```python
>>> _format_timestamp(1690201600000)
'1690201600001'
```

## Методы класса

### `create_async_generator(model: str, messages: Messages, stream: bool, proxy: str = None, **kwargs) -> AsyncResult`

**Назначение**: 

Функция создает асинхронный генератор для получения ответов от модели GPT-3.5-turbo от сервиса ai.ls.

**Параметры**:

- `model (str)`: Имя модели (например, `gpt-3.5-turbo`).
- `messages (Messages)`: Список сообщений для модели.
- `stream (bool)`: Флаг, указывающий на то, что нужно использовать потоковый режим.
- `proxy (str, optional)`: URL-адрес прокси-сервера. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры для модели (например, `temperature`).

**Возвращает**:

- `AsyncResult`: Асинхронный генератор, который выдает токены ответа модели.

**Вызывает исключения**:

- `Exception`: Если происходит ошибка при отправке запроса или при получении ответа.

**Как работает функция**: 

Функция формирует заголовок запроса, включающий информацию о клиенте, модели, языке и прокси-сервере. Затем она отправляет запрос на API ai.ls с использованием `aiohttp` и  обрабатывает ответ. После этого она возвращает асинхронный генератор, который выдает токены ответа модели. 

**Примеры**:

```python
>>> messages = [
...     {"role": "user", "content": "Hello, world!"},
... ]
>>> async for token in Ails.create_async_generator(model='gpt-3.5-turbo', messages=messages, stream=True):
...     print(token, end='')
Hello, world!
```

## Параметры класса

- `url`: URL-адрес API сервиса ai.ls.
- `working`: Флаг, указывающий на то, что генератор работает.
- `supports_message_history`: Флаг, указывающий на то, что модель поддерживает историю сообщений.
- `supports_gpt_35_turbo`: Флаг, указывающий на то, что модель поддерживает GPT-3.5-turbo.

## Примеры

```python
# Импорт модуля
from hypotez.src.endpoints.gpt4free.g4f.Provider.deprecated import Ails

# Создание экземпляра класса
provider = Ails()

# Создание списка сообщений
messages = [
    {"role": "user", "content": "Привет, как дела?"},
]

# Получение ответа от модели GPT-3.5-turbo
async for token in provider.create_async_generator(model='gpt-3.5-turbo', messages=messages, stream=True):
    print(token, end='')

# Вывод:
# Привет! У меня все отлично. А как у тебя дела?
```