# Модуль `GeekGpt`

## Обзор

Модуль `GeekGpt` предоставляет класс `GeekGpt`, который является провайдером для взаимодействия с API GeekGpt. Он поддерживает потоковую передачу данных, историю сообщений, а также модели `gpt-3.5-turbo` и `gpt-4`.

## Подробнее

Модуль предназначен для интеграции с сервисом GeekGpt через его API. Он позволяет отправлять запросы на создание завершений (completions) с использованием различных моделей и параметров, а также получать ответы в потоковом режиме.

## Классы

### `GeekGpt(AbstractProvider)`

**Описание**: Класс `GeekGpt` предоставляет реализацию для взаимодействия с API GeekGpt.

**Наследует**:
- `AbstractProvider`: Абстрактный класс, определяющий интерфейс для провайдеров.

**Атрибуты**:
- `url` (str): URL-адрес сервиса GeekGpt.
- `working` (bool): Указывает, является ли провайдер рабочим.
- `supports_message_history` (bool): Поддерживает ли провайдер историю сообщений.
- `supports_stream` (bool): Поддерживает ли провайдер потоковую передачу.
- `supports_gpt_35_turbo` (bool): Поддерживает ли провайдер модель `gpt-3.5-turbo`.
- `supports_gpt_4` (bool): Поддерживает ли провайдер модель `gpt-4`.

**Методы**:
- `create_completion()`: Создает запрос на завершение и возвращает результат в потоковом режиме.

## Методы класса

### `create_completion(model: str, messages: Messages, stream: bool, **kwargs) -> CreateResult`

```python
@classmethod
def create_completion(
    cls,
    model: str,
    messages: Messages,
    stream: bool,
    **kwargs
) -> CreateResult:
    """Создает запрос на завершение и возвращает результат в потоковом режиме.

    Args:
        model (str): Название модели для использования.
        messages (Messages): Список сообщений для отправки.
        stream (bool): Флаг, указывающий, использовать ли потоковый режим.
        **kwargs: Дополнительные аргументы для запроса.

    Returns:
        CreateResult: Генератор, возвращающий части завершения.

    Raises:
        RuntimeError: Если происходит ошибка при обработке ответа от API.

    Как работает функция:
    - Устанавливает модель, если она не указана.
    - Формирует JSON-данные для запроса, включая сообщения, модель, температуру, штрафы и флаг потоковой передачи.
    - Устанавливает заголовки для запроса, включая токен авторизации и тип контента.
    - Отправляет POST-запрос к API и обрабатывает ответ в потоковом режиме.
    - Итерируется по частям ответа, извлекает контент и возвращает его.
    - Обрабатывает ошибки, возникающие при разборе JSON-ответа.

    Внутренние функции:
        отсутствуют

    Примеры:
        >>> messages = [{"role": "user", "content": "Hello, world!"}]
        >>> for chunk in GeekGpt.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True):
        ...     print(chunk, end="")
    """
```

## Параметры класса

- `model` (str): Определяет, какую языковую модель использовать для генерации текста. Если значение не передано, по умолчанию используется `"gpt-3.5-turbo"`.
- `messages` (Messages): Список сообщений, отправляемых в API. Каждое сообщение содержит роль (например, `"user"` или `"assistant"`) и контент сообщения.
- `stream` (bool): Указывает, следует ли использовать потоковый режим для получения ответа. Если `True`, ответ будет возвращаться частями по мере их генерации.
- `kwargs` (dict): Дополнительные параметры, такие как `temperature` (температура, определяющая случайность выбора токенов), `presence_penalty` (штраф за присутствие новых токенов), `top_p` (вероятность выбора наиболее вероятных токенов) и `frequency_penalty` (штраф за частоту использования токенов).

## Примеры

```python
messages = [{"role": "user", "content": "Hello, world!"}]
for chunk in GeekGpt.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True):
    print(chunk, end="")
```
Этот пример демонстрирует отправку простого сообщения `"Hello, world!"` к модели `"gpt-3.5-turbo"` и потоковую печать ответа.