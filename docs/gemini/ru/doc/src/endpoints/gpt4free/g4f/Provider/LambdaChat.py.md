# LambdaChat

## Обзор

Модуль `LambdaChat` - это класс, который предоставляет доступ к сервису чат-ботов Lambda Chat. 

## Подробнее

Класс `LambdaChat` наследует от `HuggingChat` и расширяет его функциональность для взаимодействия с платформой Lambda Chat. 

## Классы

### `LambdaChat`

**Описание**: Класс `LambdaChat` предоставляет доступ к сервису чат-ботов Lambda Chat.

**Наследует**: `HuggingChat`

**Атрибуты**:

- `label` (str): Название платформы, в данном случае "Lambda Chat".
- `domain` (str): Домен платформы, в данном случае "lambda.chat".
- `origin` (str): URL-адрес платформы, формируется на основе `domain`.
- `url` (str): URL-адрес платформы, совпадает с `origin`.
- `working` (bool): Флаг, указывающий на работоспособность сервиса. В данном случае `True`.
- `use_nodriver` (bool): Флаг, указывающий на необходимость использования веб-драйвера. В данном случае `False`.
- `needs_auth` (bool): Флаг, указывающий на необходимость авторизации для доступа к сервису. В данном случае `False`.
- `default_model` (str): Название модели по умолчанию, в данном случае "deepseek-llama3.3-70b".
- `reasoning_model` (str): Название модели для рассуждений, в данном случае "deepseek-r1".
- `image_models` (list): Список моделей, поддерживающих работу с изображениями, в данном случае пустой список.
- `fallback_models` (list): Список моделей, которые используются в качестве резервных, если основные модели недоступны.
- `models` (list): Список всех доступных моделей, скопированный из `fallback_models`.
- `model_aliases` (dict): Словарь с псевдонимами моделей, которые могут использоваться вместо полных названий.

**Принцип работы**:

Класс `LambdaChat` использует настройки, определенные в атрибутах, для взаимодействия с платформой Lambda Chat. Он предоставляет доступ к различным моделям и функциям, которые могут использоваться для создания чат-ботов, обработки текста, рассуждений и других задач.

**Методы**:

- Все методы класса `LambdaChat` наследуются от класса `HuggingChat`.

**Примеры**:

```python
# Создание инстанса класса LambdaChat
chat = LambdaChat()

# Получение списка доступных моделей
models = chat.get_available_models()

# Вызов модели по умолчанию
response = chat.query("Привет, мир!", model=chat.default_model)

# Вызов модели для рассуждений
response = chat.query("Почему небо синее?", model=chat.reasoning_model)
```

## Методы класса

### `__init__`

```python
    def __init__(self, **kwargs: Any):
        """Инициализирует класс `LambdaChat`."""
```
 
**Назначение**: Инициализирует класс `LambdaChat`.

**Параметры**:

- `**kwargs` (Any): Дополнительные аргументы, передаваемые в конструктор.

**Возвращает**: None

**Вызывает исключения**: None

**Пример**:

```python
# Создание инстанса класса LambdaChat
chat = LambdaChat()
```

### `get_available_models`

```python
    def get_available_models(self) -> list[str]:
        """Возвращает список доступных моделей для сервиса Lambda Chat."""
```

**Назначение**: Возвращает список доступных моделей для сервиса Lambda Chat.

**Параметры**: None

**Возвращает**:
- `list[str]`: Список названий доступных моделей.

**Вызывает исключения**: None

**Пример**:

```python
# Получение списка доступных моделей
models = chat.get_available_models()
```

### `query`

```python
    def query(self, text: str, model: str | None = None, **kwargs: Any) -> dict | None:
        """Отправляет запрос к модели Lambda Chat."""
```

**Назначение**: Отправляет запрос к модели Lambda Chat.

**Параметры**:

- `text` (str): Текст запроса.
- `model` (str | None, optional): Название модели, которую нужно использовать для обработки запроса. По умолчанию используется `default_model`.
- `**kwargs` (Any): Дополнительные аргументы, передаваемые в метод.

**Возвращает**:
- `dict | None`: Словарь с ответом модели или `None` в случае ошибки.

**Вызывает исключения**: None

**Пример**:

```python
# Отправка запроса к модели по умолчанию
response = chat.query("Привет, мир!")

# Отправка запроса к другой модели
response = chat.query("Почему небо синее?", model="deepseek-r1")
```

## Параметры класса

- `label` (str): Название платформы, в данном случае "Lambda Chat".
- `domain` (str): Домен платформы, в данном случае "lambda.chat".
- `origin` (str): URL-адрес платформы, формируется на основе `domain`.
- `url` (str): URL-адрес платформы, совпадает с `origin`.
- `working` (bool): Флаг, указывающий на работоспособность сервиса. В данном случае `True`.
- `use_nodriver` (bool): Флаг, указывающий на необходимость использования веб-драйвера. В данном случае `False`.
- `needs_auth` (bool): Флаг, указывающий на необходимость авторизации для доступа к сервису. В данном случае `False`.
- `default_model` (str): Название модели по умолчанию, в данном случае "deepseek-llama3.3-70b".
- `reasoning_model` (str): Название модели для рассуждений, в данном случае "deepseek-r1".
- `image_models` (list): Список моделей, поддерживающих работу с изображениями, в данном случае пустой список.
- `fallback_models` (list): Список моделей, которые используются в качестве резервных, если основные модели недоступны.
- `models` (list): Список всех доступных моделей, скопированный из `fallback_models`.
- `model_aliases` (dict): Словарь с псевдонимами моделей, которые могут использоваться вместо полных названий.