# Модуль Vercel для работы с провайдером gpt4free
## Обзор

Модуль `Vercel` предоставляет реализацию для взаимодействия с моделями OpenAI через платформу Vercel. Он использует API Vercel для создания и стриминга ответов от языковых моделей, таких как `gpt-3.5-turbo`. Модуль поддерживает работу с прокси и предоставляет механизм для обхода защиты от ботов.

## Подробнее

Этот модуль является частью проекта `hypotez` и предназначен для интеграции с различными AI-моделями, доступными через Vercel. Он обеспечивает возможность отправки запросов к моделям и получения ответов в режиме реального времени. Для работы модуля требуется установка дополнительных зависимостей, таких как `PyExecJS`.

## Классы

### `Vercel`
**Описание**: Класс `Vercel` реализует интерфейс `AbstractProvider` и предоставляет методы для взаимодействия с API Vercel.

**Наследует**: `AbstractProvider`

**Атрибуты**:
- `url` (str): URL для взаимодействия с API Vercel (`https://sdk.vercel.ai`).
- `working` (bool): Флаг, указывающий на работоспособность провайдера (по умолчанию `False`).
- `supports_message_history` (bool): Флаг, указывающий на поддержку истории сообщений (по умолчанию `True`).
- `supports_gpt_35_turbo` (bool): Флаг, указывающий на поддержку модели `gpt-3.5-turbo` (по умолчанию `True`).
- `supports_stream` (bool): Флаг, указывающий на поддержку стриминга ответов (по умолчанию `True`).

**Методы**:
- `create_completion(model: str, messages: Messages, stream: bool, proxy: str = None, **kwargs) -> CreateResult`:
    Метод для создания запроса к API Vercel и получения ответа от языковой модели.

    **Принцип работы**:
    1. Проверяет наличие установленных зависимостей (`PyExecJS`).
    2. Определяет модель для запроса.
    3. Формирует заголовки запроса, включая токен для обхода защиты от ботов.
    4. Формирует JSON-данные для запроса, включая модель, сообщения и параметры.
    5. Отправляет POST-запрос к API Vercel и получает ответ в режиме стриминга.
    6. Обрабатывает ответ и возвращает его в виде генератора токенов.
    7. В случае ошибки повторяет попытку запроса несколько раз.

### `ModelInfo`

**Описание**: `ModelInfo` - это TypedDict, используемый для определения структуры данных, содержащей информацию о модели, такую как её идентификатор и параметры по умолчанию.

**Атрибуты**:

-   `id` (str): Идентификатор модели.
-   `default_params` (dict[str, Any]): Параметры по умолчанию для модели.

## Функции

### `create_completion`

```python
@staticmethod
def create_completion(
    model: str,
    messages: Messages,
    stream: bool,
    proxy: str = None,
    **kwargs
) -> CreateResult:
    """Создает запрос к API Vercel и возвращает ответ от языковой модели.

    Args:
        model (str): Идентификатор модели для использования.
        messages (Messages): Список сообщений для отправки в модель.
        stream (bool): Флаг, указывающий, нужно ли возвращать ответ в режиме стриминга.
        proxy (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
        **kwargs: Дополнительные параметры для передачи в API Vercel.

    Returns:
        CreateResult: Генератор токенов ответа от модели.

    Raises:
        MissingRequirementsError: Если не установлен пакет `PyExecJS`.
        ValueError: Если указанная модель не поддерживается Vercel.
    """
    ...
```

**Назначение**: Функция `create_completion` отправляет запрос к API Vercel для получения ответа от языковой модели. Она обрабатывает параметры запроса, формирует необходимые заголовки и данные, а также обеспечивает стриминг ответа.

**Параметры**:
- `model` (str): Идентификатор модели для использования. Если не указан, используется `gpt-3.5-turbo`.
- `messages` (Messages): Список сообщений для отправки в модель.
- `stream` (bool): Флаг, указывающий, нужно ли возвращать ответ в режиме стриминга.
- `proxy` (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры для передачи в API Vercel.

**Возвращает**:
- `CreateResult`: Генератор токенов ответа от модели.

**Вызывает исключения**:
- `MissingRequirementsError`: Если не установлен пакет `PyExecJS`.
- `ValueError`: Если указанная модель не поддерживается Vercel.

**Внутренние функции**:
- Отсутствуют

**Как работает функция**:
1. Проверяет наличие установленных зависимостей (`PyExecJS`).
2. Определяет модель для запроса. Если модель не указана, используется `gpt-3.5-turbo`. Если указанная модель не поддерживается, выбрасывается исключение `ValueError`.
3. Формирует заголовки запроса, включая токен для обхода защиты от ботов, полученный с помощью функции `get_anti_bot_token`.
4. Формирует JSON-данные для запроса, включая модель, сообщения и параметры.
5. Отправляет POST-запрос к API Vercel (`https://chat.vercel.ai/api/chat`) и получает ответ в режиме стриминга.
6. Обрабатывает ответ и возвращает его в виде генератора токенов.
7. В случае ошибки повторяет попытку запроса несколько раз (максимальное количество попыток определяется параметром `max_retries` в `kwargs`).

**Примеры**:

```python
# Пример использования функции create_completion
model = 'gpt-3.5-turbo'
messages = [{'role': 'user', 'content': 'Hello, how are you?'}]
stream = True
proxy = 'http://your_proxy:8080'

try:
    result = Vercel.create_completion(model=model, messages=messages, stream=stream, proxy=proxy)
    for token in result:
        print(token, end='')
except MissingRequirementsError as ex:
    print(f'Error: {ex}')
except ValueError as ex:
    print(f'Error: {ex}')
```

### `get_anti_bot_token`

```python
def get_anti_bot_token() -> str:
    """Получает токен для обхода защиты от ботов.

    Returns:
        str: Токен для обхода защиты от ботов.
    """
    ...
```

**Назначение**: Функция `get_anti_bot_token` получает токен, необходимый для обхода защиты от ботов на платформе Vercel. Этот токен используется в заголовках запроса для успешной аутентификации и получения доступа к API.

**Параметры**:
- Отсутствуют

**Возвращает**:
- `str`: Токен для обхода защиты от ботов.

**Вызывает исключения**:
- Отсутствуют

**Внутренние функции**:
- Отсутствуют

**Как работает функция**:
1. Формирует заголовки запроса.
2. Отправляет GET-запрос к API Vercel (`https://sdk.vercel.ai/openai.jpeg`) для получения данных, необходимых для генерации токена.
3. Декодирует полученные данные из формата base64.
4. Формирует JavaScript-скрипт на основе декодированных данных.
5. Выполняет JavaScript-скрипт с помощью `execjs` для получения токена.
6. Формирует JSON-данные, содержащие полученный токен и дополнительную информацию.
7. Кодирует JSON-данные в формат base64 и возвращает результат.

**Примеры**:

```python
# Пример использования функции get_anti_bot_token
token = get_anti_bot_token()
print(f'Anti-bot token: {token}')
```

### `model_info`

**Описание**: `model_info` - это словарь, содержащий информацию о поддерживаемых моделях, включая их идентификаторы и параметры по умолчанию.

**Тип**: `dict[str, ModelInfo]`

**Примеры**:

```python
model_info: dict[str, ModelInfo] = {
    'replicate/llama70b-v2-chat': {
        'id': 'replicate:replicate/llama-2-70b-chat',
        'default_params': {
            'temperature': 0.75,
            'maximumLength': 3000,
            'topP': 1,
            'repetitionPenalty': 1,
        },
    },
    ...
}
```

## Параметры класса

- Отсутствуют