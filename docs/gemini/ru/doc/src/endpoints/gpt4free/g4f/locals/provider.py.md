# Модуль `provider`

## Обзор

Модуль `provider` предоставляет класс `LocalProvider`, который позволяет использовать локальные модели GPT4All для генерации ответов. Он также предоставляет функцию `find_model_dir`, которая находит путь к каталогу, в котором хранится локальная модель.

## Подробнее

В проекте `hypotez` модуль `provider` используется для реализации локальной работы с моделями GPT4All. Он предоставляет функцию `create_completion`, которая генерирует текст с помощью выбранной модели. Модуль также реализует функцию `find_model_dir`, которая определяет местоположение модели на диске.

## Классы

### `class LocalProvider`

**Описание**: 
Класс `LocalProvider` обеспечивает  функциональность взаимодействия с локальными моделями GPT4All. 

**Методы**:

- `create_completion(model: str, messages: Messages, stream: bool = False, **kwargs)`: 
    - **Назначение**: Эта функция генерирует текст с использованием выбранной модели GPT4All. Она принимает на вход имя модели, список сообщений и параметры, такие как `stream`.
    - **Параметры**:
        - `model` (str): Название модели GPT4All (например, `'gpt4all-lora-13b'`).
        - `messages` (Messages): Список сообщений в чате.
        - `stream` (bool): Если True, генерирует текст потоковым способом.
    - **Возвращает**:
        - str: Сгенерированный текст.
    - **Как работает**:
        - Проверяет, существует ли модель в списке доступных моделей.
        - Определяет путь к файлу модели и находит каталог, в котором он хранится.
        - Если файл модели не найден, предлагает пользователю загрузить его.
        - Инициализирует объект `GPT4All` и использует его для генерации текста с помощью заданного контекста (списка сообщений).
        - Использует функцию `should_not_stop` для определения окончания генерации.
        - Если `stream` = True, генерирует текст по частям (потоком), иначе генерирует весь текст за раз.

## Функции

### `def find_model_dir(model_file: str) -> str`

**Назначение**: 
Функция `find_model_dir` определяет путь к каталогу, в котором хранится локальная модель GPT4All. 

**Параметры**:

- `model_file` (str): Имя файла с моделью.

**Возвращает**:

- str: Путь к каталогу, в котором хранится модель.

**Как работает**:
- Сначала функция пытается найти модель в каталоге `models` внутри проекта `hypotez`.
- Если модель не найдена в каталоге проекта, функция пытается найти ее в каталоге `models` в текущей директории.
- Если модель не найдена ни в одном из этих каталогов, функция ищет ее в подкаталогах текущей директории.
- Если модель не найдена, функция возвращает путь к каталогу `models` в проекте `hypotez`.

## Параметры

- `MODEL_LIST`: 
    - **Описание**: Глобальный словарь, который хранит список доступных моделей GPT4All.

## Примеры

```python
from gpt4free.g4f.locals.provider import LocalProvider
from gpt4free.g4f.typing import Messages

# Список сообщений для генерации текста
messages: Messages = [
    {"role": "user", "content": "Привет! Как дела?"},
    {"role": "assistant", "content": "Привет! У меня все хорошо, а у тебя?"}
]

# Создание экземпляра LocalProvider
provider = LocalProvider()

# Вызов функции create_completion для генерации текста
text = provider.create_completion(model="gpt4all-lora-13b", messages=messages)

# Печать сгенерированного текста
print(text)
```
```python
from gpt4free.g4f.locals.provider import find_model_dir

# Имя файла с моделью
model_file = "gpt4all-lora-13b.bin"

# Определение пути к каталогу с моделью
model_dir = find_model_dir(model_file)

# Печать пути к каталогу
print(model_dir)