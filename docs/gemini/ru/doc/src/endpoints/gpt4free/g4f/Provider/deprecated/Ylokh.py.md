# Документация для разработчика: `Ylokh.py`

## Оглавление

1.  [Обзор](#обзор)
2.  [Подробнее](#подробнее)
3.  [Классы](#классы)
    *   [`Ylokh`](#ylokh)
4.  [Методы класса](#методы-класса)
    *   [`create_async_generator`](#create_async_generator)

## Обзор

Файл `Ylokh.py` содержит класс `Ylokh`, который является асинхронным провайдером для взаимодействия с API `chat.ylokh.xyz`. Класс поддерживает потоковую передачу данных и предназначен для работы с моделями, подобными `gpt-3.5-turbo`.

## Подробнее

Модуль предоставляет интерфейс для отправки запросов к API `chat.ylokh.xyz` и получения ответов в асинхронном режиме. Он поддерживает как потоковую передачу данных, так и получение полных ответов.

## Классы

### `Ylokh`

**Описание**: Класс `Ylokh` является асинхронным провайдером, который взаимодействует с API `chat.ylokh.xyz` для генерации текста на основе предоставленных сообщений.

**Наследует**:
- `AsyncGeneratorProvider`: Класс наследует функциональность асинхронного генератора от `AsyncGeneratorProvider`.

**Атрибуты**:

-   `url` (str): URL-адрес API `chat.ylokh.xyz`.
-   `working` (bool): Флаг, указывающий на работоспособность провайдера. По умолчанию `False`.
-   `supports_message_history` (bool): Флаг, указывающий на поддержку истории сообщений. Установлен в `True`.
-   `supports_gpt_35_turbo` (bool): Флаг, указывающий на поддержку модели `gpt-3.5-turbo`. Установлен в `True`.

**Принцип работы**:
Класс использует `StreamSession` для отправки асинхронных запросов к API `chat.ylokh.xyz`. Он формирует данные запроса на основе предоставленных сообщений, модели и других параметров, а затем обрабатывает ответы, возвращая сгенерированный текст. Класс поддерживает потоковую передачу данных, что позволяет получать ответы по частям.

## Методы класса

### `create_async_generator`

```python
@classmethod
async def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    stream: bool = True,
    proxy: str = None,
    timeout: int = 120,
    **kwargs
) -> AsyncResult:
    """
    Создает асинхронный генератор для взаимодействия с API `chat.ylokh.xyz`.

    Args:
        cls (type[Ylokh]): Ссылка на класс `Ylokh`.
        model (str): Название используемой модели (например, "gpt-3.5-turbo").
        messages (Messages): Список сообщений для отправки в API.
        stream (bool, optional): Флаг, указывающий на использование потоковой передачи данных. По умолчанию `True`.
        proxy (str, optional): Адрес прокси-сервера. По умолчанию `None`.
        timeout (int, optional): Время ожидания ответа от API в секундах. По умолчанию `120`.
        **kwargs: Дополнительные параметры для передачи в API.

    Returns:
        AsyncResult: Асинхронный генератор, возвращающий сгенерированный текст.

    Raises:
        Exception: Если возникает ошибка при отправке запроса или обработке ответа.

    Внутренние функции:
        Нет
    """
```

**Как работает функция**:

1.  Функция принимает параметры, необходимые для создания запроса к API `chat.ylokh.xyz`.
2.  Формирует заголовки запроса, включая `Origin` и `Referer`.
3.  Создает словарь `data` с данными запроса, включая сообщения, модель, температуру и другие параметры.
4.  Использует `StreamSession` для отправки асинхронного POST-запроса к API.
5.  Обрабатывает ответ от API в зависимости от того, используется ли потоковая передача данных:
    *   Если `stream` установлен в `True`, функция итерируется по строкам ответа, декодирует их и извлекает содержимое из JSON-объектов.
    *   Если `stream` установлен в `False`, функция ожидает получения полного ответа в формате JSON и извлекает содержимое из него.
6.  Возвращает асинхронный генератор, который возвращает сгенерированный текст.

**Примеры**:

```python
# Пример использования с потоковой передачей данных
async for chunk in Ylokh.create_async_generator(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello, world!"}]):
    print(chunk, end="")

# Пример использования без потоковой передачи данных
async for chunk in Ylokh.create_async_generator(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello, world!"}], stream=False):
    print(chunk)