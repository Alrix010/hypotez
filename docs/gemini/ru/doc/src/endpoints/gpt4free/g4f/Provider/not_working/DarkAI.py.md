# Модуль DarkAI

## Обзор

Модуль `DarkAI` предоставляет класс `DarkAI`, который реализует асинхронный генератор для получения ответов от модели DarkAI Foundation. Модуль использует `aiohttp` для отправки запросов к API DarkAI и `StreamReader` для обработки потоковой передачи ответов.

## Подробнее

Модуль `DarkAI` предназначен для взаимодействия с моделью DarkAI Foundation, предлагая асинхронный генератор для получения ответов от модели. 

## Классы

### `class DarkAI`

**Описание**: Класс `DarkAI` реализует асинхронный генератор для получения ответов от модели DarkAI Foundation. Класс наследует от `AsyncGeneratorProvider` и `ProviderModelMixin`, предоставляя базовые функциональные возможности для работы с провайдерами моделей.

**Атрибуты**:

- `url` (str): Базовый URL для API DarkAI Foundation.
- `api_endpoint` (str): Конечная точка API для получения ответов от модели.
- `working` (bool): Флаг, указывающий на работоспособность провайдера (по умолчанию `False`).
- `supports_stream` (bool): Флаг, указывающий на поддержку потоковой передачи ответов (по умолчанию `True`).
- `default_model` (str): Имя модели по умолчанию (по умолчанию `'llama-3-70b'`).
- `models` (list): Список доступных моделей для работы с провайдером.
- `model_aliases` (dict): Словарь алиасов для моделей.

**Методы**:

- `create_async_generator()`: Асинхронный метод, который создает и возвращает асинхронный генератор для получения ответов от модели.

#### `create_async_generator(model: str, messages: Messages, proxy: str = None, **kwargs) -> AsyncResult:`

**Назначение**:  Асинхронный метод, который создает и возвращает асинхронный генератор для получения ответов от модели.

**Параметры**:

- `model` (str): Имя модели, с которой необходимо взаимодействовать.
- `messages` (Messages): Список сообщений, которые необходимо передать модели.
- `proxy` (str):  Прокси-сервер для отправки запросов (по умолчанию `None`).

**Возвращает**:

- `AsyncResult`: Асинхронный результат, который представляет собой асинхронный генератор, возвращающий части ответа модели по мере их получения.

**Как работает функция**:

1.  Извлекает модель из `model_aliases` или использует исходное имя модели, если алиаса нет.
2.  Устанавливает заголовки для запроса к API DarkAI Foundation.
3.  Создает `ClientSession` с заголовками и таймаутом 10 минут.
4.  Форматирует список сообщений в строку запроса.
5.  Отправляет POST-запрос к API DarkAI Foundation с данными запроса.
6.  Обрабатывает ответ от API, используя `StreamReader` для потоковой передачи.
7.  Считывает данные по частям и декодирует их.
8.  Если полученные данные представляют собой часть ответа, она передается через генератор.
9.  Если полученные данные указывают на окончание потоковой передачи, метод завершается.

**Примеры**:

```python
async def main():
    darkai = DarkAI()
    messages = [
        {"role": "user", "content": "Hello, world!"},
    ]
    async for chunk in darkai.create_async_generator(model="llama-3-70b", messages=messages):
        print(chunk)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

## Внутренние функции

### `format_prompt(messages: Messages) -> str:`

**Назначение**:  Форматирует список сообщений в строку запроса для модели DarkAI Foundation.

**Параметры**:

- `messages` (Messages): Список сообщений, которые необходимо форматировать.

**Возвращает**:

- `str`: Строка запроса, сформированная из списка сообщений.

**Как работает функция**:

1.  Итерирует по каждому сообщению в списке.
2.  Форматирует каждое сообщение в строку, добавляя роль (user, assistant) и текст сообщения.
3.  Объединяет все строки сообщений в одну строку запроса.

**Примеры**:

```python
messages = [
    {"role": "user", "content": "Hello, world!"},
    {"role": "assistant", "content": "Hello!"},
]
prompt = format_prompt(messages)
print(prompt)
```

## Параметры класса

- `model` (str): Имя модели, которая будет использоваться для генерации ответов. По умолчанию используется `'llama-3-70b'`.
- `messages` (Messages): Список сообщений, которые будут переданы модели для генерации ответов.
- `proxy` (str): Прокси-сервер, который будет использоваться для отправки запросов.

## Примеры

```python
# Создание инстанса провайдера DarkAI
darkai = DarkAI()

# Запрос к модели
messages = [
    {"role": "user", "content": "Привет, как дела?"},
]

# Создание асинхронного генератора
async_generator = darkai.create_async_generator(model="llama-3-70b", messages=messages)

# Получение ответов по мере их поступления
async for chunk in async_generator:
    print(chunk)
```