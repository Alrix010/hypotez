# Модуль для запуска задач с использованием LLM через LangChain и стандартных агентов.

## Обзор

Модуль предоставляет функциональность для конфигурирования моделей (Gemini, OpenAI), установки API ключей, запуска задачи с использованием LLM и браузерных инструментов, выполнения задачи до конечного результата и стриминга выполнения задачи.

## Подробнее

Этот модуль предназначен для интеграции больших языковых моделей (LLM) с инструментами для работы с браузером, используя фреймворк LangChain. Он позволяет автоматизировать задачи, требующие взаимодействия с веб-страницами, такие как поиск информации, навигация по сайтам и извлечение данных. Модуль поддерживает модели Gemini и OpenAI, предоставляет инструменты для управления API-ключами и обеспечивает возможность потоковой передачи результатов выполнения задач.

## Классы

### `Config`

**Описание**: Класс для хранения статической конфигурации приложения.

**Атрибуты**:
- `ENDPOINT` (Path): Путь к каталогу с конфигурационными файлами.
- `config` (SimpleNamespace): Объект, содержащий конфигурационные параметры, загруженные из файла `use_ai.json`.
- `GEMINI_API_KEY` (Optional[str]): API ключ для доступа к Gemini.
- `GEMINI_STATUS` (str): Статус активности Gemini (например, 'active' или 'inactive').
- `GEMINI_MODEL_NAME` (str): Имя модели Gemini.
- `OPENAI_API_KEY` (Optional[str]): API ключ для доступа к OpenAI.
- `OPENAI_API_STATUS` (str): Статус активности OpenAI (например, 'active' или 'inactive').
- `OPENAI_MODEL_NAME` (str): Имя модели OpenAI.

**Принцип работы**:
Класс `Config` предназначен для хранения и управления конфигурационными параметрами приложения, такими как API-ключи и имена моделей. Он загружает конфигурацию из JSON-файла и предоставляет удобный интерфейс для доступа к этим параметрам через атрибуты класса.

### `Driver`

**Описание**: Класс для управления LLM и запуска агентов LangChain с браузерными инструментами.

**Атрибуты**:
- `config` (Config): Экземпляр класса `Config`, содержащий конфигурацию приложения.
- `gemini` (Optional[ChatGoogleGenerativeAI]): Объект для работы с моделью Gemini.
- `openai` (Optional[ChatOpenAI]): Объект для работы с моделью OpenAI.
- `tools` (List[Tool]): Список инструментов, доступных для агентов LangChain.
- `browser` (Optional[BrowserController]): Объект для управления браузером.

**Методы**:
- `__init__`: Инициализирует LLM, контроллер браузера и инструменты.
- `__del__`: Закрывает браузер при удалении объекта Driver.
- `_get_agent_executor`: Создает и возвращает объект AgentExecutor для выполнения задач.
- `run_task`: Запускает задачу с использованием LLM и возвращает результат.
- `stream_task`: Запускает задачу с использованием LLM и возвращает потоковую передачу результатов.

## Методы класса

### `__init__`

```python
def __init__(
    cls,
    GEMINI_API_KEY: Optional[str] = None,
    OPENAI_API_KEY: Optional[str] = None,
    openai_model_name: Optional[str] = None,
    gemini_model_name: Optional[str] = None,
    start_browser: bool = True,
    **kwargs,
):
    """
    Инициализирует LLM, контроллер браузера и инструменты.

    Args:
        GEMINI_API_KEY (Optional[str], optional): API ключ для доступа к Gemini. По умолчанию `None`.
        OPENAI_API_KEY (Optional[str], optional): API ключ для доступа к OpenAI. По умолчанию `None`.
        openai_model_name (Optional[str], optional): Имя модели OpenAI. По умолчанию `None`.
        gemini_model_name (Optional[str], optional): Имя модели Gemini. По умолчанию `None`.
        start_browser (bool, optional): Флаг, указывающий, следует ли запускать браузер. По умолчанию `True`.
        **kwargs: Дополнительные аргументы.

    Raises:
        Exception: Если нет файла конфигурации.

    """
    ...
```

**Назначение**: Инициализация экземпляра класса `Driver`. Настраивает LLM (Gemini и OpenAI), контроллер браузера и инструменты, необходимые для работы агентов LangChain.

**Параметры**:
- `GEMINI_API_KEY` (Optional[str]): API ключ для доступа к Gemini. Если не указан, используется значение из конфигурации.
- `OPENAI_API_KEY` (Optional[str]): API ключ для доступа к OpenAI. Если не указан, используется значение из конфигурации.
- `openai_model_name` (Optional[str]): Имя модели OpenAI. Если не указано, используется значение из конфигурации.
- `gemini_model_name` (Optional[str]): Имя модели Gemini. Если не указано, используется значение из конфигурации.
- `start_browser` (bool): Флаг, указывающий, следует ли запускать браузер. По умолчанию `True`.
- `**kwargs`: Дополнительные аргументы.

**Как работает функция**:
1. Извлекает API-ключи и имена моделей из переданных аргументов или конфигурации.
2. Инициализирует LLM (Gemini и OpenAI) на основе предоставленных API-ключей и статусов активности.
3. Инициализирует контроллер браузера, если `start_browser` установлен в `True` и `BROWSER_CONTROLLER_AVAILABLE` тоже `True`.
4. Определяет инструменты для взаимодействия с браузером (поиск, навигация, извлечение текста, клик по элементам).

**Примеры**:

```python
driver = Driver(
    GEMINI_API_KEY="your_gemini_api_key",
    OPENAI_API_KEY="your_openai_api_key",
    openai_model_name="gpt-3.5-turbo",
    gemini_model_name="gemini-1.0-pro",
    start_browser=True
)
```

### `__del__`

```python
def __del__(cls):
    """
    Закрывает браузер при удалении объекта Driver.
    """
    ...
```

**Назначение**: Обеспечивает закрытие браузера при удалении объекта `Driver`.

**Как работает функция**:
1. Проверяет, инициализирован ли контроллер браузера.
2. Пытается закрыть браузер с помощью метода `close()` контроллера браузера.
3. Логирует ошибки, если возникают проблемы при закрытии браузера.

### `_get_agent_executor`

```python
async def _get_agent_executor(cls, llm: BaseChatModel) -> Optional[AgentExecutor]:
    """
    Создает и возвращает объект AgentExecutor для выполнения задач.

    Args:
        llm (BaseChatModel): Языковая модель для использования.

    Returns:
        Optional[AgentExecutor]: Объект AgentExecutor или None в случае ошибки.
    """
    ...
```

**Назначение**: Создает и возвращает объект `AgentExecutor` для выполнения задач с использованием указанной языковой модели и инструментов.

**Параметры**:
- `llm` (BaseChatModel): Языковая модель для использования (Gemini или OpenAI).

**Возвращает**:
- `Optional[AgentExecutor]`: Объект `AgentExecutor` или `None` в случае ошибки.

**Как работает функция**:
1. Проверяет, инициализирована ли языковая модель.
2. Проверяет, пуст ли список инструментов.
3. Загружает prompt для агента из Langchain Hub.
4. Создает агента с использованием языковой модели, инструментов и prompt.
5. Создает `AgentExecutor` с агентом и инструментами.

### `run_task`

```python
async def run_task(cls, task: str, use_gemini: bool = True) -> Optional[str]:
    """
    Запускает задачу с использованием LLM и возвращает результат.

    Args:
        task (str): Задача для выполнения.
        use_gemini (bool, optional): Флаг, указывающий, использовать ли Gemini. По умолчанию `True`.

    Returns:
        Optional[str]: Результат выполнения задачи или None в случае ошибки.
    """
    ...
```

**Назначение**: Запускает задачу с использованием выбранной LLM (Gemini или OpenAI) и возвращает результат.

**Параметры**:
- `task` (str): Задача, которую необходимо выполнить.
- `use_gemini` (bool): Флаг, определяющий, использовать ли модель Gemini. Если `False`, используется OpenAI. По умолчанию `True`.

**Возвращает**:
- `Optional[str]`: Результат выполнения задачи в виде строки или `None` в случае ошибки.

**Как работает функция**:
1. Выбирает LLM в зависимости от значения флага `use_gemini`.
2. Проверяет, инициализирована ли выбранная LLM.
3. Проверяет, что задача содержит инструменты для работы с браузером.
4. Создает `AgentExecutor` с помощью метода `_get_agent_executor`.
5. Запускает задачу с помощью метода `ainvoke` объекта `AgentExecutor`.
6. Извлекает и возвращает результат из ответа.

**Примеры**:

```python
result = await driver.run_task("Найди последнюю новость о LangChain", use_gemini=True)
```

### `stream_task`

```python
async def stream_task(cls, task: str, use_gemini: bool = True) -> Tuple[Optional[str], List[Dict[str, Any]]]:
    """
    Запускает задачу с использованием LLM и возвращает потоковую передачу результатов.

    Args:
        task (str): Задача для выполнения.
        use_gemini (bool, optional): Флаг, указывающий, использовать ли Gemini. По умолчанию `True`.

    Returns:
        Tuple[Optional[str], List[Dict[str, Any]]]: Кортеж, содержащий финальный ответ и список чанков.
    """
    ...
```

**Назначение**: Запускает задачу с использованием выбранной LLM (Gemini или OpenAI) и возвращает результаты в виде потока чанков.

**Параметры**:
- `task` (str): Задача, которую необходимо выполнить.
- `use_gemini` (bool): Флаг, определяющий, использовать ли модель Gemini. Если `False`, используется OpenAI. По умолчанию `True`.

**Возвращает**:
- `Tuple[Optional[str], List[Dict[str, Any]]]`: Кортеж, содержащий финальный ответ и список чанков, полученных в процессе выполнения задачи.

**Как работает функция**:
1. Выбирает LLM в зависимости от значения флага `use_gemini`.
2. Проверяет, инициализирована ли выбранная LLM.
3. Проверяет, что задача содержит инструменты для работы с браузером.
4. Создает `AgentExecutor` с помощью метода `_get_agent_executor`.
5. Запускает задачу с помощью асинхронного генератора `astream` объекта `AgentExecutor`.
6. Собирает чанки и извлекает финальный ответ из потока.
7. Возвращает финальный ответ и список чанков.

**Примеры**:

```python
final_answer, chunks = await driver.stream_task("Найди последнюю новость о LangChain", use_gemini=True)
```

## Функции

### `stream_agent_execution`

```python
async def stream_agent_execution(executor: AgentExecutor, task_input: Dict[str, Any], logger_instance) -> Tuple[Optional[str], List[Dict[str, Any]]]:
    """
    Асинхронно выполняет агент через AgentExecutor и стримит шаги.

    Args:
        executor (AgentExecutor): Объект AgentExecutor для выполнения задачи.
        task_input (Dict[str, Any]): Входные данные для задачи.
        logger_instance: Экземпляр логгера для записи информации о процессе выполнения.

    Returns:
        Tuple[Optional[str], List[Dict[str, Any]]]: Кортеж, содержащий финальный ответ и список всех чанков.
    """
    ...
```

**Назначение**: Асинхронно выполняет агента через `AgentExecutor` и стримит шаги выполнения задачи.

**Параметры**:
- `executor` (AgentExecutor): Объект `AgentExecutor`, который будет выполнять задачу.
- `task_input` (Dict[str, Any]): Входные данные для задачи.
- `logger_instance`: Экземпляр логгера для записи информации о процессе выполнения.

**Возвращает**:
- `Tuple[Optional[str], List[Dict[str, Any]]]`: Кортеж, содержащий финальный ответ (если есть) и список всех чанков, полученных в процессе выполнения задачи.

**Как работает функция**:
1. Инициализирует переменные для хранения финального ответа, списка чанков и идентификатора запуска.
2. Запускает асинхронный цикл для получения чанков из `executor.astream(task_input)`.
3. Для каждого полученного чанка:
    - Добавляет чанк в список `all_chunks`.
    - Извлекает информацию о текущем запуске и идентификатор запуска.
    - Логирует информацию о запланированных действиях, результатах действий и сообщениях.
    - Если в чанке есть финальный ответ, сохраняет его.
4. Обрабатывает исключения `LangChainException` и другие исключения, логируя информацию об ошибках.
5. Возвращает финальный ответ и список всех чанков.

### `main`

```python
async def main():
    """
    Функция main для демонстрации.
    """
    ...
```

**Назначение**: Функция `main` предназначена для демонстрации работы с классом `Driver` и выполнения тестовых задач.

**Как работает функция**:
1. Инициализирует объект `Driver` с включенным браузером.
2. Определяет тестовую задачу.
3. Запускает задачу с использованием метода `run_task` для каждой активной LLM (Gemini и OpenAI).
4. Запускает задачу с использованием метода `stream_task` для каждой активной LLM (Gemini и OpenAI).
5. Выводит результаты выполнения задач.