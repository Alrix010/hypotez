# Модуль: Crawlee Python Crawler

## Обзор

Модуль `crawlee_python.py` предоставляет пользовательскую реализацию `PlaywrightCrawler` с использованием библиотеки Crawlee. Он позволяет настраивать параметры браузера, обрабатывать запросы и извлекать данные из веб-страниц.

## Подробней

Этот модуль предоставляет класс `CrawleePython`, который упрощает использование `PlaywrightCrawler` из библиотеки Crawlee. Он позволяет легко настраивать браузер, указывать максимальное количество запросов, запускать браузер в headless-режиме и выбирать тип браузера (Chromium, Firefox, WebKit). Модуль также включает обработчик запросов по умолчанию, который извлекает данные со страниц и добавляет найденные ссылки в очередь.

## Классы

### `CrawleePython`

**Описание**: Пользовательская реализация `PlaywrightCrawler` с использованием библиотеки Crawlee.

**Атрибуты**:
- `max_requests` (int): Максимальное количество запросов для выполнения во время обхода.
- `headless` (bool): Определяет, запускать ли браузер в headless-режиме.
- `browser_type` (str): Тип используемого браузера ('chromium', 'firefox', 'webkit').
- `crawler` (PlaywrightCrawler): Экземпляр `PlaywrightCrawler`.
- `options` (Optional[List[str]]): Список дополнительных опций для передачи в браузер.

**Методы**:
- `__init__`: Инициализирует экземпляр класса `CrawleePython`.
- `setup_crawler`: Настраивает экземпляр `PlaywrightCrawler` с указанной конфигурацией.
- `run_crawler`: Запускает обход веб-страниц с использованием `PlaywrightCrawler`.
- `export_data`: Экспортирует весь набор данных в JSON-файл.
- `get_data`: Извлекает извлеченные данные.
- `run`: Основной метод для настройки, запуска обходчика и экспорта данных.

#### `__init__(self, max_requests: int = 5, headless: bool = False, browser_type: str = 'firefox', options: Optional[List[str]] = None)`

**Назначение**: Инициализирует класс `CrawleePython` с заданными параметрами.

**Параметры**:
- `max_requests` (int, optional): Максимальное количество запросов для выполнения во время обхода. По умолчанию `5`.
- `headless` (bool, optional): Определяет, запускать ли браузер в headless-режиме. По умолчанию `False`.
- `browser_type` (str, optional): Тип используемого браузера ('chromium', 'firefox', 'webkit'). По умолчанию `'firefox'`.
- `options` (Optional[List[str]], optional): Список дополнительных опций для передачи в браузер. По умолчанию `None`.

**Как работает функция**:
- Функция инициализирует экземпляр класса `CrawleePython` с заданными параметрами, такими как максимальное количество запросов, режим работы браузера (с графическим интерфейсом или без), тип браузера и дополнительные опции.
- Она сохраняет переданные параметры в атрибутах экземпляра класса для последующего использования.

**Примеры**:
```python
crawler = CrawleePython(max_requests=10, headless=True, browser_type='chromium')
```

#### `async setup_crawler(self)`

**Назначение**: Настраивает экземпляр `PlaywrightCrawler` с указанной конфигурацией.

**Как работает функция**:
- Создает экземпляр `PlaywrightCrawler` с заданными параметрами, такими как максимальное количество запросов, режим работы браузера и тип браузера.
- Определяет обработчик запросов по умолчанию (`request_handler`), который будет выполняться для каждой посещенной страницы.
- Обработчик запросов извлекает заголовок и контент страницы, а также добавляет все найденные на странице ссылки в очередь для дальнейшего обхода.

**Внутренние функции**:

##### `request_handler(context: PlaywrightCrawlingContext)`

**Назначение**: Обработчик запросов по умолчанию для обработки веб-страниц.

**Параметры**:
- `context` (PlaywrightCrawlingContext): Контекст обхода.

**Как работает функция**:
- Логирует информацию об обрабатываемом URL.
- Добавляет все найденные на странице ссылки в очередь.
- Извлекает данные со страницы, такие как URL, заголовок и контент (ограниченный первыми 100 символами).
- Помещает извлеченные данные в набор данных.

**Примеры**:

Этот метод является частью настройки `PlaywrightCrawler` и не вызывается напрямую.

#### `async run_crawler(self, urls: List[str])`

**Назначение**: Запускает обход веб-страниц с использованием `PlaywrightCrawler`.

**Параметры**:
- `urls` (List[str]): Список URL-адресов для начала обхода.

**Как работает функция**:
- Запускает `PlaywrightCrawler` с переданным списком URL-адресов, инициируя процесс обхода веб-страниц.

**Примеры**:
```python
await crawler.run_crawler(['https://www.example.com', 'https://www.example.org'])
```

#### `async export_data(self, file_path: str)`

**Назначение**: Экспортирует весь набор данных в JSON-файл.

**Параметры**:
- `file_path` (str): Путь для сохранения экспортированного JSON-файла.

**Как работает функция**:
- Экспортирует данные, собранные во время обхода, в файл JSON по указанному пути.

**Примеры**:
```python
await crawler.export_data('output.json')
```

#### `async get_data(self) -> Dict[str, Any]`

**Назначение**: Извлекает извлеченные данные.

**Возвращает**:
- `Dict[str, Any]`: Извлеченные данные в виде словаря.

**Как работает функция**:
- Извлекает данные, собранные `PlaywrightCrawler` во время обхода веб-страниц.

**Примеры**:
```python
data = await crawler.get_data()
print(data)
```

#### `async run(self, urls: List[str])`

**Назначение**: Основной метод для настройки, запуска обходчика и экспорта данных.

**Параметры**:
- `urls` (List[str]): Список URL-адресов для начала обхода.

**Как работает функция**:
- Вызывает методы `setup_crawler`, `run_crawler` и `export_data` для выполнения полного процесса обхода и экспорта данных.
- Логирует извлеченные данные.
- Обрабатывает исключения, которые могут возникнуть в процессе обхода.

**Примеры**:
```python
await crawler.run(['https://www.example.com', 'https://www.example.org'])
```
## Пример использования

```python
if __name__ == "__main__":
    async def main():
        crawler = CrawleePython(max_requests=5, headless=False, browser_type='firefox', options=["--headless"])
        await crawler.run(['https://www.example.com'])

    asyncio.run(main())