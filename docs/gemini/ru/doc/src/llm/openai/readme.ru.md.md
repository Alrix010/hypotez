# Модуль `ai`: Управление моделями ИИ

## Обзор

Модуль `ai` предоставляет набор инструментов для работы с различными моделями ИИ, такими как Anthropic, Dialogflow, Gemini, Helicone, LLaMA, MyAI и OpenAI. Он обеспечивает единый интерфейс для взаимодействия с этими моделями, упрощая интеграцию и использование ИИ в проектах.

## Подмодули

### prompts

#### Назначение:

Подмодуль `prompts` отвечает за создание и обработку запросов к моделям ИИ. Он предоставляет функции для генерации структурированных входных данных (подсказок), которые оптимизированы для конкретных задач и моделей.

#### Принцип работы:

`prompts` использует методы конструирования подсказок, включая:

- **Форматирование**: Преобразование входных данных в нужный формат для конкретной модели ИИ.
- **Создание шаблонов**: Создание шаблонов подсказок для типовых задач, например, для перевода, обобщения или вопросов и ответов.
- **Добавление контекста**: Добавление контекста для повышения точности ответов, например, предоставление дополнительной информации или предыдущих диалогов.

#### Примеры:

- Создание подсказки для перевода текста:
```python
from hypotez.src.llm.ai.prompts import create_translation_prompt

prompt = create_translation_prompt(text='Hello, world!', target_language='ru')
print(prompt)
```

- Создание подсказки для создания резюме:
```python
from hypotez.src.llm.ai.prompts import create_summarization_prompt

prompt = create_summarization_prompt(text='Lorem ipsum dolor sit amet...', max_tokens=100)
print(prompt)
```

### anthropic

#### Назначение:

Подмодуль `anthropic` предоставляет функции для взаимодействия с моделями ИИ Anthropic, такими как Claude. Он позволяет отправлять запросы, обрабатывать ответы и управлять настройками модели.

#### Принцип работы:

`anthropic` использует API Anthropic для:

- **Отправка запросов**: Передача запросов к модели Claude с использованием заданных параметров.
- **Получение ответов**: Обработка ответов от модели, включая обработку ошибок и форматирование.
- **Настройка модели**: Управление настройками модели, например, выбор варианта модели, определение тональности ответа и т.д.

#### Примеры:

- Отправка запроса к модели Claude:
```python
from hypotez.src.llm.ai.anthropic import Claude

model = Claude(model_name='claude-2')
response = model.send_request(prompt='What is the meaning of life?')
print(response)
```

### dialogflow

#### Назначение:

Подмодуль `dialogflow` обеспечивает интеграцию с Google Dialogflow, платформой для создания разговорных ботов. Он позволяет использовать возможности Dialogflow для понимания естественного языка (NLU), обработки диалогов и создания интерактивных приложений.

#### Принцип работы:

`dialogflow` использует API Dialogflow для:

- **Распознавание речи**: Преобразование аудио в текст для обработки Dialogflow.
- **Обработка текста**: Анализ текста на естественном языке (NLU) для понимания намерения пользователя и извлечение сущностей.
- **Создание ответов**: Генерация текстовых или голосовых ответов, а также выполнение действий, заданных в Dialogflow.

#### Примеры:

- Создание запроса к Dialogflow:
```python
from hypotez.src.llm.ai.dialogflow import Dialogflow

dialogflow = Dialogflow(project_id='your_project_id')
response = dialogflow.send_request(text='What is the weather today?')
print(response)
```

### gemini

#### Назначение:

Подмодуль `gemini` обеспечивает интеграцию с моделями ИИ Gemini, разработанными Google. Он предоставляет функции для отправки запросов, обработки ответов и управления настройками моделей Gemini.

#### Принцип работы:

`gemini` использует API Gemini для:

- **Отправка запросов**: Передача запросов к модели Gemini с использованием заданных параметров.
- **Получение ответов**: Обработка ответов от модели, включая обработку ошибок и форматирование.
- **Настройка модели**: Управление настройками модели, например, выбор варианта модели, определение тональности ответа и т.д.

#### Примеры:

- Отправка запроса к модели Gemini:
```python
from hypotez.src.llm.ai.gemini import Gemini

model = Gemini(model_name='gemini-pro')
response = model.send_request(prompt='Write a poem about love.')
print(response)
```

### helicone

#### Назначение:

Подмодуль `helicone` предоставляет функции для взаимодействия с моделями ИИ Helicone. Он позволяет отправлять запросы, обрабатывать ответы и управлять настройками моделей Helicone.

#### Принцип работы:

`helicone` использует API Helicone для:

- **Отправка запросов**: Передача запросов к модели Helicone с использованием заданных параметров.
- **Получение ответов**: Обработка ответов от модели, включая обработку ошибок и форматирование.
- **Настройка модели**: Управление настройками модели, например, выбор варианта модели, определение тональности ответа и т.д.

#### Примеры:

- Отправка запроса к модели Helicone:
```python
from hypotez.src.llm.ai.helicone import Helicone

model = Helicone(model_name='helicone-large')
response = model.send_request(prompt='Translate "Hello, world!" into Spanish.')
print(response)
```

### llama

#### Назначение:

Подмодуль `llama` обеспечивает интеграцию с моделью ИИ LLaMA (Large Language Model Meta AI). Он позволяет отправлять запросы, обрабатывать ответы и управлять настройками модели LLaMA.

#### Принцип работы:

`llama` использует API LLaMA для:

- **Отправка запросов**: Передача запросов к модели LLaMA с использованием заданных параметров.
- **Получение ответов**: Обработка ответов от модели, включая обработку ошибок и форматирование.
- **Настройка модели**: Управление настройками модели, например, выбор варианта модели, определение тональности ответа и т.д.

#### Примеры:

- Отправка запроса к модели LLaMA:
```python
from hypotez.src.llm.ai.llama import LLaMA

model = LLaMA(model_name='llama-7b')
response = model.send_request(prompt='Write a short story about a cat.')
print(response)
```

### myai

#### Назначение:

Подмодуль `myai` предоставляет платформу для создания и управления пользовательскими моделями ИИ. Он позволяет реализовывать специализированные функции ИИ, которые не входят в стандартный набор моделей.

#### Принцип работы:

`myai` предоставляет:

- **Фреймворк для обучения**: Возможность обучения собственных моделей ИИ с использованием выбранных алгоритмов и наборов данных.
- **Инструменты для развертывания**:  Развертывание обученных моделей для использования в проекте.
- **API для взаимодействия**: Создание интерфейсов для отправки запросов и получения ответов от пользовательских моделей.

#### Примеры:

- Создание пользовательской модели для классификации текстов:
```python
from hypotez.src.llm.ai.myai import MyAI

model = MyAI(model_type='text_classification')
model.train(data='your_training_data')
response = model.send_request(text='This is a sample text.')
print(response)
```

### openai

#### Назначение:

Подмодуль `openai` предоставляет функции для взаимодействия с API OpenAI, позволяя использовать различные модели OpenAI, такие как GPT-3, GPT-4 и DALL-E. Он позволяет отправлять запросы, обрабатывать ответы и управлять настройками моделей OpenAI.

#### Принцип работы:

`openai` использует API OpenAI для:

- **Отправка запросов**: Передача запросов к моделям OpenAI с использованием заданных параметров.
- **Получение ответов**: Обработка ответов от модели, включая обработку ошибок и форматирование.
- **Настройка модели**: Управление настройками модели, например, выбор варианта модели, определение тональности ответа и т.д.

#### Примеры:

- Отправка запроса к модели GPT-3:
```python
from hypotez.src.llm.ai.openai import OpenAI

model = OpenAI(model_name='text-davinci-003')
response = model.send_request(prompt='Write a story about a dog.')
print(response)
```

- Отправка запроса к модели DALL-E:
```python
from hypotez.src.llm.ai.openai import OpenAI

model = OpenAI(model_name='dall-e')
response = model.send_request(prompt='A photo of a cat wearing a hat.')
print(response)
```