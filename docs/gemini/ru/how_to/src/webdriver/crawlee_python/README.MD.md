## Как использовать модуль Crawlee Python для автоматизации и сбора данных

=========================================================================================

### Описание
-------------------------

Модуль `CrawleePython` предоставляет кастомную реализацию `PlaywrightCrawler` с использованием библиотеки Crawlee. Он позволяет настроить параметры запуска браузера, обрабатывать веб-страницы и извлекать из них данные. Конфигурация управляется через файл `crawlee_python.json`.

### Шаги выполнения
-------------------------

1. **Установка зависимостей**:
    - Установите Python 3.x.
    - Установите Playwright и Crawlee с помощью команды:
        ```bash
        pip install playwright crawlee
        ```
    - Установите браузеры Playwright с помощью команды:
        ```bash
        playwright install
        ```
2. **Настройка конфигурации**:
    - Создайте файл `crawlee_python.json` с необходимыми настройками. 
    - Используйте пример конфигурации из документации в качестве основы.
3. **Инициализация CrawleePython**:
    - Импортируйте `CrawleePython` из модуля `src.webdriver.crawlee_python`.
    - Создайте экземпляр `CrawleePython`, указав необходимые параметры (например, `max_requests`, `headless`, `browser_type`, `options`).
4. **Запуск CrawleePython**:
    - Используйте метод `run()` для запуска CrawleePython и передачи списка URL-адресов для обработки.
    - В методе `run()` вы можете добавить собственную логику для обработки каждой веб-страницы.
5. **Проверка логов**:
    - CrawleePython использует `logger` из `src.logger` для вывода ошибок, предупреждений и информации.
    - Просмотрите логи для отладки проблем.

### Пример использования
-------------------------

```python
from src.webdriver.crawlee_python import CrawleePython
import asyncio

# Инициализация CrawleePython с настройками из crawlee_python.json
async def main():
    crawler = CrawleePython() 
    await crawler.run(['https://www.example.com'])

asyncio.run(main())
```

### Дополнительные сведения
-------------------------

- Модуль поддерживает различные настройки браузера, такие как размер области просмотра, пользовательский агент, прокси-серверы и т. д.
- Дополнительные настройки можно найти в файле `crawlee_python.json` и в документации.
- Для отладки используйте логи, которые генерирует CrawleePython.
- Модуль работает с разными типами браузеров: `chromium`, `firefox` и `webkit`.
- Используйте `options` для передачи дополнительных аргументов командной строки браузеру.