### Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот код реализует веб-краулер на Python с использованием библиотеки Crawlee. Он позволяет настроить параметры браузера (например, запуск в headless-режиме), обрабатывать запросы и извлекать данные с веб-страниц.

Шаги выполнения
-------------------------
1. **Инициализация класса `CrawleePython`**: Создается экземпляр класса `CrawleePython` с указанием максимального количества запросов (`max_requests`), режима без графического интерфейса (`headless`), типа браузера (`browser_type`) и дополнительных опций (`options`).
2. **Настройка краулера**: Вызывается метод `setup_crawler`, который создает экземпляр `PlaywrightCrawler` с заданными параметрами. Также определяется обработчик запросов `request_handler`, который будет выполняться для каждой страницы.
3. **Обработка запросов**: Внутри `request_handler` извлекаются данные, такие как URL, заголовок и содержимое страницы. Все найденные на странице ссылки добавляются в очередь для дальнейшей обработки.
4. **Запуск краулера**: Метод `run_crawler` запускает краулер с начальным списком URL.
5. **Экспорт данных**: После завершения работы краулера, извлеченные данные экспортируются в JSON-файл с помощью метода `export_data`.
6. **Получение данных**: Метод `get_data` возвращает извлеченные данные в виде словаря.

Пример использования
-------------------------

```python
import asyncio
from src.webdriver.crawlee_python.crawlee_python import CrawleePython

async def main():
    # Создаем экземпляр краулера с параметрами
    crawler = CrawleePython(max_requests=5, headless=False, browser_type='firefox', options=["--disable-gpu"])

    # Запускаем краулер для указанных URL
    await crawler.run(['https://www.example.com', 'https://example.net'])

if __name__ == "__main__":
    asyncio.run(main())