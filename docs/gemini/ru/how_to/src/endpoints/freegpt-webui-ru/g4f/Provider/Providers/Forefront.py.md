## Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот блок кода реализует провайдера `Forefront` для модели `g4f`, которая предоставляет доступ к модели GPT-4. 

Шаги выполнения
-------------------------
1. **Определение переменных**:
    - `url`: Базовый URL для доступа к API `Forefront`.
    - `model`: Список поддерживаемых моделей, в данном случае только `gpt-3.5-turbo`.
    - `supports_stream`: Флаг, указывающий на поддержку потоковой передачи (streaming).
    - `needs_auth`: Флаг, указывающий на необходимость авторизации для доступа к API.
2. **Определение функции `_create_completion`**:
    - Эта функция принимает модель, список сообщений, флаг `stream` и необязательные аргументы.
    - Она формирует JSON-запрос с необходимыми параметрами, включая модель, сообщения, режим работы с интернетом и другую информацию.
    - Отправляет этот запрос на API `Forefront`.
    - Обрабатывает ответ API, извлекая данные и передавая их по одному токену через генератор.
3. **Определение `params`**:
    - Строка, содержащая информацию о поддерживаемых параметрах функции `_create_completion`.

Пример использования
-------------------------

```python
from g4f.Provider.Providers import Forefront

# Создаем объект провайдера Forefront
provider = Forefront()

# Формируем список сообщений для отправки на API
messages = [
    {'role': 'user', 'content': 'Привет, как дела?'},
]

# Выполняем запрос к API, получая результаты в виде генератора
response_generator = provider.create_completion(model='gpt-3.5-turbo', messages=messages, stream=True)

# Обрабатываем полученные токены
for token in response_generator:
    print(token)
```

**Важно**: 
-  Для работы с данным провайдером вам нужно иметь доступ к API `Forefront`.
-  Поскольку `needs_auth` равно `False`, авторизация не требуется.
-  В примере используется модель `gpt-3.5-turbo`, но вы можете попробовать другие поддерживаемые модели, если они доступны.