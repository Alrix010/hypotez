### Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот код предназначен для взаимодействия с API Vercel для генерации текста с использованием различных языковых моделей. Он включает в себя настройку HTTP-клиента, получение токена аутентификации, формирование запросов к API и обработку потоковых ответов.

Шаги выполнения
-------------------------
1. **Инициализация клиента**: Создается экземпляр класса `Client`, который настраивает сессию `requests` с необходимыми заголовками для взаимодействия с API Vercel.
2. **Получение токена аутентификации**: Функция `get_token` отправляет запрос для получения base64-encoded JSON, декодирует его, извлекает код JavaScript, выполняет его с помощью `execjs` для генерации токена, а затем кодирует токен обратно в base64 для использования в заголовках запроса.
3. **Получение параметров модели по умолчанию**: Функция `get_default_params` извлекает параметры по умолчанию для заданной модели из словаря `vercel_models`.
4. **Генерация текста**: Функция `generate` формирует полезную нагрузку (payload) с параметрами, объединяя параметры по умолчанию, предоставленные пользователем параметры и входной текст (prompt). Затем она отправляет POST-запрос к API Vercel, используя полученный токен аутентификации в заголовках.
5. **Обработка потокового ответа**: Функция `generate` использует очередь (`queue.Queue`) и потоки (`threading.Thread`) для асинхронной обработки потоковых ответов от API. Ответы поступают по частям, декодируются и передаются через очередь.
6. **Извлечение чанков из очереди**: Основной поток извлекает чанки из очереди, объединяет их в текст и разбивает на строки. Затем он извлекает JSON из каждой новой строки и генерирует их.
7. **Функция `_create_completion`**: Эта функция принимает модель и список сообщений, формирует диалог и отправляет его в Vercel для завершения. Она генерирует токены из ответа.

Пример использования
-------------------------

```python
from src.endpoints.freegpt_webui_ru.g4f.Provider.Providers import Vercel

model = "text-davinci-003"  # Выберите одну из поддерживаемых моделей
messages = [
    {"role": "user", "content": "Как дела?"}
]
stream = True

# Создаем генератор завершений
completion = Vercel._create_completion(model=model, messages=messages, stream=stream)

# Итерируемся по токенам, возвращенным генератором, и печатаем их
for token in completion:
    print(token)