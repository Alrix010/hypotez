## Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот блок кода представляет собой функцию `_create_completion`, которая отправляет запрос к API H2O AI для получения текста, сгенерированного выбранной моделью. Функция принимает модель, список сообщений чата, флаг потоковой передачи и дополнительные параметры (температура, обрезка текста, максимальное количество новых токенов, повторение пенальти и т. д.).

Шаги выполнения
-------------------------
1. **Формирование текста запроса**: 
    - Функция формирует текст запроса в формате "instruction: ..." для модели. 
    - Включает в запрос всю историю общения, включая предыдущие сообщения.
    - Добавляет начало ответа "assistant:".
2. **Создание сессии и заголовков**:
    - Функция создает объект сессии `client` для отправки запросов к API.
    - Устанавливает заголовки запроса, включая `User-Agent`, `Origin`, `Referer` и другие.
3. **Инициализация API**:
    - Выполняет GET-запрос к `https://gpt-gm.h2o.ai/` для инициализации API.
4. **Настройка параметров**:
    - Выполняет POST-запрос к `https://gpt-gm.h2o.ai/settings` для установки параметров модели, таких как  `activeModel` и `ethicsModalAccepted`.
5. **Отправка запроса**:
    - Функция формирует JSON-данные с моделью и отправляет POST-запрос к `https://gpt-gm.h2o.ai/conversation` для создания новой сессии.
    - Получает `conversationId` из ответа.
6. **Генерация текста**:
    - Отправляет POST-запрос к `https://gpt-gm.h2o.ai/conversation/{conversationId}` для получения текста, сгенерированного моделью.
    - Использует `stream=True` для потоковой передачи текста.
    - Обрабатывает каждую строку ответа, извлекая `token` и выводит его.
    - Завершает обработку, когда встречает токен `<|endoftext|>`.
7. **Вывод**:
    - Выводит информацию о поддерживаемых параметрах в формате `g4f.Providers.H2o supports: (model: str, messages: list, stream: bool, temperature: float, truncate: int, max_new_tokens: int, do_sample: bool, repetition_penalty: float, return_full_text: bool)`.

Пример использования
-------------------------

```python
from hypotez.src.endpoints.freegpt-webui-ru.g4f.Provider.Providers.H2o import _create_completion

model = 'falcon-40b'  # Выбранная модель
messages = [
    {'role': 'user', 'content': 'Привет! Как дела?'},
    {'role': 'assistant', 'content': 'Хорошо, спасибо! А у тебя как?'}
] 
stream = True # Флаг потоковой передачи 
temperature = 0.5 # Температура модели (от 0 до 1)
truncate = 2048 # Максимальный размер контекста

for token in _create_completion(model, messages, stream, temperature=temperature, truncate=truncate):
    print(token, end='')
```