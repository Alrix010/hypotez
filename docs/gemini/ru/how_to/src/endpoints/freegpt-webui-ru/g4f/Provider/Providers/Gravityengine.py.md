## Как использовать этот блок кода
=========================================================================================

### Описание
-------------------------
Этот блок кода представляет собой провайдер для модели GPT, реализующий взаимодействие с GravityEngine API. 

Он определяет следующие атрибуты:
* `url`: адрес API GravityEngine
* `model`: список поддерживаемых моделей GPT
* `supports_stream`: True, т.е. поддерживает потоковую передачу ответов
* `needs_auth`: False, т.е. не требует авторизации

Функция `_create_completion` отвечает за отправку запроса к API GravityEngine и получение ответов.

### Шаги выполнения
-------------------------
1. **Инициализация**: Определяются URL-адрес API, список поддерживаемых моделей, флаги `supports_stream` и `needs_auth`.
2. **Формирование запроса**: В функции `_create_completion` собираются данные для отправки запроса к API GravityEngine.
3. **Отправка запроса**: Функция `_create_completion` отправляет запрос к API GravityEngine с использованием библиотеки `requests`.
4. **Обработка ответа**: Ответ от API GravityEngine обрабатывается, извлекается текст ответа и передается по потоку.
5. **Информация о параметрах**: Выводится строка, содержащая информацию о типах параметров функции `_create_completion`.

### Пример использования
-------------------------

```python
from hypotez.src.endpoints.freegpt-webui-ru.g4f.Provider.Providers.Gravityengine import _create_completion

messages = [
    {"role": "user", "content": "Привет, как дела?"},
]

for response in _create_completion(model='gpt-3.5-turbo-16k', messages=messages, stream=True):
    print(response)
```

В этом примере мы используем функцию `_create_completion` для отправки запроса с сообщением "Привет, как дела?" к модели `gpt-3.5-turbo-16k`. Параметр `stream=True` активирует потоковую передачу ответов.  Каждый полученный фрагмент ответа выводится на консоль.