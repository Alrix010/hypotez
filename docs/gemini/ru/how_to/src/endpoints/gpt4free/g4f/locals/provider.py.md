## Как использовать `LocalProvider` для генерации текста с помощью моделей GPT4All
=========================================================================================

Описание
-------------------------
Этот блок кода реализует класс `LocalProvider`, который предоставляет функциональность для генерации текста с помощью моделей GPT4All, хранящихся локально. Класс предоставляет метод `create_completion`, который генерирует текст на основе входящих сообщений (messages) и выбранной модели. 

Шаги выполнения
-------------------------
1. **Инициализация глобального списка моделей**:
    - Проверяет, инициализирован ли глобальный словарь `MODEL_LIST`, хранящий информацию о доступных моделях. 
    - Если нет, вызывает функцию `get_models()` для получения информации о доступных моделях и сохранения ее в `MODEL_LIST`.

2. **Проверка наличия модели**:
    - Проверяет, присутствует ли заданная модель в списке `MODEL_LIST`.
    - Если модели нет, выдает исключение `ValueError` с сообщением о том, что модель не найдена.

3. **Поиск директории модели**:
    - Извлекает путь к файлу модели из `MODEL_LIST`.
    - Вызывает функцию `find_model_dir` для поиска директории модели. 

4. **Загрузка модели**:
    - Проверяет, существует ли файл модели по найденному пути. 
    - Если файл не найден, предлагает пользователю загрузить модель.
    - Если пользователь соглашается, скачивает модель с помощью метода `GPT4All.download_model`.
    - Если пользователь не соглашается, выдает исключение `ValueError`.

5. **Создание объекта модели**:
    - Инициализирует объект `GPT4All` с использованием найденной модели. 
    - Устанавливает параметры модели:
        - `model_name`: имя файла модели.
        - `verbose`: отключенное логирование.
        - `allow_download`: запрещена автоматическая загрузка модели.
        - `model_path`: директория модели.

6. **Формирование системного сообщения**:
    - Формирует системное сообщение из входящих сообщений с типом "system". 
    - Если системное сообщение отсутствует, устанавливает его по умолчанию.

7. **Формирование шаблона запроса**:
    - Создает шаблон запроса для модели GPT4All.

8. **Формирование контекста**:
    - Формирует контекст для модели GPT4All из всех сообщений, кроме сообщений типа "system".
    - Добавляет строку `ASSISTANT: ` в конец контекста.

9. **Генерация текста**:
    - Создает сессию чата с помощью метода `model.chat_session`.
    - Устанавливает системное сообщение и шаблон запроса для сессии.
    - Вызывает метод `model.generate` для генерации текста:
        - Если `stream=True`, генерирует текст потоково, по одному токену.
        - Если `stream=False`, генерирует весь текст целиком.

Пример использования
-------------------------

```python
from gpt4free.g4f.locals.provider import LocalProvider
from gpt4free.g4f.typing import Messages

# Список сообщений
messages: Messages = [
    {"role": "system", "content": "Ты - дружелюбный помощник."},
    {"role": "user", "content": "Привет!"},
]

# Модель для генерации текста
model = "gpt4all-lora-quantized"

# Генерация текста с помощью LocalProvider
for token in LocalProvider.create_completion(model=model, messages=messages, stream=True):
    print(token, end="")
```

В этом примере код инициализирует объект `LocalProvider` и вызывает метод `create_completion` для генерации текста с использованием модели `gpt4all-lora-quantized`. Входные сообщения включают системное сообщение и приветствие от пользователя. Метод `create_completion` генерирует текст по частям (stream=True), вызывая функцию `print` для вывода каждого токена на экран.