### Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот код определяет класс `AiAsk`, который является асинхронным провайдером генерации текста, использующим API сервиса AiAsk.me. Он поддерживает ведение истории сообщений и модель GPT-3.5 Turbo.

Шаги выполнения
-------------------------
1. **Импорт необходимых модулей**: Импортируются модули `__future__`, `ClientSession` из `aiohttp`, типы `AsyncResult` и `Messages` из `...typing`, а также базовый класс `AsyncGeneratorProvider`.
2. **Определение класса `AiAsk`**: Определяется класс `AiAsk`, наследующийся от `AsyncGeneratorProvider`. Указываются URL сервиса, поддержка истории сообщений, поддержка GPT-3.5 Turbo и статус работоспособности.
3. **Определение асинхронного генератора `create_async_generator`**: Определяется метод класса `create_async_generator`, который принимает модель, список сообщений и прокси в качестве аргументов.
4. **Формирование заголовков**: Создаются заголовки HTTP-запроса, включающие `accept`, `origin` и `referer`.
5. **Создание сессии `ClientSession`**: Создается асинхронная сессия `ClientSession` с установленными заголовками.
6. **Формирование данных запроса**: Создается словарь `data`, содержащий параметры запроса, такие как `continuous`, `id`, `list` (сообщения), `models`, `prompt`, `temperature` и `title`.
7. **Выполнение POST-запроса**: Выполняется асинхронный POST-запрос к API `f"{cls.url}/v1/chat/gpt/"` с использованием сессии, данных и прокси.
8. **Обработка ответа**: Читаются чанки из ответа, декодируются и передаются через генератор. Если достигнут лимит запросов, выбрасывается исключение `RuntimeError`.
9. **Проверка лимита запросов**: Проверяется, не достигнут ли лимит запросов, сравнивая начало буфера с сообщением об ограничении `rate_limit`.

Пример использования
-------------------------

```python
from src.endpoints.gpt4free.g4f.Provider.deprecated import AiAsk
import asyncio

async def main():
    messages = [
        {"role": "user", "content": "Hello, how are you?"}
    ]
    async for message in AiAsk.create_async_generator(model="gpt-3.5-turbo", messages=messages):
        print(message, end="")

if __name__ == "__main__":
    asyncio.run(main())