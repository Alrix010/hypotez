## Как использовать блок кода Aura.py
=========================================================================================

Описание
-------------------------
Блок кода `Aura.py` реализует класс `Aura`, который наследуется от `AsyncGeneratorProvider`. Он предназначен для асинхронного взаимодействия с API-сервисом `OpenChat` с использованием HTTP-запросов, и представляет собой провайдера для обработки и получения ответов от модели OpenChat 3.6.

Шаги выполнения
-------------------------
1. **Инициализация**: Класс `Aura` имеет статический метод `create_async_generator`, который создает асинхронный генератор для работы с API-сервисом. Метод принимает следующие параметры:
    - `model`: Строковый идентификатор модели, в данном случае `openchat_3.6`.
    - `messages`: Список сообщений, отправляемых модели, представленный в формате `Messages` (списка словарей).
    - `proxy`: Прокси-сервер (опционально).
    - `temperature`: Параметр, регулирующий креативность модели (от 0 до 1).
    - `max_tokens`: Максимальное количество токенов, которое может быть возвращено моделью.
    - `webdriver`: Экземпляр WebDriver, который используется для получения аргументов для HTTP-запроса.
    - `**kwargs`: Дополнительные параметры (например, `headers`).
2. **Формирование запроса**: Метод `create_async_generator` формирует JSON-запрос, который будет отправлен на API-сервер. 
    - В запросе содержится информация о модели, списке сообщений, ключе (который пуст в этом случае), подсказке (системные сообщения) и температуре.
3. **Отправка запроса**: Метод `create_async_generator` отправляет сформированный JSON-запрос на API-сервер с помощью `aiohttp.ClientSession`.
4. **Получение ответа**: После отправки запроса, метод начинает получать данные ответа с помощью `response.content.iter_any()` и отправляет их в виде итератора байтов.
5. **Обработка ответа**: Данные ответа декодируются в строку с использованием `chunk.decode(error="ignore")` и передаются в виде итератора, что позволяет получать ответ модели по частям (например, для отображения прогресса).

Пример использования
-------------------------

```python
from hypotez.src.endpoints.gpt4free.g4f.Provider.not_working.Aura import Aura
from hypotez.src.endpoints.gpt4free.g4f.typing import Messages

# Создание списка сообщений
messages: Messages = [
    {"role": "system", "content": "Ты —  помощник по написанию текстов."},
    {"role": "user", "content": "Напиши мне короткий текст о том, как важен свежий воздух."},
]

# Создание асинхронного генератора для получения ответа от модели
async_generator = Aura.create_async_generator(
    model="openchat_3.6",
    messages=messages,
)

# Получение ответа модели по частям
async for chunk in async_generator:
    print(chunk, end="")
```