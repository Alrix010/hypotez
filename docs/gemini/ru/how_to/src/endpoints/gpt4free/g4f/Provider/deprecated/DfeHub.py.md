## Как использовать класс `DfeHub`

=========================================================================================

### Описание
-------------------------

Класс `DfeHub` реализует провайдера для доступа к API chat.dfehub.com. Он предоставляет метод для создания завершений текста с помощью модели GPT-3.5 Turbo.

### Шаги выполнения
-------------------------
1. **Инициализация класса `DfeHub`**:
    - Создание объекта `DfeHub`.
2. **Вызов метода `create_completion`**:
    - Передача модели (`model`), списка сообщений (`messages`), флага `stream` и дополнительных аргументов (`kwargs`).
3. **Формирование запроса к API**:
    - Создание заголовков запроса (`headers`) с информацией о браузере и запросе.
    - Формирование JSON-данных (`json_data`) с параметрами модели, сообщениями и настройками генерации.
4. **Отправка запроса POST**:
    - Отправка запроса POST к API chat.dfehub.com с заголовками и JSON-данными.
5. **Обработка ответа**:
    - Итерация по ответам, разделенным на куски.
    - Проверка куска на наличие ключа `detail` для задержки.
    - Если есть `detail`:
        - Извлечение значения задержки (`delay`).
        - Ожидание (`time.sleep`) указанное количество секунд.
        - Рекурсивный вызов `create_completion` для получения продолжения ответа.
    - Если есть `content`:
        - Извлечение текста (`content`) из ответа.
        - Генерация результата с текстом.

### Пример использования
-------------------------

```python
from hypotez.src.endpoints.gpt4free.g4f.Provider.deprecated.DfeHub import DfeHub

provider = DfeHub()

messages = [
    {"role": "user", "content": "Привет, мир!"},
]

for chunk in provider.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True):
    print(chunk, end="")
```

В этом примере создается объект `DfeHub`, а затем вызывается метод `create_completion` с моделью `gpt-3.5-turbo`, списком сообщений и флагом `stream` для потоковой передачи ответов. Результаты ответа выводятся по мере их получения.