## Как использовать класс `Free2GPT`
=========================================================================================

Описание
-------------------------
Класс `Free2GPT` реализует асинхронный генератор, который взаимодействует с API `free2gpt.xyz` для получения ответов от языковой модели.

Шаги выполнения
-------------------------
1. **Инициализация:** Создаётся экземпляр класса `Free2GPT`, где:
    - `model`:  Указывает модель, которая будет использована для получения ответов.
    - `messages`: Список сообщений, которые будут отправлены модели.
    - `proxy`: (опционально)  Прокси-сервер для запросов.
    - `connector`: (опционально)  Коннектор для асинхронных HTTP-запросов.
2. **Создание генератора:**  Метод `create_async_generator` класса `Free2GPT` создает асинхронный генератор, который будет использоваться для получения ответов от модели.
3. **Формирование запроса:**
    - Генерируются заголовки запроса с информацией об агенте, языке, кодировке, реферере и источнике.
    - Формируется JSON-объект с данными, включающий список сообщений, время отправки и цифровую подпись.
4. **Отправка запроса:**
    - Используется `ClientSession` для отправки POST-запроса на URL `https://chat10.free2gpt.xyz/api/generate` с JSON-данными.
5. **Обработка ответа:**
    - Проверяется статус ответа:
        - Если статус `500` и текст ответа содержит "Quota exceeded", то генерируется исключение `RateLimitError`.
        - В случае других ошибок ответа генерируется исключение `HTTPError`.
    -  Если ответ успешный, асинхронный генератор  `response.content.iter_any()`  возвращает частями декодированный текст ответа.

Пример использования
-------------------------

```python
from hypotez.src.endpoints.gpt4free.g4f.Provider.Free2GPT import Free2GPT
from hypotez.src.endpoints.gpt4free.g4f.typing import Messages

# Инициализация модели
model = Free2GPT(model="gemini-1.5-pro")

# Пример списка сообщений 
messages: Messages = [
    {"role": "user", "content": "Привет!"},
]

# Получение ответа
async def get_response():
    async for chunk in model.create_async_generator(model="gemini-1.5-pro", messages=messages):
        print(chunk, end="")

# Запуск 
asyncio.run(get_response())
```