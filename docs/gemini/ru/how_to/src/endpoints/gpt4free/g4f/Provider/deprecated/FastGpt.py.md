## Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Данный блок кода реализует класс `FastGpt`, который представляет собой провайдера для доступа к модели GPT-3.5 от FastGPT. 
Класс наследует от базового класса `AbstractProvider`, который определяет общий интерфейс для всех провайдеров.

Шаги выполнения
-------------------------
1. **Инициализация**: Класс `FastGpt` инициализируется с указанием URL-адреса API FastGPT, а также с настройками, такими как:
    - `working`: Флаг, указывающий на то, что провайдер работает.
    - `needs_auth`: Флаг, указывающий на то, что для использования провайдера требуется авторизация.
    - `supports_stream`: Флаг, указывающий на то, что провайдер поддерживает потоковую передачу ответов.
    - `supports_gpt_35_turbo`: Флаг, указывающий на то, что провайдер поддерживает модель GPT-3.5 Turbo.
    - `supports_gpt_4`: Флаг, указывающий на то, что провайдер поддерживает модель GPT-4.
2. **Метод `create_completion`**: Метод используется для создания завершения (ответа) от модели GPT. Он принимает следующие аргументы:
    - `model`: Название модели GPT.
    - `messages`: Список сообщений в диалоге.
    - `stream`: Флаг, указывающий на то, нужно ли использовать потоковую передачу.
    - `kwargs`: Дополнительные аргументы, такие как температура, штрафы за присутствие/частоту и top_p.
3. **Запрос к API**: Метод `create_completion` отправляет запрос к API FastGPT с помощью библиотеки `requests`, используя URL-адрес `https://{subdomain}.fastgpt.me/api/openai/v1/chat/completions`. В запросе передается:
    - `headers`: Заголовки запроса с информацией о браузере, языковых настройках, использовании плагинов и т.д.
    - `json_data`: Тело запроса с информацией о модели, сообщениях, настройках и т.д.
    - `stream`: Флаг, указывающий на то, нужно ли использовать потоковую передачу.
4. **Обработка ответа**: После получения ответа от API, метод `create_completion` обрабатывает его и возвращает генератор токенов для каждого слова в ответе, используя `yield` для потоковой передачи.

Пример использования
-------------------------

```python
from hypotez.src.endpoints.gpt4free.g4f.Provider.deprecated.FastGpt import FastGpt

# Создание экземпляра провайдера FastGpt
fastgpt = FastGpt()

# Список сообщений для диалога
messages = [
    {'role': 'user', 'content': 'Привет! Как дела?'},
    {'role': 'assistant', 'content': 'Хорошо, спасибо. А у тебя как?'}
]

# Получение завершения (ответа) от модели GPT
for token in fastgpt.create_completion(model='gpt-3.5-turbo', messages=messages, stream=True):
    print(token, end='')
```

В этом примере мы создаем экземпляр класса `FastGpt` и передаем ему список сообщений для диалога, используя модель `gpt-3.5-turbo`. Затем мы вызываем метод `create_completion` с флагом `stream=True`, чтобы использовать потоковую передачу. В цикле `for` мы выводим каждый полученный токен, формируя ответ от модели.