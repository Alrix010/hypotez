Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Закомментированный блок кода предназначен для токенизации текста с использованием библиотеки `tiktoken`. Токенизация разбивает текст на отдельные токены, что полезно для оценки размера текста и подготовки его к обработке моделями, такими как GPT-3.5-turbo.

Шаги выполнения
-------------------------
1. **Импорт библиотеки**: Импортируется библиотека `tiktoken` для работы с токенами.
2. **Выбор кодировки**: Определяется кодировка для указанной модели (по умолчанию `gpt-3.5-turbo`).
3. **Кодирование текста**: Текст кодируется с использованием выбранной кодировки.
4. **Подсчет токенов**: Определяется количество токенов в закодированном тексте.
5. **Возврат результата**: Функция возвращает количество токенов и закодированный текст.

Пример использования
-------------------------

```python
# import tiktoken
# from typing import Union

# def tokenize(text: str, model: str = 'gpt-3.5-turbo') -> Union[int, str]:
#     encoding   = tiktoken.encoding_for_model(model)
#     encoded    = encoding.encode(text)
#     num_tokens = len(encoded)
    
#     return num_tokens, encoded

# Пример использования:
# text = "Пример текста для токенизации."
# num_tokens, encoded_text = tokenize(text)
# print(f"Количество токенов: {num_tokens}")
# print(f"Закодированный текст: {encoded_text}")