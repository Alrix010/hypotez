## Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот код-фрагмент предназначен для токенизации текста с использованием библиотеки `tiktoken`. Он разбивает текст на отдельные токены (единицы текста), которые могут быть использованы для обработки в модели GPT-3.5-turbo.

Шаги выполнения
-------------------------
1. **Импортирует необходимые библиотеки:**
    - `tiktoken`: библиотека для токенизации текста.
    - `typing`: библиотека для определения типов данных.
2. **Определяет функцию `tokenize`:**
    - Принимает текст (`text`) в качестве входного параметра.
    - Устанавливает модель GPT (`model`) по умолчанию как `gpt-3.5-turbo`.
    - Получает кодировку для модели GPT с помощью `tiktoken.encoding_for_model(model)`.
    - Кодирует текст с помощью `encoding.encode(text)`.
    - Вычисляет количество токенов в кодированном тексте с помощью `len(encoded)`.
    - Возвращает количество токенов (`num_tokens`) и кодированный текст (`encoded`).

Пример использования
-------------------------

```python
# Пример использования функции tokenize:
text = "Hello, world!"
model = 'gpt-3.5-turbo'  # Модель GPT

num_tokens, encoded = tokenize(text, model)

# Вывод:
print(f"Количество токенов: {num_tokens}")
print(f"Кодированный текст: {encoded}")
```

Этот пример кода демонстрирует, как использовать функцию `tokenize` для токенизации текста и получения количества токенов.