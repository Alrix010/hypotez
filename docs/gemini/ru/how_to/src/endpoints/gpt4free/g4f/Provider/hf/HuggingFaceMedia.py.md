## Как использовать блок кода HuggingFaceMedia
=========================================================================================

Описание
-------------------------
Блок кода реализует класс `HuggingFaceMedia`, который предоставляет функциональность для асинхронной генерации изображений и видео с использованием моделей Hugging Face. Класс наследует от `AsyncGeneratorProvider` и `ProviderModelMixin`, что позволяет использовать его для асинхронного взаимодействия с API и управления моделями. 

Шаги выполнения
-------------------------
1. **Получение списка моделей**: 
   - Класс `HuggingFaceMedia` предоставляет статический метод `get_models()`, который получает список доступных моделей Hugging Face, поддерживающих генерацию изображений и видео.
   - Метод выполняет запрос к API Hugging Face, чтобы получить список моделей, поддерживающих задачи `text-to-image` и `text-to-video`.
   - Метод фильтрует модели, выбирая только те, которые находятся в статусе `live` и имеют заданные задачи. 
   - Список моделей, поддерживающих задачу `text-to-video`, располагается в начале списка `cls.models`, что обеспечивает их приоритет при генерации.
   - Список моделей для генерации изображений и видео сохраняется в `cls.image_models` и `cls.video_models` соответственно. 
2. **Получение информации о модели**:
   - Статический метод `get_mapping()` получает информацию о заданной модели из API Hugging Face.
   - Метод отправляет запрос к API с использованием `StreamSession` и возвращает список доступных провайдеров для модели.
   - Информация о модели сохраняется в `cls.provider_mapping` для последующего использования.
3. **Создание асинхронного генератора**:
   - Статический метод `create_async_generator()` создает асинхронный генератор для генерации изображений или видео.
   - Метод принимает параметры, такие как модель, текст-подсказка, API-ключ, дополнительные данные, а также настройки генерации (количество изображений, аспектное соотношение, размер изображения, разрешение видео и т.д.).
   - Метод выбирает провайдера для генерации, используя `selected_provider`, либо выбирает случайный провайдер из `provider_mapping`, если `selected_provider` не указан.
   - Метод формирует URL-адрес API, используя провайдера, ID модели, API-ключ и дополнительные данные.
   - Метод отправляет запрос к API с использованием `StreamSession` и получает ответ, который преобразуется в объект `ImageResponse` или `VideoResponse`.
   - Асинхронный генератор возвращает объект `Reasoning` с информацией о прогрессе генерации, а также объекты `ProviderInfo` и `ImageResponse`/`VideoResponse` с информацией о провайдере и результатом генерации.

Пример использования
-------------------------

```python
from hypotez.src.endpoints.gpt4free.g4f.Provider.hf.HuggingFaceMedia import HuggingFaceMedia

async def generate_image(prompt: str, model: str = "stable-diffusion-xl-base-1.0"):
    """
    Генерирует изображение с использованием модели Hugging Face.
    
    Args:
        prompt (str): Текстовая подсказка для генерации.
        model (str, optional): Имя модели Hugging Face. По умолчанию "stable-diffusion-xl-base-1.0".
    
    Returns:
        ImageResponse: Объект с результатом генерации.
    """
    async for provider_info, media_response in HuggingFaceMedia.create_async_generator(model=model, prompt=prompt):
        if isinstance(media_response, ImageResponse):
            return media_response
```

В этом примере мы используем метод `create_async_generator` для генерации изображения с помощью модели `stable-diffusion-xl-base-1.0`. 
- Мы передаем текст-подсказку (`prompt`) и имя модели (`model`) в качестве параметров.
- Генератор возвращает объекты `ProviderInfo` и `ImageResponse`, которые содержат информацию о провайдере и результат генерации.
- Функция `generate_image` возвращает объект `ImageResponse`, содержащий URL-адрес сгенерированного изображения.