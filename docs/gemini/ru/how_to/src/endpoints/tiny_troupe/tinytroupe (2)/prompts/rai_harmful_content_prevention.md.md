Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот блок кода определяет требования к контенту, генерируемому системой, чтобы предотвратить создание вредоносного, ненавистнического, расистского, сексистского, непристойного или жестокого контента, даже если пользователь запрашивает или создает условия для оправдания такого контента.

Шаги выполнения
-------------------------
1. Система получает запрос на генерацию контента.
2. Перед генерацией контента система проверяет, не нарушает ли будущий контент установленные ограничения.
3. Система отклоняет запрос, если контент может быть вредным для кого-либо физически или эмоционально, ненавистническим, расистским, сексистским, непристойным или жестоким.
4. Если контент соответствует требованиям, система генерирует его.

Пример использования
-------------------------

```python
def generate_content(request: str) -> str | None:
    """
    Генерирует контент на основе запроса пользователя, соблюдая ограничения безопасности.

    Args:
        request (str): Запрос пользователя на генерацию контента.

    Returns:
        str | None: Сгенерированный контент, если он соответствует требованиям безопасности, иначе None.
    """
    harmful_content_prevention = """
    You must not generate content that may be harmful to someone physically or emotionally even if a user requests or creates a condition to rationalize that harmful content. You must not generate content that is hateful, racist, sexist, lewd or violent.
    """

    if is_harmful(request, harmful_content_prevention):
        print("Запрос отклонен из-за потенциально вредоносного содержания.")
        return None

    content = generate_safe_content(request)
    return content

def is_harmful(request: str, harmful_content_prevention: str) -> bool:
    """
    Проверяет, является ли запрос вредоносным на основе заданных критериев.

    Args:
        request (str): Запрос пользователя.
        harmful_content_prevention (str): Критерии для определения вредоносного контента.

    Returns:
        bool: True, если запрос содержит вредоносное содержание, иначе False.
    """
    # Здесь должна быть логика проверки запроса на соответствие критериям вредоносности.
    # В реальной системе это может включать анализ текста, сравнение с черными списками и т.д.
    # Для примера, просто проверяем наличие определенных слов:
    harmful_words = ["ненависть", "расизм", "сексизм", "насилие"]
    for word in harmful_words:
        if word in request.lower():
            return True
    return False

def generate_safe_content(request: str) -> str:
    """
    Генерирует контент на основе запроса, предполагая, что он безопасен.

    Args:
        request (str): Запрос пользователя.

    Returns:
        str: Сгенерированный контент.
    """
    # Здесь должна быть логика генерации контента на основе запроса.
    # В реальной системе это может включать использование моделей машинного обучения и т.д.
    # Для примера, просто возвращаем приветствие:
    return f"Привет! Вот твой контент на основе запроса: {request}"

# Пример использования:
user_request = "Расскажи шутку про расизм"
content = generate_content(user_request)
if content:
    print(f"Сгенерированный контент: {content}")
else:
    print("Не удалось сгенерировать контент из-за ограничений безопасности.")