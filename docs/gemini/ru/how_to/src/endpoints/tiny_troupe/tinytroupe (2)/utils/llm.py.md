### Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот модуль содержит набор утилит для работы с большими языковыми моделями (LLM), такими как OpenAI. Он включает в себя функции для:

- Композиции сообщений для LLM с использованием шаблонов.
- Превращения функций в функции на основе LLM с помощью декоратора.
- Извлечения JSON из текста.
- Извлечения блоков кода из текста.
- Повторного выполнения функций при возникновении ошибок.
- Добавления переменных шаблона RAI (Responsible AI).
- Усечения текста действий или стимулов.

Шаги выполнения
-------------------------

1.  **Композиция сообщений с использованием шаблонов**:

    *   Функция `compose_initial_LLM_messages_with_templates` используется для создания начальных сообщений для LLM, объединяя системные и пользовательские шаблоны с использованием `chevron`.
    *   Определяется местоположение шаблонов на основе `base_module_folder`. Если `base_module_folder` не указан, используется папка `../prompts/`.
    *   Шаблоны загружаются и отображаются с использованием предоставленных `rendering_configs`.
    *   Возвращается список сообщений, где каждое сообщение представляет собой словарь с ключами `role` (например, `"system"` или `"user"`) и `content` (отображенное содержимое шаблона).

2.  **Превращение функций в функции на основе LLM**:

    *   Декоратор `llm` используется для преобразования обычной функции в функцию, управляемую LLM.
    *   Декорированная функция должна возвращать строку (инструкцию для LLM) или параметры функции будут использоваться в качестве инструкции для LLM.
    *   Декоратор принимает `model_overrides` в качестве аргументов, которые переопределяют параметры модели LLM (например, `model`, `temperature`, `max_tokens`).
    *   Внутри декоратора создается `LLMRequest` с системным запросом (из docstring функции) и пользовательским запросом (из возвращаемого значения функции или параметров).
    *   Вызывается метод `call` объекта `LLMRequest`, который вызывает LLM и возвращает результат.

3.  **Извлечение JSON из текста**:

    *   Функция `extract_json` извлекает JSON-объект из строки, игнорируя любой текст до первой открывающей фигурной скобки `{` или квадратной скобки `[`, а также любые теги Markdown (``````json` или ```).
    *   Использует регулярные выражения для удаления нежелательного текста до и после JSON.
    *   Использует `json.loads` для разбора JSON-строки.
    *   Возвращает разобранный JSON-объект или пустой словарь в случае ошибки.

4.  **Извлечение блоков кода из текста**:

    *   Функция `extract_code_block` извлекает блок кода из строки, игнорируя любой текст до первого открывающего тройного обратного апострофа (```) и любой текст после закрывающего тройного обратного апострофа.
    *   Использует регулярные выражения для удаления нежелательного текста до и после блока кода.
    *   Возвращает извлеченный блок кода или пустую строку в случае ошибки.

5.  **Повторное выполнение функций при возникновении ошибок**:

    *   Декоратор `repeat_on_error` повторяет вызов указанной функции, если возникает исключение из указанного списка, до указанного количества повторных попыток.
    *   Декоратор принимает `retries` (количество повторных попыток) и `exceptions` (список классов исключений, которые нужно перехватить) в качестве аргументов.
    *   Если возникает исключение из списка `exceptions`, оно регистрируется, и функция повторяется.
    *   Если количество повторных попыток превышено, исключение вызывается повторно.

6.  **Добавление переменных шаблона RAI**:

    *   Функция `add_rai_template_variables_if_enabled` добавляет переменные шаблона RAI в указанный словарь, если включены отказы от ответственности RAI.
    *   Эти переменные можно настроить в файле `config.ini`.
    *   Если включено, переменные будут загружать отказы от ответственности RAI из соответствующих файлов в каталоге `prompts`.
    *   В противном случае переменные будут установлены в `None`.

7.  **Усечение текста действий или стимулов**:

    *   Функция `truncate_actions_or_stimuli` усекает содержимое действий или стимулов до указанной максимальной длины.
    *   Создает клон исходного списка, чтобы избежать неожиданных побочных эффектов.
    *   Перебирает элементы клонированного списка и усекает содержимое ключей `action` или `stimulus`, если они присутствуют.
    *   Возвращает усеченный список действий или стимулов.

Пример использования
-------------------------

```python
import os
from tinytroupe.utils.llm import compose_initial_LLM_messages_with_templates, llm, extract_json, repeat_on_error, add_rai_template_variables_if_enabled
from tinytroupe.openai_utils import OpenAIError

# Пример использования compose_initial_LLM_messages_with_templates
messages = compose_initial_LLM_messages_with_templates(
    system_template_name="system_prompt.md",
    user_template_name="user_prompt.md",
    base_module_folder="my_module",
    rendering_configs={"variable1": "value1", "variable2": "value2"}
)
print(messages)

# Пример использования декоратора llm
@llm(model="gpt-4-0613", temperature=0.5, max_tokens=100)
def joke():
    """Рассказывает анекдот."""
    return "Расскажи мне анекдот."

print(joke())

# Пример использования extract_json
json_string = '```json\n{"name": "John", "age": 30}\n```'
extracted_json = extract_json(json_string)
print(extracted_json)

# Пример использования repeat_on_error
@repeat_on_error(retries=3, exceptions=[OpenAIError])
def call_openai():
    # Симулируем OpenAIError
    raise OpenAIError("Ошибка при вызове OpenAI")

try:
    call_openai()
except OpenAIError as e:
    print(f"Исключение перехвачено после нескольких повторных попыток: {e}")

# Пример использования add_rai_template_variables_if_enabled
template_variables = {"prompt": "Some prompt"}
updated_variables = add_rai_template_variables_if_enabled(template_variables)
print(updated_variables)