### Как использовать этот блок кода
=========================================================================================

Описание
-------------------------
Этот блок кода выполняет тестирование основных свойств API языковой модели (LLM), используемого по умолчанию в библиотеке TinyTroupe. Он проверяет, что ответы от LLM API соответствуют минимальным требованиям, таким как наличие ключей `content` и `role`, непустое содержимое этих ключей, а также соответствие длины ответа определенным пределам.

Шаги выполнения
-------------------------
1. **Создание тестового сообщения**: Формируется тестовое сообщение, имитирующее вопрос к коту о секрете счастливой жизни. Используется функция `create_test_system_user_message`.
2. **Отправка сообщения в LLM API**: Тестовое сообщение отправляется в LLM API с помощью метода `send_message` объекта `openai_utils.client()`.
3. **Проверка ответа на `None`**: Утверждается, что ответ от LLM API не равен `None`.
4. **Проверка наличия ключей**: Проверяется, что ответ содержит ключи `content` и `role`.
5. **Проверка содержимого ключей**: Утверждается, что содержимое ключей `content` и `role` не пустое.
6. **Преобразование ответа в строку**: Ответ преобразуется в строку для дальнейших проверок.
7. **Проверка длины строки**: Утверждается, что длина строкового представления ответа находится в пределах от 1 до 2000000 символов.
8. **Проверка кодировки**: Утверждается, что ответ может быть закодирован в UTF-8 без исключений.

Пример использования
-------------------------

```python
import pytest
import textwrap
import logging
import sys

# Добавление путей к модулям для импорта
sys.path.append('../../tinytroupe/')
sys.path.append('../../')
sys.path.append('../')

# Импорт необходимых модулей из TinyTroupe
from tinytroupe import openai_utils
from testing_utils import create_test_system_user_message

def test_default_llmm_api():
    """
    Тестирует основные свойства API языковой модели (LLM) по умолчанию, настроенного для TinyTroupe.
    """

    # Формирование тестового сообщения
    messages = create_test_system_user_message("Если вы спросите кота, в чем секрет счастливой жизни, что бы он ответил?")

    # Отправка сообщения в LLM API
    next_message = openai_utils.client().send_message(messages)

    print(f"Следующее сообщение в виде словаря: {next_message}")

    # Проверки ответа
    assert next_message is not None, "Ответ от LLM API не должен быть None."
    assert "content" in next_message, "Ответ от LLM API должен содержать ключ 'content'."
    assert len(next_message["content"]) >= 1, "Ответ от LLM API должен содержать непустой ключ 'content'."
    assert "role" in next_message, "Ответ от LLM API должен содержать ключ 'role'."
    assert len(next_message["role"]) >= 1, "Ответ от LLM API должен содержать непустой ключ 'role'."

    # Преобразование ответа в строку
    next_message_str = str(next_message)
    print(f"Следующее сообщение в виде строки: {next_message_str}")

    # Проверки длины строки
    assert len(next_message_str) >= 1, "Ответ от LLM API должен содержать хотя бы один символ."
    assert len(next_message_str) <= 2000000, "Ответ от LLM API должен содержать не более 2000000 символов."

    # Проверка кодировки
    assert next_message_str.encode('utf-8'), "Ответ от LLM API должен быть кодируемым в UTF-8 без исключений."
```