# RubiksAI Provider for GPT4Free

## Overview

This module provides the `RubiksAI` class, which acts as a provider for the GPT4Free framework. It enables users to interact with the Rubiks AI API, utilizing its various language models for generating text, translating languages, and more.

## Details

The `RubiksAI` class inherits from `AsyncGeneratorProvider` and `ProviderModelMixin`, enabling it to handle asynchronous responses and manage various models offered by the Rubiks AI API.

## Classes

### `RubiksAI`

**Description**: This class represents a provider for the Rubiks AI API, allowing users to interact with its various language models.

**Inherits**:
- `AsyncGeneratorProvider`: Enables asynchronous generation of responses.
- `ProviderModelMixin`: Provides functionality for handling different models.

**Attributes**:

- `label` (str): Label representing the provider, "Rubiks AI".
- `url` (str): Base URL of the Rubiks AI website.
- `api_endpoint` (str): Endpoint for accessing the Rubiks AI API.
- `working` (bool): Indicates whether the provider is currently functioning.
- `supports_stream` (bool): Specifies whether the provider supports streamed responses.
- `supports_system_message` (bool): Indicates whether the provider supports system messages.
- `supports_message_history` (bool): Specifies whether the provider supports message history.
- `default_model` (str): Default model to use when no other model is specified.
- `models` (list): List of available models supported by the provider.
- `model_aliases` (dict): Mapping of model aliases to their corresponding actual names.

**Methods**:

- `generate_mid()`: Generates a unique identifier for each request.
- `create_referer()`: Creates a Referer URL with dynamic parameters for each request.
- `create_async_generator()`: Creates an asynchronous generator that sends requests to the Rubiks AI API and yields the response.


#### `generate_mid()`

**Purpose**: This method generates a unique identifier (`mid`) for each request sent to the Rubiks AI API.

**Parameters**: None

**Returns**:
- `str`: A generated `mid` string following the pattern: 6 characters - 4 characters - 4 characters - 4 characters - 12 characters.


#### `create_referer()`

**Purpose**: This method constructs a Referer URL for each request, dynamically incorporating the query (`q`), model, and unique identifier (`mid`).

**Parameters**:

- `q` (str): The query string to be included in the Referer URL.
- `mid` (str): The unique identifier generated by the `generate_mid()` method.
- `model` (str, optional): The model name to be used in the Referer URL. Defaults to an empty string.

**Returns**:
- `str`: The constructed Referer URL.


#### `create_async_generator()`

**Purpose**: This method creates an asynchronous generator that manages the communication with the Rubiks AI API, sending requests and yielding the responses.

**Parameters**:

- `model` (str): The model name to be used for the request.
- `messages` (Messages): The messages to be sent as a prompt to the Rubiks AI API.
- `proxy` (str, optional): Proxy URL, if needed. Defaults to None.
- `web_search` (bool, optional): Indicates whether to include search sources in the response. Defaults to False.
- `temperature` (float, optional): Controls the creativity of the generated response. Defaults to 0.6.
- `**kwargs`: Additional keyword arguments.

**Returns**:
- `AsyncResult`: An asynchronous result object.


**How the Function Works**:
- The function first obtains the correct model name based on the provided `model` argument.
- It then generates a unique identifier (`mid`) using the `generate_mid()` method.
- A Referer URL is created using the `create_referer()` method, incorporating the query, model, and `mid`.
- Request data is prepared, including messages, model, search options, and stream settings.
- HTTP headers are set, including Accept, Referer, User-Agent, and other relevant headers.
- The function initiates an asynchronous POST request to the Rubiks AI API endpoint, passing the prepared data and headers.
- It then handles the response, extracting data from the streamed response, and yielding the content to the caller.
- If web search is enabled, the function also yields search sources.


**Examples**:

```python
from hypotez.src.endpoints.gpt4free.g4f.Provider.not_working.RubiksAI import RubiksAI

# Example with a specific model:
async def example_with_model(messages: list):
    rubiks_ai = RubiksAI()
    async for response in rubiks_ai.create_async_generator(model='gpt-4o', messages=messages):
        print(response)

# Example with web search enabled:
async def example_with_web_search(messages: list):
    rubiks_ai = RubiksAI()
    async for response in rubiks_ai.create_async_generator(model='gpt-4o', messages=messages, web_search=True):
        print(response)
```

## Parameter Details

- `model` (str): The name of the model to be used for the request. This parameter is used to specify the specific AI model to use for generating responses. For example, "gpt-4o", "o1-mini", "claude-3.5-sonnet", etc.
- `messages` (Messages): A list of messages representing the conversation history and the current prompt to be sent to the AI. This is the main input for the AI model, containing the context and questions to be addressed.
- `proxy` (str, optional): A URL for a proxy server to be used when making requests. It is used to route the request through a proxy server, which can be helpful for bypassing firewalls or accessing websites from restricted networks.
- `web_search` (bool, optional): A flag indicating whether to include search results in the response. If set to True, the AI model will provide additional information from web searches relevant to the conversation.
- `temperature` (float, optional): A parameter that controls the creativity of the generated response. It ranges from 0 to 1, where higher values indicate more creative and unpredictable responses.

## Examples

```python
# Example with a specific model:
async def example_with_model(messages: list):
    rubiks_ai = RubiksAI()
    async for response in rubiks_ai.create_async_generator(model='gpt-4o', messages=messages):
        print(response)

# Example with web search enabled:
async def example_with_web_search(messages: list):
    rubiks_ai = RubiksAI()
    async for response in rubiks_ai.create_async_generator(model='gpt-4o', messages=messages, web_search=True):
        print(response)
```

-------------------------------------------------------------------------------------