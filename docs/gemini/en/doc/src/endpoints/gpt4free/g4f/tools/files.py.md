# Модуль для работы с файлами

## Обзор

Модуль предоставляет инструменты для обработки различных типов файлов, таких как PDF, DOCX, ODT, EPUB, XLSX, HTML, ZIP и текстовые файлы. Он также включает функциональность для скачивания файлов по URL-адресам, извлечения текста из них и кэширования результатов.

## Подробнее

Модуль предназначен для извлечения и обработки текста из файлов различных форматов, а также для скачивания файлов по URL-адресам. Он использует различные библиотеки, такие как PyPDF2, pdfplumber, pdfminer, docx, docx2txt, odfpy, ebooklib, pandas, BeautifulSoup и spacy, для работы с разными форматами файлов. Модуль также предоставляет функции для кэширования результатов и разделения файлов на части.

## Классы

В данном модуле классы отсутствуют.

## Функции

### `secure_filename`

```python
def secure_filename(filename: str) -> str:
    """
    Преобразует имя файла, удаляя небезопасные символы.

    Args:
        filename (str): Исходное имя файла.

    Returns:
        str: Безопасное имя файла.
    """
```

**Назначение**:
Функция преобразует имя файла, удаляя символы, которые могут быть небезопасными или нежелательными в файловой системе. Она заменяет все символы, кроме букв, цифр, основных знаков препинания и символов Unicode, на символ подчеркивания.

**Параметры**:
- `filename` (str): Имя файла, которое необходимо преобразовать.

**Возвращает**:
- `str`: Преобразованное имя файла, содержащее только безопасные символы.

**Принцип работы**:
- Функция принимает имя файла в качестве входных данных.
- Использует регулярное выражение для замены всех символов, кроме букв, цифр, ".", "_", "+", "-", на символ "_".
- Удаляет пробелы в начале и конце имени файла.
- Обрезает имя файла до 100 символов.
- Удаляет символы ".", "_", "-" и "+" в начале и конце имени файла.

**Примеры**:
```python
secure_filename("Имя файла.txt")  # Возвращает "Имя_файла.txt"
secure_filename("  Небезопасное имя файла  ")  # Возвращает "Небезопасное_имя_файла"
```

### `supports_filename`

```python
def supports_filename(filename: str) -> bool:
    """
    Проверяет, поддерживается ли указанный формат файла.

    Args:
        filename (str): Имя файла для проверки.

    Returns:
        bool: True, если формат файла поддерживается, иначе False.

    Raises:
        MissingRequirementsError: Если отсутствуют необходимые библиотеки для обработки файла.
    """
```

**Назначение**:
Функция проверяет, поддерживается ли указанный формат файла для обработки. Она проверяет наличие необходимых библиотек и расширение файла.

**Параметры**:
- `filename` (str): Имя файла, формат которого необходимо проверить.

**Возвращает**:
- `bool`: `True`, если формат файла поддерживается, иначе `False`.

**Вызывает исключения**:
- `MissingRequirementsError`: Если отсутствуют необходимые библиотеки для обработки файла.

**Принцип работы**:
- Функция принимает имя файла в качестве входных данных.
- Проверяет расширение файла и наличие необходимых библиотек для его обработки (например, `pypdf2` для `.pdf`, `docx` для `.docx` и т.д.).
- Если необходимые библиотеки отсутствуют, вызывает исключение `MissingRequirementsError`.
- Возвращает `True`, если формат файла поддерживается, и `False` в противном случае.

**Примеры**:
```python
supports_filename("example.pdf")  # Возвращает True, если установлена библиотека PyPDF2
supports_filename("example.docx")  # Возвращает True, если установлена библиотека docx
```

### `get_bucket_dir`

```python
def get_bucket_dir(*parts) -> str:
    """
    Формирует путь к директории bucket.

    Args:
        *parts: Части пути к директории.

    Returns:
        str: Полный путь к директории bucket.
    """
```

**Назначение**:
Функция формирует путь к директории bucket, объединяя переданные части пути и применяя функцию `secure_filename` к каждой части.

**Параметры**:
- `*parts`: Переменное количество частей пути к директории.

**Возвращает**:
- `str`: Полный путь к директории bucket.

**Принцип работы**:
- Функция принимает переменное количество частей пути к директории.
- Применяет функцию `secure_filename` к каждой части пути для обеспечения безопасности имени файла.
- Объединяет части пути с использованием `os.path.join`.
- Возвращает полный путь к директории bucket.

**Примеры**:
```python
get_bucket_dir("bucket", "subfolder", "file.txt")  # Возвращает путь к директории "buckets/bucket/subfolder/file.txt"
```

### `get_buckets`

```python
def get_buckets() -> Optional[list[str]]:
    """
    Получает список всех bucket-ов.

    Returns:
        Optional[list[str]]: Список имен bucket-ов или None, если директория не существует.
    """
```

**Назначение**:
Функция получает список всех bucket-ов, находящихся в директории `buckets`.

**Возвращает**:
- `Optional[list[str]]`: Список имен bucket-ов или `None`, если директория `buckets` не существует.

**Принцип работы**:
- Функция пытается получить список всех поддиректорий в директории `buckets`.
- Если директория `buckets` не существует, возвращает `None`.
- Возвращает список имен поддиректорий, которые являются bucket-ами.

**Примеры**:
```python
get_buckets()  # Возвращает список имен bucket-ов, например, ["bucket1", "bucket2"]
```

### `spacy_refine_chunks`

```python
def spacy_refine_chunks(source_iterator) -> Iterator[str]:
    """
    Обрабатывает текстовые фрагменты с использованием библиотеки SpaCy для выделения значимых частей.

    Args:
        source_iterator: Итератор, предоставляющий текстовые фрагменты для обработки.

    Yields:
        str: Обработанные текстовые фрагменты.

    Raises:
        MissingRequirementsError: Если библиотека SpaCy не установлена.
    """
```

**Назначение**:
Функция обрабатывает текстовые фрагменты с использованием библиотеки SpaCy для выделения значимых частей текста.

**Параметры**:
- `source_iterator`: Итератор, предоставляющий текстовые фрагменты для обработки.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий обработанные текстовые фрагменты.

**Вызывает исключения**:
- `MissingRequirementsError`: Если библиотека SpaCy не установлена.

**Принцип работы**:
- Функция принимает итератор текстовых фрагментов в качестве входных данных.
- Загружает модель SpaCy (`en_core_web_sm`).
- Для каждого фрагмента текста создает объект `Doc` с использованием SpaCy.
- Выделяет предложения и сортирует их по длине.
- Извлекает два самых длинных предложения и возвращает их.

**Примеры**:
```python
# Пример использования функции spacy_refine_chunks
source_iterator = ["This is a sentence. This is another sentence.", "Short text."]
refined_chunks = spacy_refine_chunks(source_iterator)
for chunk in refined_chunks:
    print(chunk)
```

### `get_filenames`

```python
def get_filenames(bucket_dir: Path) -> list[str]:
    """
    Получает список имен файлов из файла FILE_LIST в указанной директории.

    Args:
        bucket_dir (Path): Директория, содержащая файл FILE_LIST.

    Returns:
        list[str]: Список имен файлов.
    """
```

**Назначение**:
Функция получает список имен файлов из файла `FILE_LIST` в указанной директории.

**Параметры**:
- `bucket_dir` (Path): Директория, содержащая файл `FILE_LIST`.

**Возвращает**:
- `list[str]`: Список имен файлов.

**Принцип работы**:
- Функция принимает путь к директории bucket в качестве входных данных.
- Проверяет, существует ли файл `FILE_LIST` в указанной директории.
- Если файл существует, открывает его и считывает список имен файлов.
- Возвращает список имен файлов.

**Примеры**:
```python
# Пример использования функции get_filenames
bucket_dir = Path("/path/to/bucket")
filenames = get_filenames(bucket_dir)
print(filenames)
```

### `stream_read_files`

```python
def stream_read_files(bucket_dir: Path, filenames: list, delete_files: bool = False) -> Iterator[str]:
    """
    Читает содержимое файлов из указанной директории и возвращает его в виде итератора.

    Args:
        bucket_dir (Path): Директория, содержащая файлы.
        filenames (list): Список имен файлов для чтения.
        delete_files (bool): Если True, файлы будут удалены после прочтения.

    Yields:
        str: Содержимое файлов.
    """
```

**Назначение**:
Функция читает содержимое файлов из указанной директории и возвращает его в виде итератора. Поддерживает чтение файлов различных форматов, таких как ZIP, PDF, DOCX, ODT, EPUB, XLSX, HTML и текстовые файлы.

**Параметры**:
- `bucket_dir` (Path): Директория, содержащая файлы.
- `filenames` (list): Список имен файлов для чтения.
- `delete_files` (bool): Если `True`, файлы будут удалены после прочтения.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий содержимое файлов.

**Принцип работы**:
- Функция принимает путь к директории bucket и список имен файлов в качестве входных данных.
- Для каждого файла в списке:
    - Проверяет, существует ли файл и не является ли он пустым.
    - Если файл является ZIP-архивом, извлекает все файлы из архива во временную директорию и рекурсивно вызывает `stream_read_files` для извлеченных файлов.
    - Если файл является PDF, DOCX, ODT, EPUB, XLSX, HTML или текстовым файлом, извлекает текст из файла и возвращает его.
    - Если `delete_files` установлен в `True`, удаляет файл после прочтения.
- Возвращает содержимое файлов в виде итератора.

**Примеры**:
```python
# Пример использования функции stream_read_files
bucket_dir = Path("/path/to/bucket")
filenames = ["file1.txt", "file2.pdf"]
for chunk in stream_read_files(bucket_dir, filenames):
    print(chunk)
```

### `cache_stream`

```python
def cache_stream(stream: Iterator[str], bucket_dir: Path) -> Iterator[str]:
    """
    Кэширует содержимое потока данных в файл.

    Args:
        stream (Iterator[str]): Итератор, предоставляющий поток данных.
        bucket_dir (Path): Директория для хранения кэш-файла.

    Yields:
        str: Части данных из потока.
    """
```

**Назначение**:
Функция кэширует содержимое потока данных в файл для последующего использования.

**Параметры**:
- `stream` (Iterator[str]): Итератор, предоставляющий поток данных.
- `bucket_dir` (Path): Директория для хранения кэш-файла.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий части данных из потока.

**Принцип работы**:
- Функция принимает итератор потока данных и путь к директории bucket в качестве входных данных.
- Проверяет, существует ли кэш-файл в указанной директории.
- Если кэш-файл существует, возвращает его содержимое.
- Если кэш-файл не существует, создает временный файл и записывает в него содержимое потока данных.
- Переименовывает временный файл в кэш-файл.
- Возвращает содержимое потока данных.

**Примеры**:
```python
# Пример использования функции cache_stream
stream = ["chunk1", "chunk2", "chunk3"]
bucket_dir = Path("/path/to/bucket")
for chunk in cache_stream(stream, bucket_dir):
    print(chunk)
```

### `is_complete`

```python
def is_complete(data: str) -> bool:
    """
    Проверяет, является ли строка данных завершенной.

    Args:
        data (str): Строка данных для проверки.

    Returns:
        bool: True, если строка данных завершена, иначе False.
    """
```

**Назначение**:
Функция проверяет, является ли строка данных завершенной. Строка считается завершенной, если она заканчивается на "\\n```\\n\\n" и содержит четное количество символов "```".

**Параметры**:
- `data` (str): Строка данных для проверки.

**Возвращает**:
- `bool`: `True`, если строка данных завершена, иначе `False`.

**Принцип работы**:
- Функция принимает строку данных в качестве входных данных.
- Проверяет, заканчивается ли строка на "\\n```\\n\\n".
- Проверяет, является ли количество символов "```" в строке четным.
- Возвращает `True`, если оба условия выполняются, и `False` в противном случае.

**Примеры**:
```python
is_complete("This is a complete string.\\n```\\n\\n")  # Возвращает True
is_complete("This is an incomplete string.")  # Возвращает False
```

### `read_path_chunked`

```python
def read_path_chunked(path: Path) -> Iterator[str]:
    """
    Читает файл по частям, возвращая итератор с фрагментами текста.

    Args:
        path (Path): Путь к файлу.

    Yields:
        str: Фрагмент текста из файла.
    """
```

**Назначение**:
Функция читает файл по частям, возвращая итератор с фрагментами текста.

**Параметры**:
- `path` (Path): Путь к файлу.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий фрагменты текста из файла.

**Принцип работы**:
- Функция принимает путь к файлу в качестве входных данных.
- Открывает файл для чтения в кодировке UTF-8.
- Читает файл построчно и накапливает строки в буфере.
- Если размер буфера превышает 4096 байт, проверяет, является ли буфер завершенным (с использованием функции `is_complete`).
- Если буфер завершен или его размер превышает 8192 байта, возвращает содержимое буфера и очищает его.
- Если после прочтения всего файла в буфере остались данные, возвращает их.

**Примеры**:
```python
# Пример использования функции read_path_chunked
path = Path("/path/to/file.txt")
for chunk in read_path_chunked(path):
    print(chunk)
```

### `read_bucket`

```python
def read_bucket(bucket_dir: Path) -> Iterator[str]:
    """
    Читает кэшированные данные из bucket-а.

    Args:
        bucket_dir (Path): Директория bucket-а.

    Yields:
        str: Кэшированные данные.
    """
```

**Назначение**:
Функция читает кэшированные данные из bucket-а. Она ищет файлы кэша в указанной директории и возвращает их содержимое.

**Параметры**:
- `bucket_dir` (Path): Директория bucket-а.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий кэшированные данные.

**Принцип работы**:
- Функция принимает путь к директории bucket в качестве входных данных.
- Ищет файлы кэша с именами `PLAIN_CACHE`, `spacy_0001.cache`, `plain_0001.cache` и т.д. в указанной директории.
- Возвращает содержимое найденных файлов кэша.

**Примеры**:
```python
# Пример использования функции read_bucket
bucket_dir = Path("/path/to/bucket")
for chunk in read_bucket(bucket_dir):
    print(chunk)
```

### `stream_read_parts_and_refine`

```python
def stream_read_parts_and_refine(bucket_dir: Path, delete_files: bool = False) -> Iterator[str]:
    """
    Читает части файлов из указанной директории, обрабатывает их с помощью SpaCy и возвращает в виде итератора.

    Args:
        bucket_dir (Path): Директория, содержащая части файлов.
        delete_files (bool): Если True, части файлов будут удалены после обработки.

    Yields:
        str: Обработанные части файлов.
    """
```

**Назначение**:
Функция читает части файлов из указанной директории, обрабатывает их с помощью SpaCy и возвращает в виде итератора.

**Параметры**:
- `bucket_dir` (Path): Директория, содержащая части файлов.
- `delete_files` (bool): Если `True`, части файлов будут удалены после обработки.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий обработанные части файлов.

**Принцип работы**:
- Функция принимает путь к директории bucket и флаг `delete_files` в качестве входных данных.
- Проверяет наличие кэш-файла и, если он есть, разделяет его на части с помощью функции `split_file_by_size_and_newline`.
- Ищет части файлов с именами `plain_0001.cache`, `plain_0002.cache` и т.д. в указанной директории.
- Для каждой части файла:
    - Обрабатывает ее с помощью функции `spacy_refine_chunks`.
    - Кэширует результат обработки в файл `spacy_XXXX.cache`.
    - Возвращает обработанную часть файла.
    - Если `delete_files` установлен в `True`, удаляет часть файла после обработки.

**Примеры**:
```python
# Пример использования функции stream_read_parts_and_refine
bucket_dir = Path("/path/to/bucket")
for chunk in stream_read_parts_and_refine(bucket_dir, delete_files=True):
    print(chunk)
```

### `split_file_by_size_and_newline`

```python
def split_file_by_size_and_newline(input_filename, output_dir, chunk_size_bytes=1024*1024):
    """
    Разделяет файл на части заданного размера, разделяя только по символу новой строки.

    Args:
        input_filename: Путь к входному файлу.
        output_dir: Префикс для выходных файлов (например, 'output_part_').
        chunk_size_bytes: Желаемый размер каждой части в байтах.
    """
```

**Назначение**:
Функция разделяет файл на части заданного размера, разделяя только по символу новой строки.

**Параметры**:
- `input_filename`: Путь к входному файлу.
- `output_dir`: Директория для выходных файлов.
- `chunk_size_bytes`: Желаемый размер каждой части в байтах (по умолчанию 1MB).

**Принцип работы**:
- Функция принимает путь к входному файлу, префикс для выходных файлов и желаемый размер каждой части в байтах в качестве входных данных.
- Открывает входной файл для чтения в кодировке UTF-8.
- Читает файл построчно и накапливает строки в буфере.
- Если размер буфера превышает заданный размер, записывает содержимое буфера в выходной файл и очищает буфер.
- После прочтения всего файла записывает оставшееся содержимое буфера в выходной файл.

**Примеры**:
```python
# Пример использования функции split_file_by_size_and_newline
input_filename = "/path/to/input.txt"
output_dir = "/path/to/output"
split_file_by_size_and_newline(input_filename, output_dir, chunk_size_bytes=512*1024)
```

### `get_filename`

```python
async def get_filename(response: ClientResponse) -> str:
    """
    Пытается извлечь имя файла из ответа aiohttp.

    Args:
        response: Объект aiohttp ClientResponse.

    Returns:
        Имя файла в виде строки или None, если не удалось определить.
    """
```

**Назначение**:
Функция пытается извлечь имя файла из ответа `aiohttp`. Сначала проверяет заголовок `Content-Disposition`, затем URL.

**Параметры**:
- `response`: Объект `aiohttp ClientResponse`.

**Возвращает**:
- `str`: Имя файла в виде строки или `None`, если не удалось определить.

**Принцип работы**:
- Функция принимает объект `aiohttp ClientResponse` в качестве входных данных.
- Сначала пытается извлечь имя файла из заголовка `Content-Disposition`.
- Если заголовок `Content-Disposition` отсутствует или не содержит имени файла, пытается извлечь имя файла из URL.
- Если имя файла не удалось извлечь ни из заголовка `Content-Disposition`, ни из URL, возвращает `None`.

**Примеры**:
```python
# Пример использования функции get_filename
async def example():
    async with ClientSession() as session:
        async with session.get("https://example.com/file.pdf") as response:
            filename = await get_filename(response)
            print(filename)
```

### `get_file_extension`

```python
async def get_file_extension(response: ClientResponse):
    """
    Пытается определить расширение файла из ответа aiohttp.

    Args:
        response: Объект aiohttp ClientResponse.

    Returns:
        Расширение файла (например, ".html", ".json", ".pdf", ".zip", ".md", ".txt") в виде строки,
        или None, если не удалось определить.
    """
```

**Назначение**:
Функция пытается определить расширение файла из ответа `aiohttp`.

**Параметры**:
- `response`: Объект `aiohttp ClientResponse`.

**Возвращает**:
- `str`: Расширение файла (например, ".html", ".json", ".pdf", ".zip", ".md", ".txt") в виде строки или `None`, если не удалось определить.

**Принцип работы**:
- Функция принимает объект `aiohttp ClientResponse` в качестве входных данных.
- Сначала пытается определить расширение файла из заголовка `Content-Type`.
- Если заголовок `Content-Type` отсутствует или не содержит расширения файла, пытается извлечь расширение файла из URL.
- Если расширение файла не удалось извлечь ни из заголовка `Content-Type`, ни из URL, возвращает `None`.

**Примеры**:
```python
# Пример использования функции get_file_extension
async def example():
    async with ClientSession() as session:
        async with session.get("https://example.com/file.pdf") as response:
            extension = await get_file_extension(response)
            print(extension)
```

### `read_links`

```python
def read_links(html: str, base: str) -> set[str]:
    """
    Извлекает ссылки из HTML-кода.

    Args:
        html (str): HTML-код для анализа.
        base (str): Базовый URL для объединения относительных ссылок.

    Returns:
        set[str]: Набор URL-адресов, найденных в HTML-коде.
    """
```

**Назначение**:
Функция извлекает ссылки из HTML-кода, объединяет относительные ссылки с базовым URL и возвращает набор URL-адресов.

**Параметры**:
- `html` (str): HTML-код для анализа.
- `base` (str): Базовый URL для объединения относительных ссылок.

**Возвращает**:
- `set[str]`: Набор URL-адресов, найденных в HTML-коде.

**Принцип работы**:
- Функция принимает HTML-код и базовый URL в качестве входных данных.
- Использует библиотеку `BeautifulSoup` для анализа HTML-кода.
- Извлекает все ссылки из HTML-кода.
- Объединяет относительные ссылки с базовым URL.
- Возвращает набор URL-адресов.

**Примеры**:
```python
# Пример использования функции read_links
html = """
<html>
<body>
    <a href="https://example.com/page1">Page 1</a>
    <a href="/page2">Page 2</a>
</body>
</html>
"""
base = "https://example.com"
links = read_links(html, base)
print(links)  # Выведет: {'https://example.com/page1', 'https://example.com/page2'}
```

### `download_urls`

```python
async def download_urls(
    bucket_dir: Path,
    urls: list[str],
    max_depth: int = 0,
    loading_urls: set[str] = set(),
    lock: asyncio.Lock = None,
    delay: int = 3,
    new_urls: list[str] = list(),
    group_size: int = 5,
    timeout: int = 10,
    proxy: Optional[str] = None
) -> AsyncIterator[str]:
    """
    Асинхронно скачивает файлы по URL-адресам.

    Args:
        bucket_dir (Path): Директория для сохранения скачанных файлов.
        urls (list[str]): Список URL-адресов для скачивания.
        max_depth (int): Максимальная глубина рекурсивного скачивания (для HTML-страниц).
        loading_urls (set[str]): Набор URL-адресов, которые уже находятся в процессе скачивания.
        lock (asyncio.Lock): Блокировка для синхронизации доступа к общим ресурсам.
        delay (int): Задержка между запросами в секундах.
        new_urls (list[str]): Список новых URL-адресов, найденных на скачанных страницах.
        group_size (int): Количество URL-адресов для одновременной обработки.
        timeout (int): Время ожидания ответа от сервера в секундах.
        proxy (Optional[str]): Адрес прокси-сервера.

    Yields:
        str: Имена скачанных файлов.
    """
```

**Назначение**:
Функция асинхронно скачивает файлы по URL-адресам, сохраняет их в указанной директории и возвращает имена скачанных файлов. Поддерживает рекурсивное скачивание HTML-страниц.

**Параметры**:
- `bucket_dir` (Path): Директория для сохранения скачанных файлов.
- `urls` (list[str]): Список URL-адресов для скачивания.
- `max_depth` (int): Максимальная глубина рекурсивного скачивания (для HTML-страниц).
- `loading_urls` (set[str]): Набор URL-адресов, которые уже находятся в процессе скачивания.
- `lock` (asyncio.Lock): Блокировка для синхронизации доступа к общим ресурсам.
- `delay` (int): Задержка между запросами в секундах.
- `new_urls` (list[str]): Список новых URL-адресов, найденных на скачанных страницах.
- `group_size` (int): Количество URL-адресов для одновременной обработки.
- `timeout` (int): Время ожидания ответа от сервера в секундах.
- `proxy` (Optional[str]): Адрес прокси-сервера.

**Возвращает**:
- `AsyncIterator[str]`: Асинхронный итератор, предоставляющий имена скачанных файлов.

**Принцип работы**:
- Функция принимает список URL-адресов и параметры скачивания в качестве входных данных.
- Асинхронно скачивает файлы по URL-адресам с использованием библиотеки `aiohttp`.
- Сохраняет скачанные файлы в указанной директории.
- Если скачиваемый файл является HTML-страницей и `max_depth` больше 0, извлекает ссылки из HTML-кода и рекурсивно вызывает `download_urls` для извлеченных ссылок.
- Возвращает имена скачанных файлов в виде асинхронного итератора.

**Примеры**:
```python
# Пример использования функции download_urls
async def example():
    bucket_dir = Path("/path/to/bucket")
    urls = ["https://example.com/file1.txt", "https://example.com/file2.pdf"]
    async for filename in download_urls(bucket_dir, urls, max_depth=1):
        print(filename)
```

### `get_downloads_urls`

```python
def get_downloads_urls(bucket_dir: Path, delete_files: bool = False) -> Iterator[str]:
    """
    Получает список URL-адресов для скачивания из файла DOWNLOADS_FILE в указанной директории.

    Args:
        bucket_dir (Path): Директория, содержащая файл DOWNLOADS_FILE.
        delete_files (bool): Если True, файл DOWNLOADS_FILE будет удален после прочтения.

    Yields:
        str: URL-адреса для скачивания.
    """
```

**Назначение**:
Функция получает список URL-адресов для скачивания из файла `DOWNLOADS_FILE` в указанной директории.

**Параметры**:
- `bucket_dir` (Path): Директория, содержащая файл `DOWNLOADS_FILE`.
- `delete_files` (bool): Если `True`, файл `DOWNLOADS_FILE` будет удален после прочтения.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий URL-адреса для скачивания.

**Принцип работы**:
- Функция принимает путь к директории bucket и флаг `delete_files` в качестве входных данных.
- Проверяет, существует ли файл `DOWNLOADS_FILE` в указанной директории.
- Если файл существует, открывает его и считывает список URL-адресов.
- Если `delete_files` установлен в `True`, удаляет файл после прочтения.
- Возвращает URL-адреса в виде итератора.

**Примеры**:
```python
# Пример использования функции get_downloads_urls
bucket_dir = Path("/path/to/bucket")
for url in get_downloads_urls(bucket_dir, delete_files=True):
    print(url)
```

### `read_and_download_urls`

```python
def read_and_download_urls(bucket_dir: Path, delete_files: bool = False, event_stream: bool = False) -> Iterator[str]:
    """
    Читает URL-адреса из файла загрузок и скачивает их.

    Args:
        bucket_dir (Path): Путь к директории bucket-а.
        delete_files (bool): Удалять ли файл загрузок после прочтения.
        event_stream (bool): Генерировать ли поток событий.

    Yields:
        str: Данные потока событий или None.
    """
```

**Назначение**:
Функция читает URL-адреса из файла загрузок (`DOWNLOADS_FILE`) и скачивает их в указанную директорию bucket-а.

**Параметры**:
- `bucket_dir` (Path): Путь к директории bucket-а.
- `delete_files` (bool): Определяет, следует ли удалять файл загрузок после его прочтения.
- `event_stream` (bool): Определяет, следует ли генерировать поток событий.

**Возвращает**:
- `Iterator[str]`: Итератор, предоставляющий данные потока событий или `None`, если `event_stream` установлен в `False`.

**Принцип работы**:
- Функция принимает путь к директории bucket-а, флаг удаления файлов и флаг потока событий в качестве входных данных.
- Получает список URL-адресов из файла загрузок с помощью функции `get_downloads_urls`.
- Скачивает файлы по URL-адресам с помощью функции `download_urls`.
- Записывает имена скачанных файлов в файл `FILE_LIST`.
- Если `event_stream` установлен в `True`, генерирует поток событий, содержащий информацию о скачанных файлах.

**Примеры**:
```python
# Пример использования функции read_and_download_urls
bucket_dir = Path("/path/to/bucket")
for event in read_and_download_urls(bucket_dir, delete_files=True, event_stream=True):
    print(event)
```

### `async_read_and_download_urls`

```python
async def async_read_and_download_urls(bucket_dir: Path, delete_files: bool = False, event_stream: bool = False) -> AsyncIterator[str]:
    """
    Асинхронно читает URL-адреса из файла загрузок и скачивает их.

    Args:
        bucket_dir (Path): Путь к директории bucket-а.
        delete_files (bool): Удалять ли файл загрузок после прочтения.
        event_stream (bool): Генерировать ли поток событий.

    Yields:
        str: Данные потока событий или None.
    """
```

**Назначение**:
Функция асинхронно читает URL-адреса из файла загрузок (`DOWNLOADS_FILE`) и скачивает их в указанную