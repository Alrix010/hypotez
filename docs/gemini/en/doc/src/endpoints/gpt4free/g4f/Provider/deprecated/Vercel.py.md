## Модуль `Vercel.py`

## Обзор

Модуль `Vercel.py` предоставляет интерфейс для работы с сервисом Vercel AI для создания текстовых завершений. Он поддерживает различные модели, включая `gpt-3.5-turbo`, и обеспечивает потоковую передачу данных. Модуль использует библиотеку `requests` для выполнения HTTP-запросов и `execjs` для выполнения JavaScript-кода, необходимого для получения токена защиты от ботов.

## Подробнее

Модуль определяет класс `Vercel`, который наследуется от `AbstractProvider` и реализует методы для создания запросов к Vercel AI. Он также содержит функции для получения токена защиты от ботов, используемого для аутентификации запросов. Кроме того, в модуле определена структура данных `ModelInfo`, содержащая информацию о поддерживаемых моделях и их параметрах по умолчанию.

## Классы

### `Vercel`

**Описание**: Класс `Vercel` предоставляет интерфейс для взаимодействия с сервисом Vercel AI.

**Наследует**: `AbstractProvider`

**Атрибуты**:
- `url` (str): URL-адрес сервиса Vercel AI.
- `working` (bool): Флаг, указывающий, работает ли провайдер.
- `supports_message_history` (bool): Флаг, указывающий, поддерживает ли провайдер историю сообщений.
- `supports_gpt_35_turbo` (bool): Флаг, указывающий, поддерживает ли провайдер модель `gpt-3.5-turbo`.
- `supports_stream` (bool): Флаг, указывающий, поддерживает ли провайдер потоковую передачу данных.

**Методы**:
- `create_completion()`: Создает запрос к Vercel AI и возвращает результат.

### `Vercel.create_completion`

```python
@staticmethod
def create_completion(
    model: str,
    messages: Messages,
    stream: bool,
    proxy: str = None,
    **kwargs
) -> CreateResult:
    """Функция создает запрос к Vercel AI и возвращает результат.

    Args:
        model (str): Имя модели для использования.
        messages (Messages): Список сообщений для отправки в Vercel AI.
        stream (bool): Флаг, указывающий, использовать ли потоковую передачу данных.
        proxy (str, optional): URL-адрес прокси-сервера. По умолчанию `None`.
        **kwargs: Дополнительные параметры для передачи в Vercel AI.

    Returns:
        CreateResult: Результат запроса.

    Raises:
        MissingRequirementsError: Если не установлен пакет `PyExecJS`.
        ValueError: Если указанная модель не поддерживается Vercel.
    """
```

**Параметры**:
- `model` (str): Имя модели для использования.
- `messages` (Messages): Список сообщений для отправки в Vercel AI.
- `stream` (bool): Флаг, указывающий, использовать ли потоковую передачу данных.
- `proxy` (str, optional): URL-адрес прокси-сервера. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры для передачи в Vercel AI.

**Как работает**:

1. **Проверка зависимостей**:
   - Проверяется, установлен ли пакет `PyExecJS`. Если нет, вызывается исключение `MissingRequirementsError`.

2. **Выбор модели**:
   - Если `model` не указана, используется модель `"gpt-3.5-turbo"`.
   - Если указанная модель не найдена в `model_info`, вызывается исключение `ValueError`.

3. **Формирование заголовков**:
   - Формируются заголовки HTTP-запроса, включая токен защиты от ботов, полученный с помощью функции `get_anti_bot_token()`.

4. **Формирование данных запроса**:
   - Формируются данные JSON для отправки в Vercel AI, включающие идентификатор модели, сообщения, идентификатор игровой площадки и параметры модели по умолчанию.

5. **Выполнение запроса**:
   - Выполняется HTTP-запрос методом `POST` к адресу `'https://chat.vercel.ai/api/chat'` с использованием библиотеки `requests`.
   - В случае ошибки при выполнении запроса, выполняется повторная попытка в течение `max_retries` раз.

6. **Обработка ответа**:
   - Если `stream` установлен в `True`, функция возвращает генератор, который выдает токены из ответа по мере их поступления.
   - Если `stream` установлен в `False`, функция возвращает строку, содержащую полный ответ от Vercel AI.

**Примеры**:

Пример вызова функции:

```python
model = "gpt-3.5-turbo"
messages = [{"role": "user", "content": "Hello, Vercel!"}]
stream = True
proxy = None
kwargs = {}

result = Vercel.create_completion(model, messages, stream, proxy, **kwargs)
for token in result:
    print(token, end="")
```

## Функции

### `get_anti_bot_token`

```python
def get_anti_bot_token() -> str:
    """Функция получает токен защиты от ботов с сервиса Vercel AI.

    Returns:
        str: Токен защиты от ботов.
    """
```

**Как работает**:

1. **Формирование заголовков**:
   - Формируются заголовки HTTP-запроса.

2. **Выполнение запроса**:
   - Выполняется HTTP-запрос методом `GET` к адресу `'https://sdk.vercel.ai/openai.jpeg'` с использованием библиотеки `requests`.

3. **Обработка ответа**:
   - Декодируется ответ, полученный в формате base64, и загружается как JSON.
   - Извлекаются данные `c` и `a` из JSON.
   - Формируется JavaScript-скрипт, который выполняет функцию, полученную от сервера.
   - Выполняется JavaScript-скрипт с использованием библиотеки `execjs`.
   - Формируется JSON с результатами выполнения скрипта и данными `t` из JSON.
   - Кодируется JSON в base64 и возвращается.

### `ModelInfo`

**Описание**: `TypedDict`, описывающий структуру информации о модели.

**Поля**:
- `id` (str): Идентификатор модели.
- `default_params` (dict[str, Any]): Параметры модели по умолчанию.

### `model_info`

**Описание**: Словарь, содержащий информацию о поддерживаемых моделях.

**Пример**:

```python
model_info: dict[str, ModelInfo] = {
    'gpt-3.5-turbo': {
        'id': 'openai:gpt-3.5-turbo',
        'default_params': {
            'temperature': 0.7,
            'maximumLength': 4096,
            'topP': 1,
            'topK': 1,
            'presencePenalty': 1,
            'frequencyPenalty': 1,
            'stopSequences': [],
        },
    },
}
```