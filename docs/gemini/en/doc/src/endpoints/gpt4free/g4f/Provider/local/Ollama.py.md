# Документация для модуля `Ollama.py`

## Описание

Модуль `Ollama.py` предназначен для работы с локальными моделями Ollama в рамках проекта `hypotez`. Он предоставляет класс `Ollama`, который наследуется от `OpenaiAPI` и реализует методы для получения списка моделей и создания асинхронного генератора для взаимодействия с моделью.

## Более подробно

Этот модуль обеспечивает интеграцию с локально развернутыми моделями Ollama, позволяя использовать их для генерации текста и других задач обработки естественного языка. Он использует переменные окружения `OLLAMA_HOST` и `OLLAMA_PORT` для определения адреса и порта сервера Ollama.

## Классы

### `Ollama`

**Описание**: Класс для взаимодействия с локальными моделями Ollama.
**Наследуется от**: `OpenaiAPI`

**Атрибуты**:
- `label` (str): Метка провайдера - "Ollama".
- `url` (str): URL сайта Ollama - "https://ollama.com".
- `login_url` (None): URL для логина (отсутствует).
- `needs_auth` (bool): Требуется ли аутентификация - `False`.
- `working` (bool): Статус работоспособности провайдера - `True`.
- `models` (list): Список доступных моделей (заполняется при первом запросе).
- `default_model` (str): Модель по умолчанию.

**Принцип работы**:
Класс `Ollama` предоставляет методы для получения списка доступных моделей Ollama и создания асинхронного генератора для взаимодействия с моделью. Он использует переменные окружения `OLLAMA_HOST` и `OLLAMA_PORT` для определения адреса и порта сервера Ollama. При первом запросе списка моделей, класс обращается к API Ollama и сохраняет список доступных моделей в атрибуте `models`.

**Методы**:
- `get_models`: Возвращает список доступных моделей Ollama.
- `create_async_generator`: Создает асинхронный генератор для взаимодействия с моделью.

## Методы класса

### `get_models`

```python
    @classmethod
    def get_models(cls, api_base: str = None, **kwargs):
        """
        Получает список доступных моделей Ollama.

        Args:
            api_base (str, optional): Базовый URL API. Defaults to None.
            **kwargs: Дополнительные аргументы.

        Returns:
            list: Список доступных моделей Ollama.
        """
        ...
```

**Назначение**:
Метод `get_models` получает список доступных моделей Ollama. Если список моделей еще не был получен, метод обращается к API Ollama и сохраняет список в атрибуте `models` класса.

**Параметры**:
- `api_base` (str, optional): Базовый URL API. Если не указан, используется значение из переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы.

**Возвращает**:
- `list`: Список доступных моделей Ollama.

**Пример вызова**:

```python
models = Ollama.get_models()
print(models)
```

### `create_async_generator`

```python
    @classmethod
    def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        api_base: str = None,
        **kwargs
    ) -> AsyncResult:
        """
        Создает асинхронный генератор для взаимодействия с моделью Ollama.

        Args:
            model (str): Имя модели.
            messages (Messages): Список сообщений для отправки модели.
            api_base (str, optional): Базовый URL API. Defaults to None.
            **kwargs: Дополнительные аргументы.

        Returns:
            AsyncResult: Асинхронный генератор для взаимодействия с моделью.
        """
        ...
```

**Назначение**:
Метод `create_async_generator` создает асинхронный генератор для взаимодействия с моделью Ollama. Он использует базовый класс `OpenaiAPI` для создания генератора.

**Параметры**:
- `model` (str): Имя модели.
- `messages` (Messages): Список сообщений для отправки модели.
- `api_base` (str, optional): Базовый URL API. Если не указан, используется значение из переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор для взаимодействия с моделью.

**Пример вызова**:

```python
messages = [{"role": "user", "content": "Hello, Ollama!"}]
generator = Ollama.create_async_generator(model="llama2", messages=messages)
```