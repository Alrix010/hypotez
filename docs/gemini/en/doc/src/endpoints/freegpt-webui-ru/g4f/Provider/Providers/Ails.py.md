# Документация для модуля `Ails.py`

## Обзор

Модуль предоставляет реализацию провайдера Ails для работы с языковой моделью `gpt-3.5-turbo` через API `ai.ls`.
Он включает функции для создания запросов к API и обработки ответов в потоковом режиме.

## Детали

Модуль содержит функции для форматирования временных меток, расчета хешей и создания запросов к API `ai.ls`.
Он использует библиотеку `requests` для отправки HTTP-запросов и обработки потоковых ответов.

## Содержание

1.  [Описание модуля](#описание-модуля)
2.  [Классы](#классы)
    *   [Класс `Utils`](#класс-utils)
3.  [Функции](#функции)
    *   [Функция `_create_completion`](#функция-_create_completion)

## Описание модуля

```rst
 .. module:: src.endpoints.freegpt-webui-ru.g4f.Provider.Providers.Ails
```

## Классы

### Класс `Utils`

```python
class Utils:
    """
    Вспомогательный класс, содержащий статические методы для вычисления хешей и форматирования временных меток.

    Методы:
        hash(json_data: Dict[str, str]) -> sha256: Вычисляет хеш на основе переданных данных JSON.
        format_timestamp(timestamp: int) -> str: Форматирует временную метку.
    """
```

#### Метод `hash`

```python
def hash(json_data: Dict[str, str]) -> sha256:
    """
    Вычисляет SHA256 хеш на основе переданных данных JSON.

    Args:
        json_data (Dict[str, str]): Словарь с данными для хеширования.

    Returns:
        sha256: SHA256 хеш в шестнадцатеричном формате.

    Как работает функция:
        - Функция принимает словарь `json_data`, содержащий данные для хеширования.
        - Формирует строку `base_string` из значений по ключам `t` и `m` словаря `json_data`, а также секретной строки и длины значения по ключу `m`.
        - Вычисляет SHA256 хеш от `base_string`.

    Пример:
        >>> json_data = {'t': '1687929600', 'm': 'test message'}
        >>> Utils.hash(json_data)
        'e5b7b9b0a3a7c73b3e3a2a5b8b8b8b8b8b8b8b8b8b8b8b8b8b8b8b8b8b8b8b8b'
    """
```

#### Метод `format_timestamp`

```python
def format_timestamp(timestamp: int) -> str:
    """
    Форматирует временную метку, изменяя последнюю цифру в зависимости от её чётности.

    Args:
        timestamp (int): Временная метка в формате UNIX timestamp (миллисекунды).

    Returns:
        str: Отформатированная временная метка в виде строки.

    Как работает функция:
        - Функция принимает временную метку `timestamp`.
        - Вычисляет последнюю цифру `n` временной метки.
        - Если `n` четная, то `r` присваивается `n + 1`, иначе `n`.
        - Возвращает временную метку, из которой вычли `n` и прибавили `r`.

    Пример:
        >>> Utils.format_timestamp(1687929600000)
        '1687929600001'
        >>> Utils.format_timestamp(1687929600001)
        '1687929600001'
    """
```

## Функции

### Функция `_create_completion`

```python
def _create_completion(model: str, messages: list, temperature: float = 0.6, stream: bool = False, **kwargs):
    """
    Создает запрос к API `ai.ls` и возвращает ответ в потоковом режиме.

    Args:
        model (str): Идентификатор модели.
        messages (list): Список сообщений для отправки в API.
        temperature (float, optional): Температура модели. По умолчанию 0.6.
        stream (bool, optional): Флаг потоковой передачи. По умолчанию False.
        **kwargs: Дополнительные параметры.

    Yields:
        str: Части ответа от API.

    Как работает функция:
        - Функция принимает параметры модели, список сообщений и дополнительные параметры.
        - Формирует HTTP-заголовки, включая `authorization`, `client-id`, `content-type` и `user-agent`.
        - Формирует JSON-данные для запроса, включая параметры модели, температуру, флаг потоковой передачи, сообщения и сигнатуру.
        - Отправляет POST-запрос к API `https://api.caipacity.com/v1/chat/completions` с потоковой передачей.
        - Итерируется по ответу, извлекая контент из каждого чанка и возвращая его через `yield`.

    Примеры:
        >>> messages = [{"role": "user", "content": "Hello, world!"}]
        >>> for token in _create_completion(model="gpt-3.5-turbo", messages=messages, stream=True):
        ...     print(token, end="")
        Привет, мир!
    """