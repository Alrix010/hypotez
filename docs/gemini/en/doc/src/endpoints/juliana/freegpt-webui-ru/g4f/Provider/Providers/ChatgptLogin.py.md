# ChatGPTLogin Provider

## Overview

This module provides a `ChatGPTLogin` provider for the `hypotez` project. It allows using ChatGPT for generating text responses based on a given context. The provider utilizes a free web service that bypasses the need for authentication and directly interacts with OpenAI's ChatGPT API.

## Details

The `ChatGPTLogin` provider leverages a third-party website for free ChatGPT access. It sends requests to this website, which then interacts with OpenAI's API to generate responses. The provider doesn't require any authentication and works directly with OpenAI's GPT-3.5-turbo model.

## Classes

### `ChatGPTLogin`

**Description**: This class represents the `ChatGPTLogin` provider for the `hypotez` project. It handles communication with the free ChatGPT service and retrieves text responses from OpenAI's GPT-3.5-turbo model.

**Inherits**:

**Attributes**:

**Methods**:

### `_create_completion`

**Purpose**: This function handles the process of generating text responses using the `ChatGPTLogin` provider. It builds a request payload with the necessary parameters, sends it to the free ChatGPT service, and then retrieves the response from OpenAI's GPT-3.5-turbo model.

**Parameters**:

- `model` (str): Specifies the GPT model to use for generating responses. Currently, only `gpt-3.5-turbo` is supported.
- `messages` (list): A list of messages representing the conversation history. Each message should be a dictionary with keys `role` (user or assistant) and `content` (the message text).
- `stream` (bool): Indicates whether to stream responses or retrieve them as a single output. Currently, only `False` (no streaming) is supported.

**Returns**:

- `str`: The text response generated by ChatGPT.

**Raises Exceptions**:

- `Exception`: If an error occurs during the communication with the free ChatGPT service or OpenAI's API.

**Inner Functions**:

- `get_nonce()`: This inner function retrieves a unique nonce value required for the request payload. It fetches the necessary data from the free ChatGPT service and extracts the nonce using regular expressions.

- `transform(messages)`: This inner function transforms the `messages` list into a format suitable for the request payload. It encodes HTML entities within the message content and adds additional information for each message.

**How the Function Works**:

1. The `get_nonce()` function retrieves a nonce value from the free ChatGPT service.
2. The `transform(messages)` function processes the `messages` list, encoding HTML entities and adding relevant data for each message.
3. The function constructs the request payload using the provided `messages`, `model`, and other parameters.
4. The function sends a POST request to the free ChatGPT service with the constructed payload.
5. The function retrieves the response from OpenAI's GPT-3.5-turbo model.
6. The function returns the text response from the API.

**Examples**:

```python
# Example 1: Basic chat interaction
messages = [
    {'role': 'user', 'content': 'Hello!'},
    {'role': 'assistant', 'content': 'Hello! How can I help you today?'},
]

response = _create_completion(model='gpt-3.5-turbo', messages=messages, stream=False)

print(response)  # Output: The text response generated by ChatGPT
```

```python
# Example 2: Using a specific prompt
messages = [
    {'role': 'user', 'content': 'What is the capital of France?'},
]

response = _create_completion(model='gpt-3.5-turbo', messages=messages, stream=False)

print(response)  # Output: The text response generated by ChatGPT
```

## Parameter Details

- `model` (str): Specifies the GPT model to use for generating responses. Currently, only `gpt-3.5-turbo` is supported.
- `messages` (list): A list of messages representing the conversation history. Each message should be a dictionary with keys `role` (user or assistant) and `content` (the message text).
- `stream` (bool): Indicates whether to stream responses or retrieve them as a single output. Currently, only `False` (no streaming) is supported.

## Examples

```python
# Example 1: Basic chat interaction
messages = [
    {'role': 'user', 'content': 'Hello!'},
    {'role': 'assistant', 'content': 'Hello! How can I help you today?'},
]

response = _create_completion(model='gpt-3.5-turbo', messages=messages, stream=False)

print(response)  # Output: The text response generated by ChatGPT
```

```python
# Example 2: Using a specific prompt
messages = [
    {'role': 'user', 'content': 'What is the capital of France?'},
]

response = _create_completion(model='gpt-3.5-turbo', messages=messages, stream=False)

print(response)  # Output: The text response generated by ChatGPT
```