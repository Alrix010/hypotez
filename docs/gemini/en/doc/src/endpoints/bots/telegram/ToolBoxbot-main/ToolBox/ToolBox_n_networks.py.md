# Module ToolBox_n_networks.py

## Overview

This module defines the `neural_networks` class, which provides methods for interacting with various neural network models, including image generation and text completion models. It encapsulates the logic for making API requests to these models and handling their responses.

## More details

This module is used to abstract the interaction with different neural network APIs, allowing the application to easily switch between models or use multiple models in a unified way. It handles authentication, request formatting, and response parsing for each model.

## Classes

### `neural_networks`

**Description**: This class provides methods for interacting with neural network models.

**Inherits**: This class does not inherit from any other class.

**Attributes**: This class does not have any specific attributes.

**Working principle**: The class defines methods that encapsulate the logic for interacting with different neural network APIs. Each method is responsible for formatting the request, making the API call, and parsing the response. The class handles authentication using environment variables.

**Methods**:

- `_FLUX_schnell`: Makes a request to the FLUX.1-schnell image generation model.
- `__mistral_large_2407`: Makes a request to the Mistral Large 2407 text completion model.
- `_free_gpt_4o_mini`: Makes a request to the Free GPT-4o Mini text completion model, and falls back to Mistral Large 2407 if the request fails.

## Class Methods

### `_FLUX_schnell`

```python
def _FLUX_schnell(self, prompt: str, size: list[int, int], seed: int, num_inference_steps: int) -> str|None:
    """ Function makes a request to the FLUX.1-schnell image generation model.
    Args:
        prompt (str): Text prompt for image generation.
        size (list[int, int]): List containing the width and height of the image.
        seed (int): Random seed for image generation.
        num_inference_steps (int): Number of inference steps.

    Returns:
        str|None: Image object generated by the model or None if the request fails.

    Raises:
        requests.exceptions.RequestException: If the API request fails.

    Example:
        >>> nn = neural_networks()
        >>> image = nn._FLUX_schnell("A cat", [512, 512], 123, 50)
    """
    ...
```

**Parameters**:
- `prompt` (str): The text prompt for image generation.
- `size` (list[int, int]): A list containing the width and height of the image.
- `seed` (int): The random seed for image generation.
- `num_inference_steps` (int): The number of inference steps.

**Returns**:
- `str|None`: Image object generated by the model or None if the request fails.

**How the function works**:
1. Creates a payload with the prompt, size, seed, and number of inference steps.
2. Iterates through HF_TOKEN environment variables from HF_TOKEN1 to HF_TOKEN6.
3. Sends a POST request to the FLUX.1-schnell API endpoint.
4. If the request is successful (status code 200), opens the image from the response content and returns it.
5. If all requests fail, returns None.

### `__mistral_large_2407`

```python
def __mistral_large_2407(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """ Function makes a request to the Mistral Large 2407 text completion model.
    Args:
        prompt (list[dict[str, str]]): List of dictionaries representing the prompt messages.

    Returns:
        tuple[str, int, int]|str: Tuple containing the generated message, prompt tokens, and completion tokens, or an error string if the request fails.

    Raises:
        requests.exceptions.RequestException: If the API request fails.

    Example:
        >>> nn = neural_networks()
        >>> prompt = [{"role": "user", "content": "Hello, how are you?"}]
        >>> response = nn.__mistral_large_2407(prompt)
    """
    ...
```

**Parameters**:
- `prompt` (list[dict[str, str]]): A list of dictionaries representing the prompt messages.

**Returns**:
- `tuple[str, int, int]|str`: A tuple containing the generated message, prompt tokens, and completion tokens, or an error string if the request fails.

**How the function works**:
1. Creates a data dictionary with the prompt messages, temperature, top_p, max_tokens, and model name.
2. Sends a POST request to the Mistral AI API endpoint.
3. Parses the JSON response.
4. Returns the generated message, prompt tokens, and completion tokens.

### `_free_gpt_4o_mini`

```python
def _free_gpt_4o_mini(self, prompt: list[dict[str, str]]) -> tuple[str, int, int]|str:
    """ Function makes a request to the Free GPT-4o Mini text completion model, and falls back to Mistral Large 2407 if the request fails.
    Args:
        prompt (list[dict[str, str]]): List of dictionaries representing the prompt messages.

    Returns:
        tuple[str, int, int]|str: Tuple containing the generated message, prompt tokens, and completion tokens, or an error string if both requests fail.

    Raises:
        requests.exceptions.RequestException: If the API request fails.

    Example:
        >>> nn = neural_networks()
        >>> prompt = [{"role": "user", "content": "Hello, how are you?"}]
        >>> response = nn._free_gpt_4o_mini(prompt)
    """
    ...
```

**Parameters**:
- `prompt` (list[dict[str, str]]): A list of dictionaries representing the prompt messages.

**Returns**:
- `tuple[str, int, int]|str`: A tuple containing the generated message, prompt tokens, and completion tokens, or an error string if both requests fail.

**How the function works**:
1. Creates a data dictionary with the prompt messages, temperature, top_p, max_tokens, and model name.
2. Iterates through GIT_TOKEN environment variables from GIT_TOKEN1 to GIT_TOKEN6.
3. Sends a POST request to the Azure AI Inference API endpoint.
4. If the request is successful (status code 200), parses the JSON response and returns the generated message, prompt tokens, and completion tokens.
5. If all requests to GPT-4o Mini fail, calls the `__mistral_large_2407` function and returns its result.